{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"line-height:1.2;\">\n",
    "\n",
    "<h1 style=\"color:#BF66F2; margin-bottom: 0.3em;\">PyTorch basics 2</h1>\n",
    "\n",
    "<h4 style=\"margin-top: 0.3em; margin-bottom: 1em;\"> Create models, save and load them via checkpoints. Focus on ONNX engine. </h4>\n",
    "\n",
    "<div style=\"line-height:1.4; margin-bottom: 0.5em;\">\n",
    "    <h3 style=\"color: lightblue; display: inline; margin-right: 0.5em;\">Keywords:</h3> \n",
    "    device check without warnings + onnxruntime + torchvision models\n",
    "</div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings \n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.optim as optim  \n",
    "\n",
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"  Check if CUDA is available \"\"\"\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor x type: torch.FloatTensor, device: cpu\n",
      "Tensor x_cpu type: torch.FloatTensor, device: cpu\n"
     ]
    }
   ],
   "source": [
    "## Create a tensor on the GPU\n",
    "x = torch.randn(3, 3, device=device)\n",
    "\n",
    "## Move the tensor to the CPU\n",
    "x_cpu = x.to('cpu')\n",
    "\n",
    "## Control the type and device of the tensors\n",
    "print(f'Tensor x type: {x.type()}, device: {x.device}')\n",
    "print(f'Tensor x_cpu type: {x_cpu.type()}, device: {x_cpu.device}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#BF66F2 \">  => First way </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=\"./checkpoints/my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "=> Loading checkpoint\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.vgg16(weights=None)      #pretrained=False deprecated!\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "\n",
    "save_checkpoint(checkpoint)\n",
    "load_checkpoint(torch.load(\"./checkpoints/my_checkpoint.pth.tar\"), model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10 \n",
    "checkpoint = {\"epoch\": epoch, \"model_state_dict\": model.state_dict(), \"optimizer_state_dict\": optimizer.state_dict()}\n",
    "torch.save(checkpoint, \"./checkpoints/checkpoint2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"./checkpoints/checkpoint2.pth\")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "epoch = checkpoint[\"epoch\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#BF66F2 \">  => Second way </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#BF66F2\"> Recap: Open Neural Network Exchange</h3>\n",
    "<div style=\"margin-top: -4px;\">\n",
    "ONNX Runtime is a scoring engine to store ML and DL models in ONNX open format. <br>\n",
    "It provides a shared model representation that enables interoperability between various AI frameworks. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"  Export an initialized PyTorch model to the Open Neural Network Exchange (ONNX) format.\n",
    "Then, load the exported ONNX model (using ONNX Runtime) and perform inference.\n",
    "N.B. \n",
    "# To avoid UserWarning related to \"pretrained=False\" option, which is deprecated!\n",
    "=> model = torchvision.models.vgg16(pretrained=False)\n",
    "\"\"\"\n",
    "model = torchvision.models.vgg16(weights=None)\n",
    "\n",
    "batch_size = 3\n",
    "input_size = 100\n",
    "# Export the PyTorch model to the ONNX format, with a shape suitable for VGG16 (3 channels, 224x224 pixels).\n",
    "input_tensor = torch.randn(batch_size, 3, 224, 224)\n",
    "# Resize the input tensor to 224x224 using bicubic interpolation\n",
    "input_tensor_resized = torch.nn.functional.interpolate(input_tensor, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "torch.onnx.export(model, input_tensor_resized, \"./checkpoints/modelonnxsaved.onnx\")\n",
    "\n",
    "# Load the ONNX model\n",
    "session = onnxruntime.InferenceSession(\"./checkpoints/modelonnxsaved.onnx\")\n",
    "inputs = {\"input.1\": input_tensor_resized.numpy()}    #input.1 ! \n",
    "\n",
    "outputs = session.run(None, inputs)\n",
    "output_tensor = torch.from_numpy(outputs[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
