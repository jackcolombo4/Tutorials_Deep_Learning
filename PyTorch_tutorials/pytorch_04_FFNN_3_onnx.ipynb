{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"line-height:1.2;\">\n",
    "\n",
    "<h1 style=\"color:#BF66F2; margin-bottom: 0.3em;\">Feedforward Neural Networks in PyTorch 3 </h1>\n",
    "\n",
    "<h4 style=\"margin-top: 0.3em; margin-bottom: 1em;\">Convert two models (PyTorch and TensorFlow) into ONNX format and use ONNX Runtime to perform inference. </h4>\n",
    "\n",
    "<div style=\"line-height:1.4; margin-bottom: 0.5em;\">\n",
    "    <h3 style=\"color: lightblue; display: inline; margin-right: 0.5em;\">Keywords:</h3> \n",
    "    torchsummary + tf2onnx + onnxruntime + TensorSpec\n",
    "</div>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tf2onnx\n",
    "import onnxruntime\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip, since already installed\n"
     ]
    }
   ],
   "source": [
    "%%script echo Skip, since already installed\n",
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "model = SimpleModel()\n",
    "\n",
    "## Convert to ONNX format\n",
    "dummy_input = torch.randn(1, 2)\n",
    "torch.onnx.export(model, dummy_input, \"./data/simple_model.onnx\")\n",
    "\n",
    "### Inference with ONNX Runtime\n",
    "ort_session = onnxruntime.InferenceSession(\"./data/simple_model.onnx\")\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "output_name = ort_session.get_outputs()[0].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#BF66F2 \"> Recap: torchsummary </h3>\n",
    "<div style=\"margin-top: -8px;\">\n",
    "Show layers, output shapes, and the number of parameters (similar to Keras' model.summary())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                    [-1, 1]               3\n",
      "================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random input\n",
    "x_input = np.random.rand(1, 2).astype(np.float32)\n",
    "# Run inference\n",
    "result = ort_session.run([output_name], {input_name: x_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 21:11:05.175687: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-10-07 21:11:05.175789: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: hpmint\n",
      "2023-10-07 21:11:05.175805: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: hpmint\n",
      "2023-10-07 21:11:05.175873: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 390.157.0\n",
      "2023-10-07 21:11:05.175912: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 390.157.0\n",
      "2023-10-07 21:11:05.175931: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 390.157.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: simple_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: simple_model/assets\n",
      "WARNING:tf2onnx.tf_loader:Could not search for non-variable resources. Concrete function internal representation may have changed.\n",
      "2023-10-07 21:11:06.055917: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-10-07 21:11:06.056112: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2023-10-07 21:11:06.092838: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-10-07 21:11:06.093035: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=[2])])\n",
    "\n",
    "# Convert to ONNX format\n",
    "model.save(\"simple_model\")\n",
    "spec = (tf.TensorSpec((1, 2), tf.float32, name=\"input\"),)\n",
    "converted_model_path = tf2onnx.convert.from_keras(model, input_signature=spec, output_path=\"./data/simple_model.onnx\")\n",
    "\n",
    "# Inference with ONNX Runtime\n",
    "ort_session = onnxruntime.InferenceSession(\"./data/simple_model.onnx\")\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "output_name = ort_session.get_outputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random input\n",
    "x_input = np.random.rand(1, 2).astype(np.float32)\n",
    "# Run inference\n",
    "result = ort_session.run([output_name], {input_name: x_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.583429]], dtype=float32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
