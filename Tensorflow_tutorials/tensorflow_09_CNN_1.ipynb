{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"line-height:0.5\">\n",
    "<h1 style=\"color:#FF7C00  \"> Convolutional Neural Networks in TensorFlow 1 </h1>\n",
    "<span style=\"display: inline-block;\">\n",
    "    <h3 style=\"color: lightblue; display: inline;\">Keywords:</h3>\n",
    "    CNN + Regularization \n",
    "</span>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set an environment variable to suppress log messages from TensorFlow with level 2 or lower.\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.datasets import cifar10, mnist\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping. Works only when GPU is available.\n"
     ]
    }
   ],
   "source": [
    "%%script echo Skipping. Works only when GPU is available.\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FF7C00  \">  <u> Example #1 </u></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data \n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# Normalize the pixel values of the input images, they are converted to float32 and divided by 255.0 to scale the values between 0 and 1.\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 17:42:15.226471: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n"
     ]
    }
   ],
   "source": [
    "############ CNN model\n",
    "model0 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(32, 32, 3)),\n",
    "        layers.Conv2D(32, 3, padding=\"valid\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, 3, activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(10),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" CNN model 2 using the Keras functional API\n",
    "Instead of using the Sequential API, it defines the model as a directed acyclic graph\n",
    "The model has the same architecture as the previous model, but it uses batch normalization layers after each convolutional layer\n",
    "- Conv2D: convolutional layer with 32 filters, a kernel size of 3x3, no padding\n",
    "    => outputs a tensor of the same shape as the input\n",
    "- BatchNormalization: layer that normalizes the activations of the previous convolutional layer across the batch\n",
    "- relu activation function \n",
    "- MaxPooling2D: a max pooling layer that performs max pooling operation on the output of the previous layer,\n",
    "    using a 2x2 window and a stride of 2\n",
    "- Conv2D: (64 filters, a kernel size of 3x3, no padding)\n",
    "- BatchNormalization\n",
    "- relu activation function \n",
    "- MaxPooling2D: a max pooling layer (2x2 window + stride of 2)\n",
    "- Conv2D: convolutional layer with 128 filters, a kernel size of 3x3, and no padding. => outputs a tensor of the same shape as the input\n",
    "- BatchNormalization\n",
    "- relu activation function \n",
    "- Flatten: layer that flattens the output of the previous layer into a 1D tensor\n",
    "- Dense: fully connected layer with 64 units and ReLU activation. => outputs a tensor of shape (64,)\n",
    "- Dense: fully connected layer with 10 units and linear activation. => outputs a tensor of shape (10,) for class probabilities\n",
    "\"\"\"\n",
    "def my_model():\n",
    "    inputs = keras.Input(shape=(32, 32, 3))\n",
    "    x = layers.Conv2D(32, 3)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, 3)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(128, 3)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(10)(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#FF7C00  \">  Recap: Crossentropy Sparse Categorical </h3>\n",
    "<div style=\"margin-top: -23px;\">\n",
    "It calculates the cross-entropy loss between the true labels and predicted logits (unnormalized scores) output \n",
    "by the last layer of the neural network. <br>\n",
    "=> For multi-class classification problems. <br> \n",
    "This solution can be adopted when the labels are integers instead of one-hot encoded vectors: <br>\n",
    "the true labels y_train and y_test will be integer arrays of shape (num_samples in the dataset). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 17:42:17.103836: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 - 84s - loss: 1.3365 - accuracy: 0.5257 - 84s/epoch - 107ms/step\n",
      "Epoch 2/10\n",
      "782/782 - 43s - loss: 0.9663 - accuracy: 0.6601 - 43s/epoch - 55ms/step\n",
      "Epoch 3/10\n",
      "782/782 - 48s - loss: 0.8097 - accuracy: 0.7167 - 48s/epoch - 62ms/step\n",
      "Epoch 4/10\n",
      "782/782 - 74s - loss: 0.7089 - accuracy: 0.7565 - 74s/epoch - 94ms/step\n",
      "Epoch 5/10\n",
      "782/782 - 84s - loss: 0.6225 - accuracy: 0.7836 - 84s/epoch - 107ms/step\n",
      "Epoch 6/10\n",
      "782/782 - 76s - loss: 0.5541 - accuracy: 0.8085 - 76s/epoch - 97ms/step\n",
      "Epoch 7/10\n",
      "782/782 - 83s - loss: 0.4881 - accuracy: 0.8331 - 83s/epoch - 106ms/step\n",
      "Epoch 8/10\n",
      "782/782 - 77s - loss: 0.4390 - accuracy: 0.8507 - 77s/epoch - 99ms/step\n",
      "Epoch 9/10\n",
      "782/782 - 91s - loss: 0.3777 - accuracy: 0.8738 - 91s/epoch - 116ms/step\n",
      "Epoch 10/10\n",
      "782/782 - 74s - loss: 0.3338 - accuracy: 0.8880 - 74s/epoch - 94ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 17:54:32.547507: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 122880000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 - 3s - loss: 0.9770 - accuracy: 0.7017 - 3s/epoch - 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9769536256790161, 0.70169997215271]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" SparseCategoricalCrossentropy loss. \n",
    "N.B. 1\n",
    "- argument \"from_logits\":\n",
    "    If True => it outputs logits, since the last layer of the model is a dense layer with no activation function.\n",
    "    If False => the loss function would expect the output of the last layer to be probabilities, and it would internally apply \n",
    "    the softmax activation function to the logits. However, in this case, the loss function expects the raw logits as input.\n",
    "N.B. 2\n",
    "- Adam optimization algorithm => adaptive learning rate optimization algorithm to compute individual adaptive learning rates \n",
    "    for different parameters from estimates of first and second moments of the gradients.\n",
    "    => learning rate => 3e-4, which is a relatively small learning rate often used in training deep neural networks.\n",
    "\"\"\"\n",
    "model = my_model()\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=2)\n",
    "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#FF7C00 \"><u> Recap: </u></h3>\n",
    "<div style=\"margin-top: -20px;\">\n",
    "The compile method is used to configure the training process of the model, before starting it.\n",
    "As usual, 3 fundamental vars must be specified: the optimizer, the loss function, and the metrics to evaluate during training/validation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FF7C00  \"> <u> Example #2 </u></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Network's layers:\n",
    "- Conv2D: (32 filters, a kernel size of 3x3, and \"same\" padding)\n",
    "- BatchNormalization to normalize the activations of the previous convolutional layer across the batch\n",
    "- relu activation function that applies the Rectified Linear Unit (ReLU) activation to the output of the batch normalization layer\n",
    "- MaxPooling2D: a max pooling layer that performs max pooling operation on the output of the previous layer,\n",
    "    using a 2x2 window and a stride of 2.\n",
    "- Conv2D: (64 filters, a kernel size of 3x3, and \"same\" padding). => outputs a tensor of the same shape as the input\n",
    "- BatchNormalization\n",
    "- relu activation function\n",
    "- MaxPooling2D: (2x2 window and a stride of 2)\n",
    "- Conv2D: (128 filters, a kernel size of 3x3, and \"same\" padding). => outputs a tensor of the same shape as the input\n",
    "- BatchNormalization\n",
    "- relu activation function \n",
    "- Flatten: layer that flattens the output of the previous layer into a 1D tensor\n",
    "- Dense: fully connected layer with 64 units and ReLU activation, and L2 regularization with a weight decay of 0.01\n",
    "    => outputs a tensor of shape (64,)\n",
    "- Dropout: regularization layer that randomly sets a fraction of the inputs to 0 during training to prevent overfitting\n",
    "- Dense: fully connected layer with 10 units and linear activation. => outputs a tensor of shape (10,) for class probabilities\n",
    "\"\"\"\n",
    "\n",
    "def my_regularized_model():\n",
    "    inputs = keras.Input(shape=(32, 32, 3))\n",
    "    x = layers.Conv2D(32, 3, padding=\"same\", kernel_regularizer=regularizers.l2(0.01),)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\", kernel_regularizer=regularizers.l2(0.01),)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(128, 3, padding=\"same\", kernel_regularizer=regularizers.l2(0.01),)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01),)(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(10)(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#FF7C00  \">  Recap: fit() arguments </h3>\n",
    "<div style=\"margin-top: -23px;\">\n",
    "\n",
    "- x: The input data [Numpy array or a list of arrays].\n",
    "- y: The target data [Numpy array or a list of arrays].\n",
    "- batch_size: The number of samples per gradient update in mini-batch.\n",
    "- epochs: The number of epochs (a complete pass through the entire dataset) to train the model.\n",
    "- verbose: The level of detail to display during training.\n",
    "    - =0: no output during the training process.\n",
    "    - =1: displays a progress bar during the training process.\n",
    "    - =2: displays the epoch number, training loss and accuracy, but does not show a progress bar.\n",
    "- validation_data: The data on which to evaluate the loss and any model metrics at the end of each epoch. \n",
    "    - [tuple of (x_val, y_val) or a generator that yields batches of validation data].\n",
    "- shuffle: training or not the data before each epoch.\n",
    "- callbacks: functions to call during training \n",
    "    - EarlyStopping stops training when a monitored quantity has stopped improving\n",
    "    - ModelCheckpoint to save the model after every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping for now to run subsequent examples ...\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipping for now to run subsequent examples ...\n",
    "model3 = my_regularized_model()\n",
    "model3.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model3.fit(x_train, y_train, batch_size=64, epochs=150, verbose=2)   \n",
    "model3.evaluate(x_test, y_test, batch_size=64, verbose=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#FF7C00  \">  <u> Example # 3 </u></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" HYPERPARAMETERS \"\"\"\n",
    "BATCH_SIZE = 64\n",
    "WEIGHT_DECAY = 0.001\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['image_0003.jpg', 'image_0018.jpg', 'image_0008.jpg'],\n",
       " ['img_folder/101_ObjectCategories/rooster/image_0032.jpg',\n",
       "  'img_folder/101_ObjectCategories/rooster/image_0003.jpg',\n",
       "  'img_folder/101_ObjectCategories/rooster/image_0039.jpg'],\n",
       " [0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the path to the dataset folder\n",
    "dataset_folder = \"img_folder/101_ObjectCategories/\"\n",
    "# Get the list of subfolders (categories) in the dataset folder\n",
    "subfolders = os.listdir(dataset_folder)\n",
    "\n",
    "filepaths, labels = [], []\n",
    "\n",
    "\"\"\" Iterate over the subfolders and get the filepaths and labels for each image\n",
    "- image_names is the list of the images in the current subfolder\n",
    "- filepaths list of all paths \n",
    "- labels is the list of all number of folder to which an image belong\n",
    "\"\"\"\n",
    "for i, subfolder in enumerate(subfolders):\n",
    "    # Get the list of image file names in the current subfolder\n",
    "    image_names = os.listdir(os.path.join(dataset_folder, subfolder))\n",
    "    # Add the filepaths and labels for the images in the current subfolder\n",
    "    filepaths += [os.path.join(dataset_folder, subfolder, image_name) for image_name in image_names]\n",
    "    labels += [i] * len(image_names)\n",
    "\n",
    "image_names[:3], filepaths[:3], labels[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7316"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the filepaths and labels into training and testing sets\n",
    "train_filepaths, test_filepaths, train_labels, test_labels = train_test_split(filepaths, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "len(train_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_folder/101_ObjectCategories/camera/image_0...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_folder/101_ObjectCategories/Faces_easy/ima...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_folder/101_ObjectCategories/electric_guita...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_folder/101_ObjectCategories/helicopter/ima...</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_folder/101_ObjectCategories/umbrella/image...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath  label\n",
       "0  img_folder/101_ObjectCategories/camera/image_0...     36\n",
       "1  img_folder/101_ObjectCategories/Faces_easy/ima...     43\n",
       "2  img_folder/101_ObjectCategories/electric_guita...     59\n",
       "3  img_folder/101_ObjectCategories/helicopter/ima...     74\n",
       "4  img_folder/101_ObjectCategories/umbrella/image...     20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrames for the training and testing sets\n",
    "train_df = pd.DataFrame({\"filepath\": train_filepaths, \"label\": train_labels})\n",
    "test_df = pd.DataFrame({\"filepath\": test_filepaths, \"label\": test_labels})\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36]\n",
      " [43]\n",
      " [59]]\n",
      "\n",
      "[[19]\n",
      " [64]\n",
      " [12]]\n"
     ]
    }
   ],
   "source": [
    "train_images = os.getcwd() + \"/\" + train_df.iloc[:, 0].values\n",
    "test_images = os.getcwd() + \"/\" + test_df.iloc[:, 0].values\n",
    "\n",
    "train_labels = train_df.iloc[:, 1:].values\n",
    "test_labels = test_df.iloc[:, 1:].values\n",
    "\n",
    "#train_labels = np.squeeze(train_labels)\n",
    "#test_labels = np.squeeze(test_labels)\n",
    "\n",
    "print(train_labels[:3])\n",
    "print()\n",
    "print(test_labels[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_path, label):\n",
    "    \"\"\" Reads an image from a file and returns it as a tensor along with its label.\n",
    "    \n",
    "    Parameters:\n",
    "        - Path to the image file [str]\n",
    "        - Labels for the image [list]\n",
    "    \n",
    "    Details: \n",
    "        - Read the image file as a binary string\n",
    "        - Decode the binary string into a tensor with the specified number of channels\n",
    "        - Normalize pixel values to [0, 1]\n",
    "        - In older versions => set shape in order to avoid error\n",
    "            - image.set_shape((64, 64, 1))\n",
    "            - label[0].set_shape([])\n",
    "            - label[1].set_shape([])\n",
    "        - Create a dictionary containing the labels\n",
    "    \n",
    "    Returns:\n",
    "        - image tensor representing the image, with shape (height, width, channels).\n",
    "        - labels (dict) with the labels for the image, with keys 'first_num' and 'second_num'.\n",
    "    \"\"\"    \n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_image(image, channels=1)    \n",
    "    #image /= 255.0  \n",
    "    \n",
    "    #print(tf.shape(image)) # return a Tensor not the actual shape!\n",
    "    #print(tf.shape(image).numpy()) # from TensorFlow 2.x, where Tensors and NumPy arrays are separate types!\n",
    "    #print(tf.shape(image).eval())\n",
    "    \n",
    "    image_shape = tf.numpy_function(lambda x: tf.shape(x).numpy(), [image], tf.int32)\n",
    "    print(image_shape)\n",
    "    #image_shape = tf.numpy_function(tf.shape, [image], tf.int32)\n",
    "    #image.set_shape((64, 64, 1))\n",
    "    #image = tf.image.pad_to_bounding_box(image, 0, 0, 64, 64)\n",
    "    #labels = {\"first_num\": label[0], \"second_num\": label[1]}\n",
    "    labels = {\"label\": label}\n",
    "\n",
    "    return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"PyFunc:0\", dtype=int32, device=/job:localhost/replica:0/task:0)\n",
      "Tensor(\"PyFunc:0\", dtype=int32, device=/job:localhost/replica:0/task:0)\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\"\"\" \n",
    "N.B.\n",
    "'from_tensor_slices()' \n",
    "To pass the labels flatten method creates a dataset whose elements are slices of the given tensors. \n",
    "The given tensors are sliced along their first dimension. It means preserving the structure of the input tensors, \n",
    "removing the first dimension of each tensor and using it as the dataset dimension. \n",
    "All input tensors must have the same size in their first dimensions.\n",
    "\"\"\"\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels.flatten()))\n",
    "train_dataset = (\n",
    "    train_dataset.shuffle(buffer_size=len(train_labels))\n",
    "    .map(read_image)\n",
    "    .batch(batch_size=BATCH_SIZE)\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels.flatten()))\n",
    "test_dataset = (\n",
    "    test_dataset.map(read_image)\n",
    "    .batch(batch_size=BATCH_SIZE, drop_remainder=True)  #drop any incomplete batches at the end\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### => Sequential Layer Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" The variable x is reassigned after each layer to hold the output tensor from that layer. It is like chaining layers together! \n",
    "x act as a pointer that moves through this roadmap as you build it. \n",
    "\"\"\"\n",
    "inputs = keras.Input(shape=(64, 64, 1))\n",
    "\n",
    "x = layers.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=3,\n",
    "    padding=\"same\",\n",
    "    kernel_regularizer=regularizers.l2(WEIGHT_DECAY),\n",
    ")(inputs)\n",
    "\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = keras.activations.relu(x)\n",
    "x = layers.Conv2D(64, 3, kernel_regularizer=regularizers.l2(WEIGHT_DECAY),)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = keras.activations.relu(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", kernel_regularizer=regularizers.l2(WEIGHT_DECAY),)(x)\n",
    "x = layers.Conv2D(128, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "\n",
    "output = layers.Dense(10, activation=\"softmax\", name=\"label\")(x)        # the name should be equal to name of key in labels dictionary of \"read_image()\"\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Configure the model for training. Define the optimizer, loss function, and metrics that will be used during the training process.\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
