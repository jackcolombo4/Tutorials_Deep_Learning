{"cells":[{"cell_type":"markdown","metadata":{},"source":["<h1 style=\"color:#BF66F2 \"> Residual Networks in PyTorch 1 </h1>\n","<div style=\"margin-top: -30px;\">\n","<h4> 2 examples of ResNets based on the Street View House Numbers (SVHN) dataset. Focus on learning rate schedulers. </h4>\n","</div>\n","<div style=\"margin-top: -18px;\">\n","<span style=\"display: inline-block;\">\n","    <h3 style=\"color: lightblue; display: inline;\">Keywords:</h3>\n","    resnet18 + torch.optim + torch.autograd + optim.step() + requires_grad\n","</span>\n","</div>"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":528,"status":"ok","timestamp":1689365992183,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"z3MpKBfd3YKL"},"outputs":[],"source":["# autocompletion\n","#!pip install jedi\n","%config Completer.use_jedi = True"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","from torchvision.models import resnet18, ResNet18_Weights"]},{"cell_type":"markdown","metadata":{"id":"Qv1B6Fq9yb2j"},"source":["<h3 style=\"color:#BF66F2\"> Recap: ResNets</h3>\n","<div style=\"margin-top: -17px;\">\n","ResNet-18 model is implemented as a class in the torchvision.models module of the PyTorch library, it is loaded with its default pre-trained weights. <br>\n","ResNet is trained on the ImageNet dataset, a large-scale image classification dataset: consists of 1.2 million images belonging to 1000 different classes. <br>\n","\n","The model takes an input image of size 224x224 pixels and outputs a probability distribution over the 1000 classes. <br>\n","Then it uses this information to adjust its weights so that it can predict the correct label for a given input image. <br>\n","The process of adjusting the weights of the model based on the ground-truth labels is known as supervised learning.\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# NN with 18 convolutional layers\n","model = resnet18(weights=ResNet18_Weights.DEFAULT) "]},{"cell_type":"markdown","metadata":{},"source":["<h2 style=\"color:#BF66F2 \"> <u> Example 1 </u> </h2>"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":877,"status":"ok","timestamp":1689366520777,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"DA2YKIITxtYa"},"outputs":[],"source":["data_tensor = torch.rand(1, 3, 64, 64)\n","# Create the ground-truth outputs (targets)\n","labels_tensor = torch.rand(1, 1000) "]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1689366520778,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"hkyTcyM5z-Ub","outputId":"adf4e66c-c4e6-4fdc-fd1c-018f417043fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["type model = <class 'torchvision.models.resnet.ResNet'>\n"]}],"source":["print(f\"type model = {type(model)}\")"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1689366520779,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"fJy-6GkaxwTp","outputId":"213cbc9c-21b2-4da1-d868-2364ecbd3fc5"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'torch.Tensor'>\n","<class 'torch.Tensor'>\n"]}],"source":["\"\"\" Assign to each class a unique label in the range from 0 to 999.\n","The model has to predict the correct label for a given input image.\n","\"\"\"\n","print(type(data_tensor))\n","print(type(labels_tensor))"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1689366520780,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"XnsP8uuF3bLT","outputId":"7f512af9-176a-4a7c-e3ee-aa8647080c91"},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","1\n"]}],"source":["## Slicing\n","labels_tensor2 = labels_tensor[0][0]\n","labels_tensor2 = labels_tensor[:1]\n","print(len(labels_tensor))\n","print(len(labels_tensor2))"]},{"cell_type":"markdown","metadata":{"id":"PHzInYJA5qn-"},"source":["<h4 style=\"color:#BF66F2 \">  Step #1 </h4>\n","Run the input data through the model through each of its layers to make a prediction => Performing the Forward Pass."]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1689366520782,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"_pVEv47R5srQ"},"outputs":[],"source":["# Perform forward pass\n","prediction = model(data_tensor) "]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1689366520782,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"Y3W2wff756TJ","outputId":"16e041c9-9f22-4edb-cb01-592dab2da66e"},"outputs":[{"data":{"text/plain":["tensor([[-0.4706, -0.2791, -0.5038, -1.2571, -0.4725,  0.0677, -0.0241,  0.4223,\n","          0.5338, -0.8712, -1.0038, -0.5996, -0.0404, -0.5431, -1.0367, -0.7903,\n","         -0.6267,  0.0956, -0.3114, -0.5726, -1.6220, -0.6621, -1.4162,  0.2537,\n","         -0.7347, -1.1150, -1.0951, -1.1698, -0.7301, -0.4161, -0.5347, -0.7960,\n","         -0.3765, -0.4521, -0.5154, -0.3166,  0.4740, -0.5638, -0.7520, -0.0622,\n","         -0.6628, -1.0831, -1.1103, -0.3416, -0.7653, -0.5388, -0.6666, -0.6966,\n","         -1.6033, -1.1438, -0.3556,  0.3514, -0.5565, -0.6628, -0.3979, -1.1646,\n","         -0.6183, -1.3783, -0.3140, -0.6261,  0.5639, -0.1567, -0.6663, -0.1863,\n","         -0.7991, -0.2993, -0.6027, -0.2634, -1.0620, -0.9908, -1.3605, -0.1366,\n","         -1.3244, -0.4294, -1.0877, -1.0231, -0.2424, -0.7421,  0.0159,  0.1607,\n","         -0.7783, -1.5676, -0.0120, -0.7848, -0.9231, -0.1835, -0.0653,  0.1628,\n","         -0.0711, -0.7416, -1.0887, -1.2781, -1.7643, -0.2562,  0.3406, -1.9942,\n","         -0.4248,  0.0100, -1.2979, -0.3086, -0.7146, -1.1805, -1.1121, -0.5356,\n","         -0.4150, -0.6167, -0.2677, -1.4259, -1.3162, -1.6351, -1.1859, -0.7286,\n","          1.1499,  0.2096,  0.1342, -1.1648, -0.9564, -0.2311,  0.6865, -0.5334,\n","         -1.2731,  0.2755,  0.5110,  0.2964,  1.2811, -0.2485,  0.4161, -1.3514,\n","         -1.2477, -1.2184, -1.3891, -1.5464, -1.1274, -1.2624, -0.6596, -1.4088,\n","         -0.5221, -0.8487, -1.4416, -1.4713, -1.6479, -1.5098, -1.8616, -1.2889,\n","         -0.6720, -0.3963, -0.8985, -1.9801, -1.2073, -1.2278,  0.4520,  1.3125,\n","         -1.2514, -0.6039, -0.1736, -0.0850, -0.7942, -0.5666, -0.0604,  0.2573,\n","          0.2141,  0.6428,  0.0590,  0.5902,  0.3153, -0.0936, -0.3656, -0.7328,\n","          0.5677, -0.9921, -0.2903,  0.7222,  0.0510, -0.0618,  0.2825, -0.8572,\n","         -0.1500, -0.2955,  0.6874,  0.6187,  0.5190, -0.1856,  0.4778, -0.0072,\n","          0.5336,  0.4809,  0.5118,  0.0624, -0.3361,  0.3400, -0.7365,  0.4605,\n","          0.3024,  0.4282, -0.9307,  0.7476, -0.1380,  0.2917, -0.1396,  0.5329,\n","          0.1291, -0.0423,  0.2083,  0.3132, -0.2551,  0.2749, -0.1965,  0.7660,\n","          1.4332,  0.6793,  0.0056,  0.5473,  0.2204, -0.0399,  0.0254,  0.0165,\n","         -0.3163,  0.4034, -0.6199,  0.6195,  0.1039, -0.3858, -0.0521,  0.7220,\n","          0.1545,  0.5396, -0.0848,  0.7229, -0.5699, -0.4213, -0.1168,  0.3174,\n","          0.2475, -0.3887,  0.9146,  0.9689,  0.6294,  0.5897,  0.7884, -0.0437,\n","          0.3889, -0.0649,  0.1974,  0.4173, -0.3211,  0.3743,  0.6357, -0.2887,\n","          0.6834,  0.1725,  0.4981,  0.6675, -1.3303,  0.5697,  0.7996, -0.6787,\n","          0.4142, -0.0048, -0.1445,  0.2436, -0.0984, -0.7213, -0.6396,  0.2620,\n","          0.7800,  0.5891,  0.0790,  0.6208, -0.5513, -0.6791, -1.0538, -1.4434,\n","         -0.6125,  0.5967, -1.3862, -1.4386, -1.3486, -1.0056, -1.4748, -0.6702,\n","         -0.7127,  0.7086,  0.7247, -0.0927,  0.4012,  0.8932, -0.1363,  0.0708,\n","         -0.7665, -1.5600, -1.0978, -1.2405, -0.4928, -0.8916, -1.2000, -0.9457,\n","         -0.8480, -1.6453, -0.4506, -0.1434, -1.9069, -1.0245, -0.9005, -0.4421,\n","         -1.3206, -1.0639,  0.1618, -1.0705, -1.6258, -0.7082,  0.0605, -0.2445,\n","         -0.5505,  0.0617,  0.7486, -0.6933, -0.8393, -0.7904, -1.2025, -0.6917,\n","         -1.6512, -1.0812, -1.3626, -1.6189, -1.5086, -1.5105, -1.4582,  0.0170,\n","         -0.0779, -0.1741, -0.0757, -0.0206,  0.0543,  0.5092, -0.6562, -1.0028,\n","         -1.3589,  0.3237,  0.7900, -1.3263, -0.6138,  0.0427, -1.1326, -1.8682,\n","         -0.8830,  0.5022, -0.7489, -1.6971, -0.1237, -1.6403, -1.2096, -2.0019,\n","         -1.3061, -0.9381, -0.6912,  0.2751,  0.9114, -0.0579,  0.2441,  0.4566,\n","         -0.3260,  0.1382, -0.0501,  0.0928, -0.6483, -0.8549, -1.1456, -0.3991,\n","         -0.9262, -0.6705, -0.9972, -0.6634, -0.6198, -0.0580, -0.3856, -1.2073,\n","         -1.1550,  0.2507, -0.4504, -0.6636, -0.1629, -0.6343, -0.4674, -0.7432,\n","         -0.8762, -0.8595, -1.2695, -1.5392, -0.8295,  0.1084,  0.6239,  0.4807,\n","         -1.4451, -1.7153,  0.1127,  0.5909, -1.0530, -0.5413,  0.7682,  0.3179,\n","         -0.6206,  0.5386,  0.1830, -2.3005, -1.7665, -0.7446, -0.2134, -0.2542,\n","         -0.3253,  0.7950, -0.1346,  0.5392,  2.2869,  0.4131,  0.4959,  1.1170,\n","         -0.2406,  0.3606,  0.3412,  0.9649,  0.8031,  1.4732, -0.1341,  0.2360,\n","          0.2888, -1.0538, -0.1359,  1.4880,  1.9319,  0.4607, -0.8744, -0.1657,\n","          0.2174,  0.9426,  0.7728,  1.2039, -0.2792, -0.6957,  0.4776,  0.2238,\n","          1.0498,  0.7778, -0.1206, -0.3180, -0.2431,  0.3725,  0.4060,  1.4083,\n","          1.1891, -0.6276,  0.0652,  0.1549,  0.6310, -0.0519, -0.1967,  0.7204,\n","          1.5585,  1.4897, -0.0816,  0.8866, -0.8246,  0.5325,  1.3930,  2.5921,\n","          0.7504, -0.2114, -1.1114,  0.3042, -0.1812,  1.3998,  1.3042,  0.4805,\n","          0.6776,  1.5616, -0.2285,  0.0956,  0.2003,  0.6073,  1.1621,  0.4603,\n","          0.0718,  0.1034,  0.0602, -0.8694, -1.7151, -0.2003, -0.5257,  1.1515,\n","          1.6943,  1.3736, -0.0385,  0.9030,  0.6559, -0.9993,  1.0681, -0.8392,\n","          0.1954, -0.4252, -0.2339,  1.6399, -1.7309,  0.7391,  1.4247,  0.7062,\n","          1.0937,  1.2076,  0.8828,  0.6034,  0.4816,  0.4774, -1.3017, -0.9983,\n","          0.9349,  0.1115,  1.3862,  1.8069,  0.5665,  0.2259,  1.2637,  1.0932,\n","         -0.6486,  0.4083,  0.9736,  1.7449,  0.2507, -0.6194, -0.1659, -0.5650,\n","          0.8814, -0.0179,  0.9776,  0.4269, -0.0681, -1.0167,  0.5239, -0.3970,\n","         -0.4590, -0.6282,  0.0913,  1.2057, -1.4018,  1.6831,  1.2789,  0.8179,\n","          0.6676,  1.0532,  0.6580, -2.0798, -1.2527,  0.1635, -0.4245,  0.1228,\n","          0.9025, -0.0128, -1.6154, -0.7978,  0.2475,  0.3956,  1.1321,  0.3345,\n","         -0.2194,  0.0789,  0.7688,  0.1864, -1.2584, -0.8285,  0.1437,  1.5526,\n","          0.6508, -0.3284,  1.3159,  0.5570,  1.1161, -0.5213,  0.4387,  0.0403,\n","         -0.6828,  1.1078,  0.7913,  0.6375,  0.2254, -0.0098,  0.8121,  0.5115,\n","          0.6888,  0.9254, -0.3602,  1.9402,  1.2065,  1.2934, -0.6943,  0.3889,\n","         -0.4296,  0.6140,  0.2015, -0.3715,  1.1575, -0.0688, -0.5509,  0.6719,\n","          2.0933, -0.0941, -0.2410, -0.4116,  0.6473,  0.4058,  1.5229, -0.6757,\n","          0.6099, -0.2335,  0.9801,  0.6111, -0.5667,  0.8861, -0.0047,  0.2336,\n","          1.0523,  0.5707,  2.1341,  0.9255,  1.0292,  0.9297,  0.4647,  0.4831,\n","          0.0431, -1.3405,  0.8795, -0.3372, -1.4495,  0.4096,  0.1877,  0.9026,\n","          0.7345,  1.1108, -0.2338,  0.3365,  1.3356,  0.9526,  0.7978,  0.2142,\n","         -1.8303,  1.0199, -0.0901,  1.3268,  0.9146, -0.9211,  0.5181,  0.8853,\n","         -0.4667, -1.3814,  1.0280,  0.0934,  0.8860,  1.0062, -0.0557,  0.7018,\n","          0.1177,  0.0384,  0.1695,  0.6644, -0.0284, -0.8379, -0.1390, -1.0132,\n","          0.7199,  0.0845,  1.2028,  0.7235, -0.8803, -0.3707,  0.3951,  0.0924,\n","         -0.5060,  0.8419,  1.2421, -0.8456,  1.5197,  0.9542,  1.1219,  0.2222,\n","          0.5149,  0.6062, -0.5950,  0.4911,  0.7927, -1.3527, -0.0473, -0.9853,\n","         -0.2714, -0.6668, -0.7346,  0.8000,  0.9109,  0.9563, -1.0882,  0.7534,\n","          1.8726,  0.0513, -0.4439,  0.5650,  2.0262, -0.3286, -0.3472,  0.3768,\n","          0.9691, -0.4220, -0.6364,  0.5464,  1.1181,  0.2858,  1.3495,  1.0037,\n","          0.0623, -0.3744,  0.2190, -0.4806,  0.8339, -0.5923, -0.3449,  0.6064,\n","         -0.2052,  0.3224,  1.6027,  0.2441, -0.5954,  1.4856, -0.6394, -0.3407,\n","          1.5064, -0.5419,  0.2457,  2.2446, -0.5663,  2.0059, -1.4517,  0.1295,\n","          0.3583,  0.8624,  1.0768,  0.4508,  1.2564, -0.1476,  0.2376,  0.0748,\n","          0.6174,  0.0033, -0.0381,  0.7786,  0.6670,  1.3909,  0.3947, -0.0826,\n","          1.0103,  0.5636,  0.6348, -0.7070,  1.2137, -0.2145,  1.2500, -0.0138,\n","          0.6035,  0.8880,  0.5211,  0.8355,  1.0945,  0.7441,  0.4675,  0.7212,\n","         -0.0783,  1.4417,  0.3619,  0.3809,  1.4690,  0.9897,  0.9347,  0.6400,\n","          0.4706,  0.5679,  1.7173, -0.6908, -0.8946, -0.8297,  0.8291,  0.8262,\n","          1.6607,  0.2322,  0.5811,  1.0677,  0.5995, -0.0528,  0.5496,  1.3010,\n","          1.8834,  1.1894,  0.6820,  0.4599,  1.0863,  0.6850, -0.8813,  0.3591,\n","         -0.5517,  0.5703, -0.7222, -1.1087,  1.0501,  1.1626,  0.4555, -0.0288,\n","          1.3003,  0.2408, -0.6150,  1.0914, -0.3191,  1.9268, -1.2561, -0.3049,\n","          0.0963, -1.0621,  1.1138,  0.0637, -1.4564, -1.2606,  0.2941,  1.0041,\n","          1.1300, -0.9274,  0.1882,  1.1600,  1.5381, -0.3865,  1.0898,  0.1436,\n","         -0.7464, -1.1651,  0.0437,  0.6442,  1.6347,  1.6957,  1.0056, -0.4944,\n","          1.5366,  0.5304,  0.3429,  0.3563,  0.8049,  1.8928,  0.6353, -0.5604,\n","          0.1294,  1.0684,  1.3900,  1.1765,  1.8915, -0.8138, -0.6838,  0.4201,\n","         -0.5614, -0.0861, -0.3024,  1.0995,  0.0359,  1.4914,  0.8730,  0.4383,\n","         -0.4970,  0.6315,  0.2350, -0.1882,  1.8244, -0.3592,  1.1351, -1.5135,\n","          1.0316, -1.2177, -2.2070,  0.0493,  1.6347,  0.2097, -0.3998,  1.5682,\n","          1.2545, -0.2647,  1.4216,  1.3910, -0.3536,  0.3940, -0.1912, -0.2055,\n","         -1.0286,  0.0564, -0.5534,  0.5587,  0.5692, -0.0650, -0.4894, -0.4604,\n","          1.1965,  0.7412,  2.0896,  1.9405, -1.1330, -0.5498,  1.6923,  0.9136,\n","          0.8299, -0.0219, -0.5422,  1.4239, -0.4368,  1.1532,  1.5445,  0.9094,\n","          1.0008, -0.4283, -2.0669, -0.2630,  0.0276,  0.1437,  0.6384,  0.2200,\n","          0.1347,  1.1484, -0.2484,  0.7911, -0.1245, -0.7388, -0.9001, -0.5341,\n","          0.0512,  1.5085, -0.1101,  0.1648,  0.6461, -1.2527,  0.1141, -0.3242,\n","          0.3290,  0.5756,  0.2069,  0.0312, -0.4291, -0.5821, -0.1053,  0.1858,\n","         -0.2696, -0.7482, -1.2517,  0.5965,  0.6410, -0.2941,  0.0144, -0.5065,\n","         -0.4685,  0.6153,  0.9414, -0.2850, -0.3567, -0.4879,  0.3386, -0.9343,\n","          0.4729,  0.6352, -0.4286, -0.9133, -1.0918, -0.0627,  0.6979, -0.3183,\n","          1.0099,  0.2769,  0.1194,  0.9297, -0.3731, -0.5613, -2.2151,  0.9660,\n","         -1.6603,  0.3567, -0.0429, -0.7973, -0.7476,  0.0154,  0.7788, -0.2815,\n","         -0.7182, -1.2820, -2.4184,  1.4860, -0.1232, -0.7396, -0.6259, -1.1031,\n","         -0.8314, -2.1369, -1.0015, -0.3827,  0.1737, -0.6744,  1.5482,  1.1909]],\n","       grad_fn=<AddmmBackward0>)"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["prediction"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1689366522065,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"OhFebXkI5ynV","outputId":"d5e66c83-11d5-4a85-a028-05555a6f83a4"},"outputs":[{"data":{"text/plain":["tensor([-0.4706, -0.2791, -0.5038, -1.2571, -0.4725], grad_fn=<SliceBackward0>)"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["prediction[0][:5]"]},{"cell_type":"markdown","metadata":{"id":"FfpKg4PW6EJx"},"source":["<h4 style=\"color:#BF66F2 \">  Step #2 </h4>\n","<div style=\"margin-top: -20px;\">\n","<div style=\"line-height:1.3\">\n","\n","- Calculate the error (loss = difference from model’s predictions and the corresponding labels. <br>\n","- Backpropagate the error through the network calling the '.backward()' method. <br>\n","The optimizer used is 'Autograd' to calculate and store the gradients for each model parameter in the parameter’s '.grad' attribute.\n","</div>\n","</div>"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1689366522066,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"6F8bQHiS6KBj"},"outputs":[],"source":["loss = (prediction - labels_tensor).sum()\n","# Perform the backward pass\n","loss.backward() "]},{"cell_type":"markdown","metadata":{"id":"ickcElT96QdU"},"source":["<div style=\"line-height:0.1\">\n","<h4 style=\"color:#BF66F2 \">  Step #3 </h4>\n","</div>\n","<div style=\"line-height:1.2\">\n","Load an optimizer, in this case SGD with a learning rate of 0.01 and momentum of 0.9. <br>\n","All parameters are registered in the optimizer.\n","</div>"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1689366523348,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"fz3yqHCy6Ugj","outputId":"f2c77d94-0166-49cb-ed5b-2f925081413b"},"outputs":[{"data":{"text/plain":["SGD (\n","Parameter Group 0\n","    dampening: 0\n","    differentiable: False\n","    foreach: None\n","    lr: 0.01\n","    maximize: False\n","    momentum: 0.9\n","    nesterov: False\n","    weight_decay: 0\n",")"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n","optim"]},{"cell_type":"markdown","metadata":{"id":"GmUdtbjX6nMm"},"source":["<div style=\"line-height:0.1\">\n","<h4 style=\"color:#BF66F2 \">  Step #4 </h4>\n","</div>\n","<div style=\"line-height:1.2\">\n","Finally, call '.step()' method to initiate gradient descent. <br> \n","The optimizer adjusts each parameter by its gradient stored in '.grad'.\n","</div>"]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1689366523850,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"1CRtdS7t6o7K"},"outputs":[],"source":["\"\"\" Compute the gradient descent.\n","N.B.\n","All optimizers implement a step() method, that updates the parameters.\n","\"\"\"\n","op = optim.step() \n","op"]},{"cell_type":"markdown","metadata":{},"source":["<h2 style=\"color:#BF66F2 \"> <u> Example 2 </u> </h2>"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1689366523851,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"3oPqMQjg63kU"},"outputs":[],"source":["# Create two new tensors \n","a = torch.tensor([2., 3.], requires_grad=True)\n","b = torch.tensor([6., 4.], requires_grad=True)"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1689366524850,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"zyogFamE9EoL","outputId":"23018c54-57bb-4a97-de77-4de1f3cace08"},"outputs":[{"data":{"text/plain":["tensor([-12.,  65.], grad_fn=<SubBackward0>)"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["# Create tensor Q from a and b.\n","Q = 3*a**3 - b**2\n","Q"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1689366525883,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"MqGXutwA9hwW","outputId":"86512445-054a-4945-a24d-53cda085539d"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([True, True])\n","tensor([True, True])\n"]}],"source":["\"\"\" Find the gradients.\n","N.B.\n","The gradient corresponds to a tensor of the same shape as Q.\n","\"\"\"\n","external_grad = torch.tensor([1., 1.])\n","Q.backward(gradient=external_grad)\n","\n","# Check if collected gradients are correct\n","print(9*a**2 == a.grad)\n","print(-2*b == b.grad)"]},{"cell_type":"markdown","metadata":{"id":"Y30PWaSj_cbr"},"source":["**Recap:** <br>\n","Torch.autograd is an engine for computing vector-Jacobian. <br>\n","It tracks operations on all tensors which have their requires_grad flag set to True. <br>\n","The output tensor of an operation will require gradients even if only a single input tensor has requires_grad=True. <br>\n","\n","For tensors that don’t require gradients, setting this attribute to False excludes it from the gradient computation DAG. <br>\n","In a NN, parameters that don’t compute gradients are usually called frozen parameters. <br>\n","It is useful to “freeze” part of your model if you know in advance that you won’t need the gradients of those parameters. <br>"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1689366534960,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"AhpWEd9SAtG3","outputId":"3085745e-b18b-4948-94bf-beb6b0c51f94"},"outputs":[{"name":"stdout","output_type":"stream","text":["Does 'a' require gradients? : False\n","Does 'b' require gradients?: True\n"]}],"source":["# Set requires_grad\n","x = torch.rand(5, 5)\n","y = torch.rand(5, 5)\n","z = torch.rand((5, 5), requires_grad=True)\n","\n","a = x + y\n","print(f\"Does 'a' require gradients? : {a.requires_grad}\")\n","b = x + z\n","print(f\"Does 'b' require gradients?: {b.requires_grad}\")"]},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1689366534961,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"1C4rdcd5BFMP"},"outputs":[],"source":["## Freeze all the parameters in the network\n","for param in model.parameters():\n","    param.requires_grad = False"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1689366535961,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"xMmraitHA0Du","outputId":"c4c028c7-2834-4902-e4a3-fd72d8f91c06"},"outputs":[{"data":{"text/plain":["Linear(in_features=512, out_features=10, bias=True)"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\" Replace the last linear layer model.fc. (the ResNet classifier) with a new linear layer (unfrozen by default) \n","that acts as our classifier.\n","In order to finetune the model on a new dataset with 10 labels.\n","\"\"\"\n","model.fc = torch.nn.Linear(512, 10)\n","model.fc"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":482,"status":"ok","timestamp":1689366572018,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"BRoEGvDfB0h-","outputId":"05b2f9fd-51ce-42a0-f2b4-705158dfb979"},"outputs":[{"data":{"text/plain":["SGD (\n","Parameter Group 0\n","    dampening: 0\n","    differentiable: False\n","    foreach: None\n","    lr: 0.01\n","    maximize: False\n","    momentum: 0.9\n","    nesterov: False\n","    weight_decay: 0\n",")"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\" Stochastic Gradient Descent \"\"\"\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n","optimizer"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1689366573113,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"WaTp0kReIaLS","outputId":"1985d83b-f899-4354-c718-713e74dcea38"},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","True\n","True\n","False\n"]}],"source":["x = torch.randn(5, requires_grad=True)\n","y = x.pow(2)\n","z = x.exp()\n","print(x.equal(y.grad_fn._saved_self))\n","print(x is y.grad_fn._saved_self)\n","print(z.equal(z.grad_fn._saved_result))\n","print(z is z.grad_fn._saved_result)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNLupuayfQnT5n4fY2lM8+2","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
