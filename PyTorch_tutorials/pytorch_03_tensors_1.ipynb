{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"line-height:0.5\">\n",
    "<h1 style=\"color:#BF66F2 \">  Tensors in PyTorch 1 </h1>\n",
    "<h4> Reshaping, Striding, and Manipulating tensors. </h4> \n",
    "<div style=\"margin-top: 4px;\">\n",
    "<span style=\"display: inline-block;\">\n",
    "    <h3 style=\"color: lightblue; display: inline;\">Keywords:</h3>\n",
    "    %%time magic command + torch.optim + torch.multiply + torch.randn + warnings.simplefilter(\"ignore\")\n",
    "</span>\n",
    "</div>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.9\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.8393e+25])\n",
      "tensor([-4.3735e-07,  4.5843e-41,  7.8338e-35])\n",
      "tensor([[1, 0, 0, 0, 0],\n",
      "        [0, 2, 0, 0, 0],\n",
      "        [0, 0, 3, 0, 0],\n",
      "        [0, 0, 0, 4, 0],\n",
      "        [0, 0, 0, 0, 5]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([1, 3, 5, 7])\n",
      "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Create empty tensors => x = torch.empty#(size of dimensions) \"\"\"\n",
    "x = torch.empty(1)\n",
    "y = torch.empty(3)\n",
    "z = torch.empty(2,3,4,5,2)  \n",
    "q = torch.ones(2,2, dtype=torch.int16)\n",
    "s = torch.diag(torch.tensor([1,2,3,4,5]))\n",
    "e = torch.eye(3)\n",
    "a = torch.arange(1, 8, 2)\n",
    "l = torch.linspace(0, 1, 5)\n",
    "print(x)\n",
    "print(y)\n",
    "#print(z)\n",
    "print(s)\n",
    "print(e)\n",
    "print(a)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5000, 0.0000], dtype=torch.float16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0)\n",
    "ten = torch.tensor([2.5, 0], dtype=torch.float16) \n",
    "ten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ten_num array = tensor([2, 3, 4, 5, 6])\n",
      "[2 3 4 5 6]\n",
      "tensor([2.5000, 0.0000], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# 1) From Numpy array\n",
    "arra = np.array([1, 2, 3, 4, 5])\n",
    "ten_num = torch.from_numpy(arra) #also ten_num change!! \n",
    "xx = ten_num\n",
    "x_np = xx.numpy()\n",
    "arra += 1\n",
    "\n",
    "print(f\"ten_num array = {ten_num}\")\n",
    "print(x_np) #also this change!\n",
    "print(ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xdf = tensor([[1, 3, 5],\n",
      "        [2, 4, 6]])\n"
     ]
    }
   ],
   "source": [
    "# 2) From Pandas dataframe\n",
    "df = pd.DataFrame({'A': [1, 2], 'B': [3, 4], 'C': [5, 6]})\n",
    "xdf = torch.tensor(df.values)\n",
    "print(f\"xdf = {xdf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xl = tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# 3) From a list of lists:\n",
    "x_list = [[1, 2, 3], [4, 5, 6]]\n",
    "xl = torch.tensor(x_list)\n",
    "print(f\"xl = {xl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rx = tensor([[-1.4989,  1.3164, -1.8248],\n",
      "        [ 1.0753, -0.7757, -0.3708]])\n"
     ]
    }
   ],
   "source": [
    "# 4) Randomly generated tensor with a given shape:\n",
    "rx = torch.randn((2, 3))\n",
    "print(f\"rx = {rx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2293, 0.2179, 0.5171, 0.4198, 0.2406],\n",
      "        [0.1794, 0.5975, 0.0716, 0.4121, 0.9055],\n",
      "        [0.9797, 0.9055, 0.7710, 0.9138, 0.3979],\n",
      "        [0.3785, 0.2866, 0.2086, 0.0080, 0.6578]])\n",
      "2\n",
      "torch.Size([4, 5])\n",
      "(None, None)\n",
      "tensor([0.9797, 0.9055, 0.7710, 0.9138, 0.3979])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2293, 0.1794, 0.9797, 0.3785],\n",
       "        [0.2179, 0.5975, 0.9055, 0.2866],\n",
       "        [0.5171, 0.0716, 0.7710, 0.2086],\n",
       "        [0.4198, 0.4121, 0.9138, 0.0080],\n",
       "        [0.2406, 0.9055, 0.3979, 0.6578]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5)\n",
    "ranten = torch.rand(4, 5)\n",
    "print(ranten)\n",
    "print(ranten.ndim)\n",
    "print(ranten.shape)\n",
    "print(ranten.names)\n",
    "print(ranten[2])\n",
    "ra2 = ranten.transpose(0,1)\n",
    "ra2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0654, 0.0426, 0.4027, 0.4002, 0.9435],\n",
      "         [0.3784, 0.7279, 0.0553, 0.9930, 0.9732],\n",
      "         [0.2259, 0.6959, 0.8427, 0.2963, 0.4022]]])\n",
      "3\n",
      "torch.Size([1, 3, 5])\n",
      "(None, None, None)\n",
      "tensor([[0.0654, 0.0426, 0.4027, 0.4002, 0.9435],\n",
      "        [0.3784, 0.7279, 0.0553, 0.9930, 0.9732],\n",
      "        [0.2259, 0.6959, 0.8427, 0.2963, 0.4022]])\n"
     ]
    }
   ],
   "source": [
    "# 6) Rand\n",
    "ranten = torch.rand(1, 3, 5)\n",
    "print(ranten)\n",
    "print(ranten.ndim)\n",
    "print(ranten.shape)\n",
    "print(ranten.names)\n",
    "print(ranten[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "tensor([[[0.7595, 0.8329, 0.2097,  ..., 0.8284, 0.4403, 0.5561],\n",
      "         [0.4182, 0.9320, 0.7243,  ..., 0.6176, 0.0155, 0.1564],\n",
      "         [0.4568, 0.0991, 0.2384,  ..., 0.5284, 0.7979, 0.9997],\n",
      "         ...,\n",
      "         [0.6376, 0.2030, 0.3721,  ..., 0.9531, 0.8573, 0.9872],\n",
      "         [0.2176, 0.6084, 0.8702,  ..., 0.9452, 0.4859, 0.3221],\n",
      "         [0.2888, 0.5912, 0.7806,  ..., 0.4225, 0.7269, 0.1247]]])\n",
      "torch.float32\n",
      "cpu\n",
      "150528\n"
     ]
    }
   ],
   "source": [
    "# 7)\n",
    "ra1 = torch.rand(1, 3, 224, 224)\n",
    "print()\n",
    "print(ra1.ndim)\n",
    "print(ra1.shape)\n",
    "print(ra1.size())       # same as shape\n",
    "print(ra1[:, 1])\n",
    "print(ra1.dtype)\n",
    "print(ra1.device)       # total number of elements in the tensor.\n",
    "print(ra1.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.8773, 0.4463, 0.6021,  ..., 0.6001, 0.3332, 0.0326],\n",
       "          [0.0520, 0.8049, 0.1437,  ..., 0.2140, 0.8957, 0.7976],\n",
       "          [0.1086, 0.9595, 0.0905,  ..., 0.7239, 0.6051, 0.1180],\n",
       "          ...,\n",
       "          [0.8789, 0.2816, 0.7663,  ..., 0.2017, 0.7507, 0.3057],\n",
       "          [0.1852, 0.7399, 0.7758,  ..., 0.0053, 0.9536, 0.8370],\n",
       "          [0.2895, 0.1455, 0.0787,  ..., 0.4001, 0.3740, 0.3242]],\n",
       "\n",
       "         [[0.7595, 0.8329, 0.2097,  ..., 0.8284, 0.4403, 0.5561],\n",
       "          [0.4182, 0.9320, 0.7243,  ..., 0.6176, 0.0155, 0.1564],\n",
       "          [0.4568, 0.0991, 0.2384,  ..., 0.5284, 0.7979, 0.9997],\n",
       "          ...,\n",
       "          [0.6376, 0.2030, 0.3721,  ..., 0.9531, 0.8573, 0.9872],\n",
       "          [0.2176, 0.6084, 0.8702,  ..., 0.9452, 0.4859, 0.3221],\n",
       "          [0.2888, 0.5912, 0.7806,  ..., 0.4225, 0.7269, 0.1247]],\n",
       "\n",
       "         [[0.5388, 0.0149, 0.8761,  ..., 0.0285, 0.4097, 0.9484],\n",
       "          [0.6749, 0.0577, 0.0962,  ..., 0.0225, 0.5456, 0.2823],\n",
       "          [0.1371, 0.4029, 0.1710,  ..., 0.8169, 0.5310, 0.7785],\n",
       "          ...,\n",
       "          [0.2385, 0.3466, 0.4282,  ..., 0.6504, 0.3170, 0.9873],\n",
       "          [0.5157, 0.5374, 0.3236,  ..., 0.4636, 0.7283, 0.0389],\n",
       "          [0.7887, 0.5461, 0.1341,  ..., 0.2363, 0.2514, 0.1137]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8) Copy tensors #1\n",
    "\"\"\" \n",
    "N.B.\n",
    "- 'yy = ra1' => 'yy' and 'ra1' refer to the same tensor object in memory. \n",
    "Callling 'yy.add(1)' means to generate a new tensor with the values of ra1 incremented by 1, \n",
    "but without modify 'ra1' or yy in-place. Use ra1.add_(1) to modify 'ra1' in-place\n",
    "\"\"\"\n",
    "yy = ra1\n",
    "yy.add(1)\n",
    "ra1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "torch.Size([3, 8])\n",
      "torch.Size([2, 3, 4])\n",
      "torch.Size([4, 3, 2])\n",
      "\n",
      "tensor([[[ 1.5979,  0.8161,  0.0935,  0.2026],\n",
      "         [ 0.5049,  0.5279, -0.4712,  1.1922],\n",
      "         [ 0.6317,  0.1504,  0.5426,  0.8935]],\n",
      "\n",
      "        [[ 0.3370, -0.3175,  2.1700,  0.4758],\n",
      "         [ 0.4339, -0.4590,  0.0279,  0.1146],\n",
      "         [ 0.3633,  0.4099,  0.7050,  1.3141]]])\n",
      "\n",
      "tensor([[[ 1.5979,  0.3370],\n",
      "         [ 0.5049,  0.4339],\n",
      "         [ 0.6317,  0.3633]],\n",
      "\n",
      "        [[ 0.8161, -0.3175],\n",
      "         [ 0.5279, -0.4590],\n",
      "         [ 0.1504,  0.4099]],\n",
      "\n",
      "        [[ 0.0935,  2.1700],\n",
      "         [-0.4712,  0.0279],\n",
      "         [ 0.5426,  0.7050]],\n",
      "\n",
      "        [[ 0.2026,  0.4758],\n",
      "         [ 1.1922,  0.1146],\n",
      "         [ 0.8935,  1.3141]]])\n"
     ]
    }
   ],
   "source": [
    "# 9) Copy tensors #2 => Views\n",
    "x1 = torch.randn(2, 3, 4)\n",
    "\n",
    "# Reshape the tensor to have shape (3, 8)\n",
    "y1 = x1.view(3, 8) \n",
    "print(x1.shape)\n",
    "print(y1.shape)\n",
    "y2 = x1.transpose(0, 2)\n",
    "print(x1.shape)\n",
    "print(y2.shape) \n",
    "print()\n",
    "print(x1)\n",
    "print()\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "tensor([[[ 1.5979,  0.8161,  0.0935,  0.2026],\n",
      "         [ 0.5049,  0.5279, -0.4712,  1.1922],\n",
      "         [ 0.6317,  0.1504,  0.5426,  0.8935]],\n",
      "\n",
      "        [[ 0.3370, -0.3175,  2.1700,  0.4758],\n",
      "         [ 0.4339, -0.4590,  0.0279,  0.1146],\n",
      "         [ 0.3633,  0.4099,  0.7050,  1.3141]]])\n",
      "\n",
      "tensor([[ 1.5979,  0.8161,  0.0935,  0.2026],\n",
      "        [ 0.5049,  0.5279, -0.4712,  1.1922],\n",
      "        [ 0.6317,  0.1504,  0.5426,  0.8935],\n",
      "        [ 0.3370, -0.3175,  2.1700,  0.4758],\n",
      "        [ 0.4339, -0.4590,  0.0279,  0.1146],\n",
      "        [ 0.3633,  0.4099,  0.7050,  1.3141]])\n",
      "torch.Size([6, 4])\n"
     ]
    }
   ],
   "source": [
    "# 10) Reshape the tensor to have shape (6, 4)\n",
    "y3 = x1.reshape(6, 4) \n",
    "print(x1.shape)\n",
    "print(x1)\n",
    "print()\n",
    "print(y3)\n",
    "print(y3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.3790, -0.5328,  0.7471, -0.9571]],\n",
      "\n",
      "         [[-0.5873, -0.6424, -0.3490, -1.2817]],\n",
      "\n",
      "         [[-0.0945, -0.7134,  0.8987, -0.8470]]]])\n",
      "torch.Size([1, 3, 1, 4])\n",
      "tensor([[ 1.3790, -0.5328,  0.7471, -0.9571],\n",
      "        [-0.5873, -0.6424, -0.3490, -1.2817],\n",
      "        [-0.0945, -0.7134,  0.8987, -0.8470]])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 11) Remove dimensions of size 1 from the tensor.\n",
    "x2 = torch.randn(1, 3, 1, 4) \n",
    "y4 = x2.squeeze()\n",
    "print(x2)\n",
    "print(x2.shape)\n",
    "print(y4)\n",
    "print(y4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8041, -1.1978, -0.8636, -0.7963],\n",
      "        [ 0.6860,  1.8731, -0.4374, -0.0574],\n",
      "        [ 0.1817, -0.2148,  0.0285,  1.6633]])\n",
      "torch.Size([3, 4])\n",
      "tensor([[[[ 0.8041, -1.1978, -0.8636, -0.7963]],\n",
      "\n",
      "         [[ 0.6860,  1.8731, -0.4374, -0.0574]],\n",
      "\n",
      "         [[ 0.1817, -0.2148,  0.0285,  1.6633]]]])\n",
      "torch.Size([1, 3, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "# 12) Add dimensions of size 1 to the tensor for 0 and 2 position\n",
    "x3 = torch.randn(3, 4)\n",
    "y5 = x3.unsqueeze(0).unsqueeze(2) \n",
    "print(x3)\n",
    "print(x3.shape)\n",
    "print(y5)\n",
    "print(y5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.8773, 1.4463, 1.6021,  ..., 1.6001, 1.3332, 1.0326],\n",
       "          [1.0520, 1.8049, 1.1437,  ..., 1.2140, 1.8957, 1.7976],\n",
       "          [1.1086, 1.9595, 1.0905,  ..., 1.7239, 1.6051, 1.1180],\n",
       "          ...,\n",
       "          [1.8789, 1.2816, 1.7663,  ..., 1.2017, 1.7507, 1.3057],\n",
       "          [1.1852, 1.7399, 1.7758,  ..., 1.0053, 1.9536, 1.8370],\n",
       "          [1.2895, 1.1455, 1.0787,  ..., 1.4001, 1.3740, 1.3242]],\n",
       "\n",
       "         [[1.7595, 1.8329, 1.2097,  ..., 1.8284, 1.4403, 1.5561],\n",
       "          [1.4182, 1.9320, 1.7243,  ..., 1.6176, 1.0155, 1.1564],\n",
       "          [1.4568, 1.0991, 1.2384,  ..., 1.5284, 1.7979, 1.9997],\n",
       "          ...,\n",
       "          [1.6376, 1.2030, 1.3721,  ..., 1.9531, 1.8573, 1.9872],\n",
       "          [1.2176, 1.6084, 1.8702,  ..., 1.9452, 1.4859, 1.3221],\n",
       "          [1.2888, 1.5912, 1.7806,  ..., 1.4225, 1.7269, 1.1247]],\n",
       "\n",
       "         [[1.5388, 1.0149, 1.8761,  ..., 1.0285, 1.4097, 1.9484],\n",
       "          [1.6749, 1.0577, 1.0962,  ..., 1.0225, 1.5456, 1.2823],\n",
       "          [1.1371, 1.4029, 1.1710,  ..., 1.8169, 1.5310, 1.7785],\n",
       "          ...,\n",
       "          [1.2385, 1.3466, 1.4282,  ..., 1.6504, 1.3170, 1.9873],\n",
       "          [1.5157, 1.5374, 1.3236,  ..., 1.4636, 1.7283, 1.0389],\n",
       "          [1.7887, 1.5461, 1.1341,  ..., 1.2363, 1.2514, 1.1137]]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy.add_(1)  #also the original tensor change!\n",
    "yy\n",
    "ra1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.8773, 1.4463, 1.6021,  ..., 1.6001, 1.3332, 1.0326],\n",
       "          [1.0520, 1.8049, 1.1437,  ..., 1.2140, 1.8957, 1.7976],\n",
       "          [1.1086, 1.9595, 1.0905,  ..., 1.7239, 1.6051, 1.1180],\n",
       "          ...,\n",
       "          [1.8789, 1.2816, 1.7663,  ..., 1.2017, 1.7507, 1.3057],\n",
       "          [1.1852, 1.7399, 1.7758,  ..., 1.0053, 1.9536, 1.8370],\n",
       "          [1.2895, 1.1455, 1.0787,  ..., 1.4001, 1.3740, 1.3242]],\n",
       "\n",
       "         [[1.7595, 1.8329, 1.2097,  ..., 1.8284, 1.4403, 1.5561],\n",
       "          [1.4182, 1.9320, 1.7243,  ..., 1.6176, 1.0155, 1.1564],\n",
       "          [1.4568, 1.0991, 1.2384,  ..., 1.5284, 1.7979, 1.9997],\n",
       "          ...,\n",
       "          [1.6376, 1.2030, 1.3721,  ..., 1.9531, 1.8573, 1.9872],\n",
       "          [1.2176, 1.6084, 1.8702,  ..., 1.9452, 1.4859, 1.3221],\n",
       "          [1.2888, 1.5912, 1.7806,  ..., 1.4225, 1.7269, 1.1247]],\n",
       "\n",
       "         [[1.5388, 1.0149, 1.8761,  ..., 1.0285, 1.4097, 1.9484],\n",
       "          [1.6749, 1.0577, 1.0962,  ..., 1.0225, 1.5456, 1.2823],\n",
       "          [1.1371, 1.4029, 1.1710,  ..., 1.8169, 1.5310, 1.7785],\n",
       "          ...,\n",
       "          [1.2385, 1.3466, 1.4282,  ..., 1.6504, 1.3170, 1.9873],\n",
       "          [1.5157, 1.5374, 1.3236,  ..., 1.4636, 1.7283, 1.0389],\n",
       "          [1.7887, 1.5461, 1.1341,  ..., 1.2363, 1.2514, 1.1137]]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 13) Create tensor with same data as ra1, but with its own memory not a shared one!\n",
    "z = ra1.clone()\n",
    "z[0, 0, 0, 0] = 7.0\n",
    "ra1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# 14) Create a random tensor with a similar shape to an image tensor\n",
    "rand_image_tensor = torch.rand(size=(3, 224, 224))    #(height, widht, colour channels)\n",
    "print(rand_image_tensor.ndim)\n",
    "print(rand_image_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0.8350, 0.8575, 0.5386, 0.4283, 0.1917, 0.5022, 0.8101, 0.7854, 0.7712,\n",
      "        0.4309])\n",
      "stride of c_tens is (1,)\n"
     ]
    }
   ],
   "source": [
    "# 15)\n",
    "\"\"\" Create a range of tensors and tensors-like.\n",
    "N.B\n",
    "Do not use 'a_tens = torch.range(0,10)' since 'torch.range' is deprecated !\n",
    "\"\"\"\n",
    "a_tens = torch.arange(0.0 ,10.0)\n",
    "b_tens = torch.zeros_like(a_tens)\n",
    "c_tens = torch.rand_like(a_tens)\n",
    "print(a_tens)\n",
    "print(b_tens)\n",
    "print(c_tens)\n",
    "print(f'stride of c_tens is {c_tens.stride()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#BF66F2 \"> Recap: Stride </h3>\n",
    "<div style=\"margin-top: -8px;\">\n",
    "The stride of a tensor is a tuple of integers that specifies the number of elements to step in each dimension when traversing the tensor. <br>\n",
    "It represents the number of bytes between adjacent elements in memory for each dimension of the tensor.\n",
    "\n",
    "**Example:** <br>\n",
    "Consider a PyTorch tensor x with shape (13, 4124, 545, 6546, 123). <br>\n",
    "The stride of x can be calculated as follows: <br>\n",
    "1) The stride for the last (innermost) dimension is always 1. <br>\n",
    "This is because elements along the innermost dimension are stored contiguously in memory, so the stride between adjacent elements <br> is simply the size of one element, which is 1. <br>\n",
    "2) For the fourth dimension, the stride is the number of elements between adjacent elements along that dimension. <br>\n",
    "In this case, x has 6546 elements along the fourth dimension, so the stride along that dimension is 123 * 1 = 123.\n",
    "3) For the third dimension, the stride is the number of elements between adjacent elements along that dimension. <br>\n",
    "In this case, x has 545 elements along the third dimension, and each block of 6546 elements along the fourth dimension is 123 elements apart, <br> so the stride along the third dimension is 6546 * 123 = 804858. <br>\n",
    "4) For the second dimension, the stride is the number of elements between adjacent elements along that dimension. <br>\n",
    "In this case, x has 4124 elements along the second dimension, and each block of 545 elements along the third dimension is 804858 elements apart, <br> so the stride along the second dimension is 545 * 804858 = 438829190.\n",
    "5) For the first (outermost) dimension, the stride is the number of elements between adjacent elements along that dimension. <br>\n",
    "In this case, x has 13 elements along the first dimension, and each block of 4124 elements along the second dimension is 438829190 elements apart, <br> so the stride along the first dimension is 4124 * 438829190 = 1.806e+12. <br>\n",
    "\n",
    "Hence, the STRIDE of x is: (1, 123, 804858, 438829190, 180598125960)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stride: (3, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Here the tensor has 2 dimentions. size (2,3)\n",
    "The first (outermost) dimension has size 2 and the second (innermost) dimension has size 3.\n",
    "The stride for the last (innermost) dimension of a PyTorch tensor is always 1, regardless of the size of the other dimensions. \n",
    "This is because adjacent elements in memory along the innermost dimension are stored contiguously, \n",
    "so the stride between them is simply the size of one element.\n",
    "\"\"\"\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "stride = x.stride()\n",
    "print(\"stride:\", stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7273, 1.3169, 0.2948], requires_grad=True)\n",
      "tensor([[[[ 0.6988, -0.2432],\n",
      "          [-1.1648, -2.7377],\n",
      "          [ 0.6026, -2.1569],\n",
      "          [-0.2726,  0.1849]],\n",
      "\n",
      "         [[ 0.5109,  0.2411],\n",
      "          [-0.5887, -1.4085],\n",
      "          [ 0.5020,  0.4002],\n",
      "          [-0.6306,  1.0168]],\n",
      "\n",
      "         [[-0.5062,  1.0458],\n",
      "          [ 1.1618,  0.5608],\n",
      "          [-0.3831,  0.0402],\n",
      "          [-0.1679,  0.6867]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Create random tensors with values drawn from a normal distribution. \"\"\"\n",
    "x1 = torch.randn(3, requires_grad=True) \n",
    "x = torch.randn(1, 3, 4, 2, requires_grad=True) \n",
    "y = x + 2\n",
    "z = y*y*2\n",
    "\n",
    "z = z.mean(dim=(0, 1, 2, 3))\n",
    "print(x1)\n",
    "print(x)\n",
    "#print(y)\n",
    "#print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape from dim 1 to dim 2\n",
    "d_tens = torch.reshape(c_tens,(2,5)) \n",
    "d_tens.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([41., 63., 19.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Crete a tensors with specific type [float 32]. \"\"\"\n",
    "fl32_tens = torch.tensor([41.0, 63.0, 19.0],\n",
    "                        #dtype=torch.float16,\n",
    "                        #dtype=torch.float32,\n",
    "                        #dtype=torch.float64,\n",
    "                        dtype=torch.float,          # corresponds to => torch.float32\n",
    "                        #dtype=float,               # corresponds to => torch.float64 == torch.double\n",
    "                        device=None, \n",
    "                        requires_grad=False\n",
    "                        )\n",
    "fl32_tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int32\n",
      "tensor([ 41., 126.,  57.])\n",
      "Shape of tensor: torch.Size([3])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "int16_tens = torch.tensor([1,2,3], dtype=torch.int16)\n",
    "int32_tens = torch.tensor([1,2,3], dtype=torch.int32)\n",
    "res = int32_tens * int16_tens\n",
    "print(res.dtype)\n",
    "res1 = int16_tens * fl32_tens\n",
    "print(res1)\n",
    "print(f\"Shape of tensor: {res1.shape}\")\n",
    "print(f\"Datatype of tensor: {res1.dtype}\")\n",
    "print(f\"Device tensor is stored on: {res1.device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#BF66F2 \">  Tensor manipulations </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3., 4.])\n",
      "tensor([1, 2, 3])\n",
      "tensor([1., 1., 2.])\n",
      "tensor([ 2.,  6., 12.])\n",
      "tensor([ 2.,  6., 12.])\n",
      "tensor([ 20.,  60., 120.])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Operations on tensors.\n",
    "N.B. \n",
    "Tensors don't change unless reassigned!  \n",
    "Doing ten + 10 ... ten * 10  does not modify the tensor.\"\"\"\n",
    "tensor_mani = torch.tensor([1, 2, 3])\n",
    "tensor_mani2 = torch.tensor([1, 2, 3])\n",
    "tensor_mani = tensor_mani + 3 \n",
    "tensor_mani = tensor_mani * 2\n",
    "tensor_mani = tensor_mani - 4\n",
    "tensor_mani = tensor_mani / 2\n",
    "tensor_mani3 = tensor_mani // 2\n",
    "tensor_mani4 = tensor_mani * tensor_mani2\n",
    "print(tensor_mani)\n",
    "print(tensor_mani2)\n",
    "print(tensor_mani3)\n",
    "print(tensor_mani4)\n",
    "\n",
    "# Try a torch function\n",
    "te5 = torch.multiply(tensor_mani4, 10) \n",
    "print(tensor_mani4)\n",
    "print(te5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3., 4.]) tensor(20.) tensor(60.) tensor(120.)\n",
      "tensor([1, 2, 3])\n",
      "mat_tensor.shape is \"torch.Size([3])\"\n",
      "tensor([1, 4, 9])\n",
      "\n",
      "tensor(14)\n",
      "tensor(14)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Multiplication\n",
    "- Element-wise multiplication\t[1*1, 2*2, 3*3] = [1, 4, 9]\ttensor * tensor\n",
    "- Matrix multiplication\t[1*1 + 2*2 + 3*3] = [14]\ttensor.matmul(tensor)\n",
    "\"\"\"\n",
    "# Element-wise multiplication (each element multiplies its equivalent, index 0->0, 1->1, 2->2)\n",
    "mat_tensor = torch.tensor([1, 2, 3])\n",
    "print(tensor_mani, * te5)\n",
    "print(mat_tensor)\n",
    "print(f\"mat_tensor.shape is \\\"{mat_tensor.shape}\\\"\")\n",
    "mat_mat = mat_tensor * mat_tensor\n",
    "print(mat_mat)\n",
    "print()\n",
    "# Matrix multiplication 1\n",
    "print(torch.matmul(mat_tensor, mat_tensor)) \n",
    "# Matrix multiplication 2 using \"@\" symbol (though not recommended) \n",
    "print(mat_tensor @ mat_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.32 ms, sys: 153 µs, total: 1.47 ms\n",
      "Wall time: 3.49 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\" Matrix multiplication by hand.\n",
    "N.B.\n",
    "It is always not recommended doing operations with 'for' statements, when not strictly necessary, \\\\\n",
    "since loops are computationally expensive \"\"\"\n",
    "value = 0\n",
    "for i in range(len(mat_tensor)):\n",
    "  value += mat_tensor[i] * mat_tensor[i]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 421 µs, sys: 49 µs, total: 470 µs\n",
      "Wall time: 492 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\" Matrix multiplication wiht matmul. \"\"\"\n",
    "torch.matmul(mat_tensor, mat_tensor)    # faster!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "\n",
      "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
      "\n",
      "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
      "\n",
      "Output:\n",
      "\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Shape calculation common error. \n",
    "- The 'matmul' operation works when tensor_B is transposed => torch.matmul(tensor_A, tensor_B will return error\n",
    "\"\"\"\n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                        [3, 4],\n",
    "                        [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                        [8, 11], \n",
    "                        [9, 12]], dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
    "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
    "print(\"Output:\\n\")\n",
    "\n",
    "### Multiplicate (mm = a shortcut for matmul)\n",
    "output = torch.mm(tensor_A, tensor_B.T)         \n",
    "# or ...\n",
    "#output = torch.matmul(tensor_A, tensor_B.T)   \n",
    "\n",
    "print(output) \n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "\n",
      "Output:\n",
      "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
      "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
      "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Create tensor for a Neural Network.\n",
    "# Since the linear layer always starts with a random weights matrix, let's make it reproducible using matrix multiplication.\n",
    "\"\"\" \n",
    "# Allow reproducibility\n",
    "torch.manual_seed(42) \n",
    "\n",
    "linear = torch.nn.Linear(in_features=2,     # in_features = matches inner dimension of input \n",
    "                        out_features=6)     # out_features = describes outer value \n",
    "x = tensor_A\n",
    "output = linear(x)\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Minimum: 0\n",
      "Maximum: 90\n",
      "Mean: 45.0\n",
      "Sum: 450\n",
      "CPU times: user 2.41 ms, sys: 282 µs, total: 2.69 ms\n",
      "Wall time: 12.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\" Max min sum ...\n",
    "N.B.\n",
    "'print(f\"Mean: {x_ten.mean()}\")' will return error without the datatype must be specified!\n",
    "\"\"\"\n",
    "x_ten = torch.arange(0, 100, 10)\n",
    "print(x_ten)\n",
    "print(f\"Minimum: {x_ten.min()}\")\n",
    "print(f\"Maximum: {x_ten.max()}\")\n",
    "print(f\"Mean: {x_ten.type(torch.float32).mean()}\")\n",
    "print(f\"Sum: {x_ten.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Minimum: 0\n",
      "Maximum: 90\n",
      "Mean: 45.0\n",
      "Sum: 450\n",
      "CPU times: user 2.73 ms, sys: 0 ns, total: 2.73 ms\n",
      "Wall time: 2.55 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_ten = torch.arange(0, 100, 10)\n",
    "torch.max(x_ten), torch.min(x_ten), torch.mean(x_ten.type(torch.float32)), torch.sum(x_ten)\n",
    "print(x_ten)\n",
    "print(f\"Minimum: {x_ten.min()}\")\n",
    "print(f\"Maximum: {x_ten.max()}\")\n",
    "print(f\"Mean: {x_ten.type(torch.float32).mean()}\")\n",
    "print(f\"Sum: {x_ten.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### => Passing a tensor to \"backward()\" as an argument.\n",
    "\n",
    "The tensor should be a scalar tensor (i.e., a tensor with only one element) that represents the \"sensitivity\" of the loss <br>\n",
    "with respect to the output tensor. <br>\n",
    "The scalar tensor is used to scale the gradients during backpropagation, and it is multiplied with each element <br> of the gradient tensor \n",
    "to compute the final gradient. <br>\n",
    "(Default value when no argument is passed to backward is 1.0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" N.B. \n",
    "- v = torch.tensor([0.1,1.0,0.01], dtype=torch.float32) lead to  \"RuntimeError: Mismatch in shape!\" \"\"\"\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    v = torch.tensor([0.1], dtype=torch.float32)\n",
    "    v = torch.tensor(0.1, dtype=torch.float32)\n",
    "    z.backward(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.5880, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 4, 2, requires_grad=True)\n",
    "y = x + 2\n",
    "z = y * y * 2\n",
    "z = z.mean(dim=(0, 1, 2, 3))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[3.4918e-34, 0.0000e+00],\n",
       "          [2.7511e-34, 0.0000e+00],\n",
       "          [8.9683e-44, 0.0000e+00],\n",
       "          [2.6905e-43, 0.0000e+00]],\n",
       "\n",
       "         [[3.5958e-34, 0.0000e+00],\n",
       "          [1.8777e-43, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00, 0.0000e+00],\n",
       "          [7.7052e+31, 7.2148e+22],\n",
       "          [1.5766e-19, 1.0256e-08],\n",
       "          [1.6802e-04, 3.0270e+12]]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Create a scalar tensor to scale the gradients. \n",
    "N.B.\n",
    "- 'sensitivity = torch.tensor([0.1], dtype=torch.float32' => not working: Missmatch in shape error!\n",
    "\"\"\"\n",
    "sensitivitys = torch.ones(x.size())\n",
    "sensitivityo = torch.ones_like(x)\n",
    "sensitivitye = torch.empty_like(x)\n",
    "\n",
    "# Compute the gradients of x with respect to z, scaled by the sensitivity tensor\n",
    "x.backward(sensitivitye)\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.],\n",
      "        [7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with the same shape as x but with different values\n",
    "v_vals = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "v = torch.tensor(v_vals, dtype=torch.float32)\n",
    "print(v)\n",
    "\n",
    "if x.size()==v.size(): #callable\n",
    "    print(\"x and v => same size\")\n",
    "if x.shape==v.shape:\n",
    "    print(\"x and v => same shape\")    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if v is a 4-dimensional tensor with shape (2, 3, 4, 5), the following slice expressions would produce tensors with different numbers of dimensions:\n",
    "\n",
    "- v[0]: selects the first batch of data, resulting in a 3-dimensional tensor with shape (3, 4, 5) \\\n",
    "- v[:, 1]: selects the second row of data in all batches, resulting in a 3-dimensional tensor with shape (2, 4, 5) \\\n",
    "- v[0, 1, 2]: selects a single element of the tensor, resulting in a 0-dimensional scalar tensor \\\n",
    "- v[0, :, 1, :]: selects the second column of the second row in the first batch, resulting in a 2-dimensional tensor with shape (4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x and v have different sizes\n",
      "x and v have different shapes\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 4, 2, requires_grad=True)\n",
    "v_vals = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "v = torch.tensor(v_vals, dtype=torch.float32)\n",
    "\n",
    "if x.size() == v.size():\n",
    "    print(\"x and v have the same size\")\n",
    "else:\n",
    "    print(\"x and v have different sizes\")\n",
    "\n",
    "if x.shape == v.shape:\n",
    "    print(\"x and v have the same shape\")\n",
    "else:\n",
    "    print(\"x and v have different shapes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 2.],\n",
       "          [3., 4.],\n",
       "          [5., 6.],\n",
       "          [7., 8.]],\n",
       "\n",
       "         [[1., 2.],\n",
       "          [3., 4.],\n",
       "          [5., 6.],\n",
       "          [7., 8.]],\n",
       "\n",
       "         [[1., 2.],\n",
       "          [3., 4.],\n",
       "          [5., 6.],\n",
       "          [7., 8.]]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" The slice v[0, :, :, :] corresponds to all elements of v in the first dimension (batch size), \n",
    "all elements of v in the remaining three dimensions. \n",
    "v[0, :, :, :] is a 3D tensor that has the same shape as the last three dimensions of v.\n",
    "The first dimension (index 0) is usually reserved for the batch size, and the remaining dimensions correspond to the shape of the data.\n",
    "\n",
    "\n",
    "array created by hands..with same shape as x\n",
    "values =    [[[[1., 2.], [3., 4.], [5., 6.], [7., 8.]], \n",
    "            [[11., 32.], [3., 43.], [53., 6.], [7., 81.]], \n",
    "            [[1.1, 2.], [3.3, 41.], [5.2, 62.], [7.1, 84.]]]]\n",
    "\"\"\"\n",
    "x = torch.randn(1, 3, 4, 2, requires_grad=True)\n",
    "\n",
    "# Create v with the same shape as x and manually specified values\n",
    "v = torch.empty_like(x)\n",
    "# Assign the values of a 4x2 NumPy array to a slice of the PyTorch tensor v\n",
    "v[0, :, :, :] = torch.tensor([[1, 2], [3, 4], [5, 6], [7, 8]]) \n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x and v have the same size\n",
      "x and v have the same shape\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of x and v\n",
    "if x.size() == v.size():\n",
    "    print(\"x and v have the same size\")\n",
    "else:\n",
    "    print(\"x and v have different sizes\")\n",
    "if x.shape == v.shape:\n",
    "    print(\"x and v have the same shape\")\n",
    "else:\n",
    "    print(\"x and v have different shapes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1.],\n",
      "          [1., 1.],\n",
      "          [1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.],\n",
      "          [1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.],\n",
      "          [1., 1.],\n",
      "          [1., 1.]]]])\n"
     ]
    }
   ],
   "source": [
    "#### Compute the gradients of x with respect to z, scaled by the sensitivity tensor\n",
    "z = x.sum()\n",
    "z.backward(torch.ones_like(z), retain_graph=True) #gradient descent dz/dx\n",
    "grad = x.grad \n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7860, 1.0060, 0.8448], requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tex = torch.randn(3, requires_grad=True)\n",
    "tex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tensor = tex.sum().backward()\n",
    "a_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7860, 1.0060, 0.8448])\n",
      "tensor([0.7860, 1.0060, 0.8448])\n",
      "tensor([2.7860, 3.0060, 2.8448])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" detach() method. \n",
    "It creates a new tensor yx1 that shares the same data as tex, but is not part of the computation graph \n",
    "and has requires_grad=False.\n",
    "\"\"\"\n",
    "tex.requires_grad_(False) #modify in place with underscore\n",
    "yx1 = tex.detach() # detached tensor \n",
    "print(yx1)\n",
    "print(tex)\n",
    "with torch.no_grad(): #computing a tensor yx2 inside a torch.no_grad() context\n",
    "    yx2 = tex + 2\n",
    "    print(yx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#BF66F2 \"> Recap: Stochastic Gradient Descent SGD </h2>\n",
    "<div style=\"margin-top: -8px;\">\n",
    "SGD is used to find the best set of parameters that minimize the loss function of a model during training to improve its overall performance. <br>\n",
    "\n",
    "Stochastic means that it uses randomly selected subsets or \"batch\" of the training data, rather than the full dataset. <br>\n",
    "Threfore, all processes of computing gradients, updating weights, and resetting gradients to zero is typically repeated multiple times <br> during training to optimize the model parameters. <br>\n",
    "E.G. => Between epochs i need to reset to avoid errors...<br>\n",
    "<div style=\"margin-top: -12px;\">\n",
    "\n",
    "- tensor([3., 3., 3., 3.]) <br>\n",
    "- tensor([6., 6., 6., 6.]) <br>\n",
    "- tensor([9., 9., 9., 9.]) <br>\n",
    "- tensor([12., 12., 12., 12.]) <br>\n",
    "\n",
    "An SGD optimizer updates the values of weights during training, trying to adjust the values of the model parameters based on the <br> gradients of the loss function, with respect to the parameters. <br>\n",
    "Its goal is to find the set of parameter values that minimize the loss function, which corresponds to the best fit of the model  <br>\n",
    "to the training data.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" SGD optimizer.\n",
    "N.B.1 \n",
    "1) Declaring the SGD => torch.optim.SGD(weights, lr=0.01) without brakets [...] lead to an error! \n",
    "    (weights is a tensor and not an iterable of tensors)\n",
    "N.B.2\n",
    "The 'step()' method updates the weights and then call the zero_grad() method to reset the gradients to zero.   \n",
    "\"\"\"\n",
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(4):\n",
    "    model_output = (weights * 3).sum(dim=0)\n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "\n",
    "    weights.grad.zero_() \n",
    "\n",
    "optimizer = torch.optim.SGD([weights], lr=0.01) \n",
    "# Update weights (model parameters) according to the gradients computed during backpropagation.\n",
    "optimizer.step() \n",
    "# Reset gradient\n",
    "optimizer.zero_grad() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Simple gradient descent with no bias involved. \"\"\"\n",
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "# Forward pass\n",
    "y_hat = w * x \n",
    "###Calculate Loss\n",
    "loss = (y_hat - y).pow(2) \n",
    "# or ...\n",
    "#loss = (y_hat - y)**2\n",
    "\n",
    "# Backward pass\n",
    "loss.backward() \n",
    "# Loss\n",
    "print(loss)\n",
    "# First gradient of w\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#BF66F2 \">  Recap: Scaling Tradeoff </h3>\n",
    "<div style=\"margin-top: -8px;\">\n",
    "Larger weights can lead to more complex models with higher capacity, but can also be more prone to overfitting and require more careful regularization.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"  Scale he weights by a factor of 3.\n",
    "It can be a useful to increase the magnitude of the weights.\n",
    "N.B.1\n",
    "'model_output' is obtained by:\n",
    "    - scaling the weights by a factor of 3 ;\n",
    "    - sums up the resulting tensor along the first dimension (so 0, the columns);\n",
    "    - effectively collapsing the tensor to a scalar value ;\n",
    "N.B.2\n",
    "last cell\n",
    "\"\"\"\n",
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(114):\n",
    "    model_output = torch.relu(weights * 3).sum(dim=0) \n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "\n",
    "    weights.grad.zero_() \n",
    "\n",
    "optimizer = torch.optim.SGD([weights], lr=0.01) \n",
    "optimizer.step()\n",
    "optimizer.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
