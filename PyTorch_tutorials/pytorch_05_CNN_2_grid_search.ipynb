{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjMWHXQjgbCb"
      },
      "source": [
        "<div style=\"line-height:1.2;\">\n",
        "\n",
        "<h1 style=\"color:#BF66F2; margin-bottom: 0.3em;\"> Convolutional Neural Networks in PyTorch 2 </h1>\n",
        "\n",
        "<h4 style=\"margin-top: 0.3em; margin-bottom: 1em;\"> Two Examples with two different CNN classes from modelled on the torch.nn.Module.  </h4>\n",
        "\n",
        "<div style=\"line-height:1.4; margin-bottom: 0.5em;\">\n",
        "    <h3 style=\"color: lightblue; display: inline; margin-right: 0.5em;\">Keywords:</h3>\n",
        "    GridSearchCV + RandomizedSearchCV + LeaveOneOut + torch.cuda.amp.GradScaler()\n",
        "</div>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O6eSdZOJA4Js"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn                            # import torch.nn as nn\n",
        "from torch import optim                         # import torch.optim as optim\n",
        "\n",
        "\n",
        "from torch.utils.data import (DataLoader,)      # from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.model_selection import GridSearchCV, LeaveOneOut, RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g1zH0eVKKleM"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Bwq_0qnmKl-P",
        "outputId": "993496ea-729f-4469-9646-9c1ed7ef9850"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d5200a1a-179a-43a7-93c8-a36ee3669eeb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d5200a1a-179a-43a7-93c8-a36ee3669eeb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving MNIST.zip to MNIST (1).zip\n"
          ]
        }
      ],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho11IEt2KugS",
        "outputId": "a0064e28-f529-4438-ab80-b89d0a6e4e77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/MNIST.zip\n",
            "replace MNIST/raw/t10k-images-idx3-ubyte? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip /content/MNIST.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WEicGEh3A7vv"
      },
      "outputs": [],
      "source": [
        "\"\"\" Neural Network class.\n",
        "The first layer is a convolutional layer with:\n",
        "    1 input channel + 8 output channels, a kernel size of 3x3, a stride of 1, and padding () of 1.\n",
        "The second layer is a max-pooling layer with a kernel size of 2x2 and a stride of 2.\n",
        "The third layer is a convolutional layer with:\n",
        "    8 input channels, 16 output channels, a kernel size of 3x3, a stride of 1, and padding of 1.\n",
        "The fourth layer is a fully connected layer with:\n",
        "    1677 input features (output from the second convolutional layer) and num_classes output features (10).\n",
        "\"\"\"\n",
        "class my_CNN(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=10):\n",
        "        super(my_CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=8,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1,\n",
        "        )\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=8,\n",
        "            out_channels=16,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1,\n",
        "        )\n",
        "        self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gLnLVvtA7zt",
        "outputId": "f3071b8a-cb19-492b-d762-35867627d5bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XxfWMuiqA73m"
      },
      "outputs": [],
      "source": [
        "\"\"\" Hyperparameters \"\"\"\n",
        "in_channels = 1\n",
        "num_classes = 10\n",
        "learning_rate = 3e-4    #karpathy's constant\n",
        "batch_size = 64\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "g9zdcdphA77U"
      },
      "outputs": [],
      "source": [
        "train_dataset = datasets.MNIST(root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = datasets.MNIST(root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5yvYn4NEA7-_"
      },
      "outputs": [],
      "source": [
        "# Initialize network\n",
        "model = my_CNN(in_channels=in_channels, num_classes=num_classes).to(device)\n",
        "\n",
        "## Define loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyMWNTdSA8Cr",
        "outputId": "ed4fb239-73d3-42fa-9493-4ef58deeacf4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [00:09<00:00, 95.40it/s] \n",
            "100%|██████████| 938/938 [00:08<00:00, 111.78it/s]\n",
            "100%|██████████| 938/938 [00:08<00:00, 110.55it/s]\n",
            "100%|██████████| 938/938 [00:08<00:00, 113.17it/s]\n",
            "100%|██████████| 938/938 [00:08<00:00, 108.12it/s]\n",
            "100%|██████████| 938/938 [00:08<00:00, 111.49it/s]\n",
            "100%|██████████| 938/938 [00:07<00:00, 119.27it/s]\n",
            "100%|██████████| 938/938 [00:08<00:00, 110.94it/s]\n",
            "100%|██████████| 938/938 [00:08<00:00, 110.94it/s]\n",
            "100%|██████████| 938/938 [00:07<00:00, 119.95it/s]\n"
          ]
        }
      ],
      "source": [
        "############### Train\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
        "        ## Get data to cuda (if possible)\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        # Forward pass\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # Perform parameter update\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uDtdJneZA8GN"
      },
      "outputs": [],
      "source": [
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "    model.train()\n",
        "    return num_correct / num_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3oPNwFfA8Ji",
        "outputId": "f7d018af-8ee6-490a-f55a-d7c808343558"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 98.30\n",
            "Accuracy on test set: 97.95\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:.2f}\")\n",
        "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEW3MyyGBECE"
      },
      "source": [
        "<h2 style=\"color:#BF66F2 \"> <u> Example #2 </u> </h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OePxNCY9BEFh"
      },
      "source": [
        "<h3 style=\"color:#BF66F2 \"> Recap: CNN </h3>\n",
        "<div style=\"margin-top: -8px;\">\n",
        "The choice of the number of channels for each convolutional layer is often based on the principle of gradually increasing the number of channels\n",
        "<br> as the spatial resolution of the feature maps decreases.    <br>\n",
        "This is because the lower layers of the network typically extract low-level features, such as edges and corners, while the higher <br> layers extract more abstract and complex features.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFtmTK1YBEJB"
      },
      "source": [
        "### => Model #2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "L5NJanTYBEMb"
      },
      "outputs": [],
      "source": [
        "class MY_CNN(nn.Module):\n",
        "    \"\"\" Simple Convolutional Neural Network with two convolutional layers and one fully connected layer.\n",
        "\n",
        "    Args:\n",
        "        - Number of input channels [int, default: 1]\n",
        "        - Number of output classes [int, default: 10]\n",
        "\n",
        "    Methods:\n",
        "        - forward(x): Performs a forward pass through the CNN model.\n",
        "\n",
        "    Details:\n",
        "        - The CNN model has four layers:\n",
        "            - 1. Convolutional layer with 420 output channels, kernel size of (3, 3), stride of (1, 1), and padding of (1, 1).\n",
        "            - 2. Max pooling layer with kernel size of (2, 2) and stride of (2, 2).\n",
        "            - 3. Convolutional layer with 1000 output channels, kernel size of (3, 3), stride of (1, 1), and padding of (1, 1).\n",
        "            - 4. Fully connected layer with 1000 * 7 * 7 input features and 'num_classes' output features.\n",
        "\n",
        "        - Padding = adding extra, typically zero-valued, pixels around the edges of an input image before\\\\\n",
        "        it is convolved with a filter.\n",
        "        - Stride = number of pixels by which the convolutional filter (the kernel) is shifted across\\\\\n",
        "        the input image or feature map during the convolution operation.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels=1, num_classes=10):\n",
        "        \"\"\" Initializations. \"\"\"\n",
        "        super(MY_CNN, self).__init__()\n",
        "\n",
        "        ###### First convolutional layer\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=420,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(1, 1),\n",
        "        )\n",
        "        # Max pooling layer\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "        ###### Second convolutional layer\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=420,\n",
        "            out_channels=1000,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(1, 1),\n",
        "        )\n",
        "        # Fully connected layer\n",
        "        self.fc1 = nn.Linear(1000 * 7 * 7, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\" Performs a forward pass through all layers of the CNN model.\\\\\n",
        "        This method is implicitly called when the model is used to make a prediction on the data.\\\\\n",
        "        It is called during training [scores = model(data)] and executed with data as the input tensor x.\\\\\n",
        "        The output of the forward method is the predicted scores, to compute the loss function.\n",
        "\n",
        "        Parameters:\n",
        "            Input [torch.Tensor of shape (batch_size, in_channels, height, width)]\n",
        "\n",
        "        Details:\n",
        "            - Apply the first convolutional layer with kernel size of (3, 3), stride of (1, 1), and padding of (1, 1),\\\\\n",
        "                and the ReLU activation function.\\\\\n",
        "                The output of layer1 is passed through the The Rectified Linear Unit function element-wise.\\\\\n",
        "                ReLU is commonly used in CNNs, since it introduces nonlinearity into the network,\\\\\n",
        "                to make it capable of learning more complex and expressive representations of the input data.\n",
        "            - Apply max pooling layer with kernel size of (2, 2) and stride of (2, 2).\n",
        "            - Apply the second convolutional layer with kernel size of (3, 3), stride of (1, 1),\\\\\n",
        "            and padding of (1, 1), and the ReLU activation function.\n",
        "            - Apply max pooling layer with kernel size of (2, 2) and stride of (2, 2).\n",
        "            - Reshape the tensor to have a size of (batch_size, 1000 * 7 * 7).\n",
        "                The input to the fully connected layer must be a 1D tensor,\\\\\n",
        "                    so we need to reshape the output of the second convolutional layer to a 1D tensor\\\\\n",
        "                    before passing it to the fully connected layer.\n",
        "                - x.reshape(x.shape[0], -1)\n",
        "                    - 1) First dimension of the tensor ==> batch size, is kept the same, while the remaining\\\\\n",
        "                    dimensions are collapsed into a single dimension.\n",
        "                    - 2) Second dimension of the tensor ==> \"-1\" indicates that the size of the remaining dimension\\\\\n",
        "                    should be inferred automatically based on the size of the tensor and the specified batch size.\n",
        "            - Apply the fully connected layer to output a tensor of size (batch_size, 'num_classes').\n",
        "        Returns:\n",
        "            Output tensor of shape (batch_size, 'num_classes') [a torch.Tensor]\n",
        "        \"\"\"\n",
        "        # First convolutional layer\n",
        "        x = F.relu(self.conv1(x))\n",
        "        # Max pooling layer\n",
        "        x = self.pool(x)\n",
        "        # Second convolutional layer\n",
        "        x = F.relu(self.conv2(x))\n",
        "        # Max pooling layer\n",
        "        x = self.pool(x)\n",
        "        # Reshape the tensor\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        # Fully connected layer (batch_size, 'num_classes')\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGvBo06LBEP4",
        "outputId": "6a19e5f7-e8eb-40e5-9787-65a7f4ebc931"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "\"\"\" Check that GPU is working \"\"\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "assert device.type == \"cuda\", \"GPU not available\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-3JhEEKYBETR"
      },
      "outputs": [],
      "source": [
        "\"\"\" Hyperparameters (initial guesses). \"\"\"\n",
        "in_channel = 1\n",
        "num_classes = 10\n",
        "learning_rate = 3e-4\n",
        "batch_size = 100\n",
        "num_epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cHkPh9sGKBc5"
      },
      "outputs": [],
      "source": [
        "train_dataset = datasets.MNIST(root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataset = datasets.MNIST(root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-2ENvf5-KBwU"
      },
      "outputs": [],
      "source": [
        "# Define model, loss and optimizer\n",
        "model = MY_CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c01xx0UqKB1B"
      },
      "source": [
        "<h3 style=\"color:#BF66F2 \"> Recap: Forward pass </h3>\n",
        "<div style=\"margin-top: -8px;\">\n",
        "\n",
        "PyTorch.cuda.amp.GradScaler() to scale the gradients during backpropagation to avoid numerical underflow or overflow <br> when training with mixed precision. <br>\n",
        "Mixed precision training is a technique that involves using a combination of single-precision and half-precision floating-point numbers <br> to perform forward and backward passes through the neural network. <br>\n",
        "This technique can help reduce the memory requirements and computational cost of training deep learning models without sacrificing accuracy. <br>\n",
        "\n",
        "In mixed precision training, the gradients that are computed during the backward pass may be very small or very large, <br> depending on the scale of the input data and the model parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Nf7lC5eOKB4r"
      },
      "outputs": [],
      "source": [
        "# Define a Scaler (necessary for FP16!)\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXWD2FVvKB7-"
      },
      "source": [
        "### => Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuD-b4owi-kx",
        "outputId": "0ac39ee7-38bc-4d4e-ea9c-40000a413a64"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [0/5]: 100%|██████████| 600/600 [00:26<00:00, 22.28it/s, loss=0.032]\n",
            "Epoch [1/5]: 100%|██████████| 600/600 [00:27<00:00, 22.12it/s, loss=0.0256]\n",
            "Epoch [2/5]: 100%|██████████| 600/600 [00:27<00:00, 21.94it/s, loss=0.0805]\n",
            "Epoch [3/5]: 100%|██████████| 600/600 [00:27<00:00, 21.79it/s, loss=0.00576]\n",
            "Epoch [4/5]: 100%|██████████| 600/600 [00:27<00:00, 21.94it/s, loss=0.00144]\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    # Wrap train_loader with tqdm\n",
        "    loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=True)\n",
        "\n",
        "    for batch_idx, (data, targets) in loop:\n",
        "        # Send data to cuda\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        ########## Forward pass through the model to get the predicted scores\n",
        "        with torch.cuda.amp.autocast():\n",
        "            scores = model(data)\n",
        "            # Calculate the loss using the predicted scores and the actual targets\n",
        "            loss = criterion(scores, targets)\n",
        "\n",
        "        ######## Backward pass to calculate the gradients of the loss function w.r.t. the model parameters\n",
        "        # Reset the gradients of all model parameters\n",
        "        optimizer.zero_grad()\n",
        "        # Scale the loss to avoid numerical underflow or overflow and compute gradients\n",
        "        scaler.scale(loss).backward()\n",
        "        # Update the model parameters using the computed gradients\n",
        "        scaler.step(optimizer)\n",
        "        # Update the scale factor for the next iteration\n",
        "        scaler.update()\n",
        "\n",
        "        # Update the tqdm loop with additional information (like current loss)\n",
        "        loop.set_description(f\"Epoch [{epoch}/{num_epochs}]\")\n",
        "        loop.set_postfix(loss=loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "L_HHp-dpKKBS"
      },
      "outputs": [],
      "source": [
        "def check_accuracy(loader, model):\n",
        "    \"\"\" Point out the model's accuracy on the data from the give dataloader.\n",
        "\n",
        "    Parameters:\n",
        "        - DataLoader object that provides the data to check the model's accuracy [torch.utils.data.DataLoader]\n",
        "        - Model to be evaluated model [torch.nn.Module]\n",
        "\n",
        "    Details:\n",
        "        - Initialize counters for the number of correct predictions and the total number of samples\n",
        "        - Set the model to evaluation mode\n",
        "        - Disable gradient computation using 'torch.no_grad()'\n",
        "        - Iterate over the data in the loader, making predictions using the model and comparing them to the ground truth labels\n",
        "        - Finally, train() the model and print the accuracy of the model on the data from the loader\n",
        "    \"\"\"\n",
        "    num_correct, num_samples = 0, 0\n",
        "    model.eval()\n",
        "\n",
        "    # Disable gradient computation for efficiency reasons\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            # Get data to cuda if possible\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "\n",
        "            ## Compute the predicted labels as the class with the highest score\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "\n",
        "            ## Update the number of correct predictions and the number of samples\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "    print(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}\")\n",
        "\n",
        "    # Set the model back to training mode\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EhlRueZKKFD",
        "outputId": "366d0531-3c78-42e7-f723-fc9e4845209e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Got 59784 / 60000 with accuracy 99.64\n",
            "Got 9907 / 10000 with accuracy 99.07\n"
          ]
        }
      ],
      "source": [
        "check_accuracy(train_loader, model)\n",
        "check_accuracy(test_loader, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Wcaz4dFhKKIh"
      },
      "outputs": [],
      "source": [
        "def f1_scorer(model, X, y_true):\n",
        "    \"\"\" Compute the F1 score for multi-class classification.\n",
        "\n",
        "    Parameters:\n",
        "        - model (): Trained PyTorch model [nn.Module]\n",
        "        - Input data X [torch.Tensor]\n",
        "        - Target tensor y_true [torch.Tensor]\n",
        "\n",
        "    Returns:\n",
        "        - F1 score [float]\n",
        "    \"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    X, y_true = X.to(device), y_true.to(device)\n",
        "    with torch.no_grad():\n",
        "        y_pred = model(X)\n",
        "        y_pred = torch.argmax(y_pred, dim=1)\n",
        "    score = f1_score(y_true.cpu().numpy(), y_pred.cpu().numpy(), average='macro')\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5RfbRV6j0Vo",
        "outputId": "bb2482da-b737-440c-9796-a1a74f2e26d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.9714501537110232\n"
          ]
        }
      ],
      "source": [
        "X_test_list, y_test_list = [], []\n",
        "# Ensure model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Iterate over test data to collate it into one large tensor\n",
        "with torch.no_grad():\n",
        "    for data, targets in test_loader:\n",
        "        X_test_list.append(data.cpu())\n",
        "        y_test_list.append(targets.cpu())\n",
        "\n",
        "# Convert lists of tensors to one large tensor\n",
        "X_test = torch.cat(X_test_list, dim=0)\n",
        "y_test = torch.cat(y_test_list, dim=0)\n",
        "\n",
        "\"\"\" Calculate F1 score\n",
        "=> N.B.\n",
        "To avoid the OutOfMemoryError: CUDA out of memory. Tried to allocate 12.27 GiB, it is necessary to consider only a small part of the dataset)\n",
        "\"\"\"\n",
        "f1 = f1_scorer(model, X_test[:100], y_test[:100])\n",
        "print(f\"F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37I_vHarKKMl"
      },
      "source": [
        "### => Model #2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ApHHaTm6KKPS"
      },
      "outputs": [],
      "source": [
        "class MY_CNN(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=10):\n",
        "        super(MY_CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=420,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(1, 1),\n",
        "        )\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=420,\n",
        "            out_channels=1000,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(1, 1),\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(1000 * 7 * 7, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = nn.functional.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        out = self.fc1(x)\n",
        "        return out\n",
        "\n",
        "    def fit(self, train_loader, criterion, optimizer, lr, num_epochs):\n",
        "        \"\"\" Trains the CNN model using the specified hyperparameters.\n",
        "\n",
        "        Parameters:\n",
        "            - DataLoader object containing the training data [torch.utils.data.DataLoader]\n",
        "            - Loss function (criterion) to use for training [torch.nn.modules.loss._Loss]\n",
        "            - Optimizer used for training [torch.optim.Optimizer]\n",
        "            - Learning rate to use for training [float]\n",
        "            - Number of epochs to train for [int]\n",
        "\n",
        "        Returns:\n",
        "            - Trained CNN model\n",
        "        \"\"\"\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.to(device)\n",
        "\n",
        "        ## Define optimizer and scheduler\n",
        "        optimizer = optimizer(self.parameters(), lr=lr)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.1)\n",
        "\n",
        "\n",
        "        ###################################### Train the model\n",
        "        for epoch in range(num_epochs):\n",
        "            train_loss = 0.0\n",
        "            for i, (inputs, labels) in enumerate(train_loader):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backward and optimize\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            scheduler.step(train_loss)\n",
        "\n",
        "        return self"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U78QXYnKKSI"
      },
      "source": [
        "<div style=\"line-height:0.8\">\n",
        "<h4> <b> Note: </b> <h4>\n",
        "</div>\n",
        "<div style=\"line-height:0.1\">\n",
        "<h4> Common problems with \"grid_search.fit([train_loader], y_train)\" <h4>\n",
        "</div>\n",
        "<div style=\"line-height:1.4\">\n",
        "\n",
        "- ValueError: Cannot have number of splits n_splits=3 greater than the number of samples: n_samples=1. <br>\n",
        "- ValueError: k-fold cross-validation requires at least one train/test split by setting n_splits=2 or more, got n_splits=1. <br>\n",
        "- TypeError: Singleton array array(<torch.utils.data.dataloader.DataLoader object at 0x780366fd59f0>, <br>\n",
        "      dtype=object) cannot be considered a valid collection.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XCh3C_YTKKV_"
      },
      "outputs": [],
      "source": [
        "\"\"\" Get dataset as numpy arrays.\n",
        "N.B.\n",
        "Using:\n",
        "    #train_data_numpy = train_dataset.numpy()\n",
        "    #train_labels_numpy = train_dataset.targets.numpy()\n",
        "will lead to Error: 'MNIST' object has no attribute 'numpy'...\n",
        "\"\"\"\n",
        "train_data_numpy = []\n",
        "train_labels_numpy = []\n",
        "\n",
        "for i, (image, label) in enumerate(train_dataset):\n",
        "    # Convert the image to a numpy array\n",
        "    image_numpy = image.numpy()\n",
        "    train_data_numpy.append(image_numpy)\n",
        "    train_labels_numpy.append(label)\n",
        "\n",
        "train_data_numpy = np.array(train_data_numpy)\n",
        "train_labels_numpy = np.array(train_labels_numpy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3lXtzJKKKYp",
        "outputId": "06b492e0-9fde-4d5a-b45c-ba701354cd93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data_numpy[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVzLSRf3KKbO"
      },
      "source": [
        "<h3 style=\"color:#BF66F2 \"> Grid Search </h3>\n",
        "Adding too many parameters will soon make the code to ask for too much RAM and the program may crash!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2e_RwQTmQF-c"
      },
      "outputs": [],
      "source": [
        "class MyCNNWrapper(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, in_channels=1, num_classes=10, learning_rate=0.001, epochs=10):\n",
        "        \"\"\"\n",
        "        Initialize the wrapper with default parameters.\\\\\n",
        "        The parameters can then be adjusted with grid search.\n",
        "        \"\"\"\n",
        "        self.in_channels = in_channels\n",
        "        self.num_classes = num_classes\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.model = MY_CNN(in_channels=in_channels, num_classes=num_classes)\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\" Train the model \"\"\"\n",
        "        self.model.fit(X, self.criterion, torch.optim.Adam, self.learning_rate, self.epochs)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\" Make predictions. \"\"\"\n",
        "        # Set model to evaluation mode\n",
        "        self.model.eval()\n",
        "        outputs = self.model(torch.tensor(X, dtype=torch.float32))\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        return preds.numpy()\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        \"\"\" Get parameters for this estimator. \"\"\"\n",
        "        return {\n",
        "            \"in_channels\": self.in_channels,\n",
        "            \"num_classes\": self.num_classes,\n",
        "            \"learning_rate\": self.learning_rate,\n",
        "            \"epochs\": self.epochs\n",
        "        }\n",
        "\n",
        "    def set_params(self, **parameters):\n",
        "        \"\"\" Set the parameters of the estimator. \"\"\"\n",
        "        for parameter, value in parameters.items():\n",
        "            setattr(self, parameter, value)\n",
        "        # Update model\n",
        "        self.model = MY_CNN(in_channels=self.in_channels, num_classes=self.num_classes)\n",
        "        # Update loss\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "        return self"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu8kPJiTKKd0",
        "outputId": "27437742-2fb8-41d6-8844-427f19694e82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping, it may cause RAM crash.\n"
          ]
        }
      ],
      "source": [
        "%%script echo Skipping, it may cause RAM crash.\n",
        "\"\"\" GridSearchCV.\n",
        "N.B.1\n",
        "It works but it use too much RAM!\n",
        "N.B.2\n",
        "The fit function need to be defined also to use it ! (self, train_loader, criterion, optimizer, lr, num_epochs).\n",
        "\"\"\"\n",
        "##### Define the hyperparameters to search over\n",
        "param_grid = {\n",
        "    'hidden_size': [64, 128, 256],\n",
        "    'learning_rate': [1e-3, 3e-4, 1e-4],\n",
        "    'batch_size': [50, 100, 200],\n",
        "    'num_epochs': [5, 10, 20],\n",
        "}\n",
        "# Create an instance of the wrapper class\n",
        "wrapper = MyCNNWrapper()\n",
        "\n",
        "# Create an instance of the LeaveOneOut class\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "grid_search = GridSearchCV(estimator=wrapper, param_grid=param_grid, cv=loo, scoring=f1_scorer) #cv=1 scoring='f1_macro')\n",
        "\n",
        "# Train the model using grid search to find the best hyperparameters\n",
        "grid_search.fit(train_data_numpy, train_labels_numpy)\n",
        "\n",
        "print(grid_search.best_params_)\n",
        "# Evaluate the best model found by grid search\n",
        "best_model = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4fVSQAZKKgP",
        "outputId": "f15afe23-5ae4-476e-87af-6334560c797c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping, it may cause RAM crash.\n"
          ]
        }
      ],
      "source": [
        "%%script echo Skipping, it may cause RAM crash.\n",
        "\"\"\" Random GridSearchCV\n",
        "N.B.1\n",
        "It works but it use too much RAM!\n",
        "N.B.2\n",
        "#ValueError: --> fits failed. It is very likely that your model is misconfigured.\n",
        "N.B.3\n",
        "TypeError: Adam object is not callable\n",
        "\"\"\"\n",
        "###### Define the hyperparameters to search over\n",
        "param_grid = {\n",
        "    'hidden_size': [64, 128, 256],\n",
        "    'learning_rate': [1e-3, 3e-4, 1e-4],\n",
        "    'batch_size': [50, 100, 200],\n",
        "    'num_epochs': [5, 10, 20],\n",
        "}\n",
        "# Create an instance of the wrapper class\n",
        "wrapper = MyCNNWrapper()\n",
        "\n",
        "# Create an instance of the LeaveOneOut class\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Create an instance of the RandomizedSearchCV class\n",
        "random_search = RandomizedSearchCV(estimator=wrapper, param_distributions=param_grid, n_iter=10, cv=3) # cv=loo, scoring=f1_scorer)\n",
        "\n",
        "# Train the model using random search to find the best hyperparameters\n",
        "random_search.fit(train_data_numpy, train_labels_numpy)\n",
        "\n",
        "print(random_search.best_params_)\n",
        "# Evaluate the best model found by grid search\n",
        "best_model = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvBTrZQSKaUm",
        "outputId": "2527d789-6540-4acd-e45f-d31e90018b41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping, it may cause RAM crash.\n"
          ]
        }
      ],
      "source": [
        "%%script echo Skipping, it may cause RAM crash.\n",
        "best_model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = best_model(images)\n",
        "        _, predicted = torch.max(outputs.data, dim=1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(\"Test accuracy: %.2f%%\" % (accuracy * 100))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
