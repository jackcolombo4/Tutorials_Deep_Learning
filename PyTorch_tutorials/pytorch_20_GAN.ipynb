{"cells":[{"cell_type":"markdown","metadata":{},"source":["<div style=\"line-height:0.5\">\n","<h1 style=\"color:#BF66F2 \"> Generative Adversarial Network in PyTorch 1 </h1>\n","<h4> Example of GANs using the MNIST dataset with Binary Cross Entropy. </h4>\n","\n","<span style=\"display: inline-block;\">\n","    <h3 style=\"color: lightblue; display: inline;\">Keywords:</h3>\n","    SummaryWriter + nn.BCELoss() + LeakyReLU\n","</span>\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"XXdsxabA913O"},"source":["<h2 style=\"color:#BF66F2 \"> GANs</h2>\n","<div style=\"margin-top: -25px;\">\n","\n","\n","\n","=> Train a generative model by framing the problem as a supervised learning problem with two sub-models:      \n","<div style=\"margin-top: -20px;\">\n","\n","+ Generator model trained to generate new realistic samples that can fool the critic.\n","+ Discriminator (or Critic) model that classify examples as either real (from the domain) or fake (generated), trained to distinguish <BR>between real and fake samples.\n","\n","The generator and discriminator models are trained in an adversarial manner, (in a zero-sum game!)\n","<br> => they are trained to compete against each other.\n","\n","The generator aims to generate realistic samples to deceive the discriminator, while the discriminator aims to correctly classify between real and fake samples, <br> \n","with the critic trying to improve its ability to distinguish real from fake samples, and the generator trying to improve its ability <br> to generate realistic samples that can fool the discriminator.\n","\n","This process continues iteratively until the generator can produce realistic samples that are indistinguishable from real data, and the discriminator <br> can no longer differentiate between real and fake samples with high confidence.\n","Namely it finishes when the discriminator model is fooled about <br>  half the time, meaning the generator model is generating plausible examples.   \n","</div>\n","</div>\n"]},{"cell_type":"markdown","metadata":{"id":"fLirbzVrSxJU"},"source":["<h3 style=\"color:#BF66F2 \"> The GAN approach:</h3>\n","<div style=\"margin-top: -25px;\">\n","\n","Do not look for an explicit density model s describing the manifold of natural images...<br>\n","Just find out a model able to generate samples that «looks like» training samples.\n","<div style=\"margin-top: -18px;\">\n","\n","1. Sample a seed from a known distribution    \n","2. This is defined a priori and also referred to as noise   \n","3. Feed this seed to a learned transformation that generates realistic samples    \n","4. Use a neural network to learn this transformation the NN is going to be trained in an unsupervised manner, no label needed    \n","\n","Final GOAL => create a regularization PRIOR in other problem to perform anomaly detection!\n","</div>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fg3VKJxJ9Uqc"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.datasets as datasets\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":68,"status":"ok","timestamp":1690022473064,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"fF_cY6Ug-zHy","outputId":"700ccf9c-aec8-4a42-96a9-4dba1993fce8"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nFmHHZv59Wzi"},"outputs":[],"source":["class Discriminator(nn.Module):\n","    \"\"\" Discriminator model for GAN.\n","    \n","    Attributes:\n","        Sequential layers of the generator [nn.Sequential]\n","    \"\"\"\n","    def __init__(self, in_features):\n","        super().__init__()\n","        self.disc = nn.Sequential(\n","            nn.Linear(in_features, 128),   # 128 output features\n","            nn.LeakyReLU(0.01),            # negative slope of 0.01\n","            nn.Linear(128, 1),             # 128 in => 1 ouput feature\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, x):\n","        \"\"\" Forward pass of the generator. \"\"\"\n","        return self.disc(x)\n","\n","\n","class Generator(nn.Module):\n","    \"\"\" Generator model for GAN.\n","    \n","    Attributes:\n","        Sequential layers of the discriminator [nn.Sequential].\n","    \n","    Details:\n","        final activation func Tanh() it is used to normalize inputs to [-1, 1] so make outputs [-1, 1].\n","    \"\"\"\n","    def __init__(self, z_dim, img_dim):\n","        super().__init__()\n","        self.gen = nn.Sequential(\n","            nn.Linear(z_dim, 256),\n","            nn.LeakyReLU(0.01),\n","            nn.Linear(256, img_dim),\n","            nn.Tanh(),\n","        )\n","\n","    def forward(self, x):\n","        \"\"\" Forward pass of the discriminator. \"\"\"\n","        return self.gen(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_bgA-67jAMcX"},"outputs":[],"source":["\"\"\" Hyperparameters \"\"\"\n","lr = 3e-4                 #0.0003 (3 multiplied by 10 to the power of -4)\n","z_dim = 64\n","image_dim = 28 * 28 * 1   #total = 784\n","batch_size = 32\n","num_epochs = 50"]},{"cell_type":"markdown","metadata":{},"source":["<h2 style=\"color:#BF66F2 \"> Initialize models and optimizers </h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QOxXCkP2BDpx"},"outputs":[],"source":["# Create an instance of the Discriminator class with the specified input image dimension.\n","disc_obj = Discriminator(image_dim).to(device)\n","# Create an instance of the Generator class with input noise dimension (z_dim) and output image dimension (image_dim).\n","gen_obj = Generator(z_dim, image_dim).to(device)\n","\n","# Generate fixed random noise tensor used during training for generating sample images, \n","# initialized with random values drawn from a standard normal distribution.\n","fixed_noise = torch.randn((batch_size, z_dim)).to(device)\n","\n","### Define a sequence of image transformations to be applied to the training images:\n","    # Convert the input image to a PyTorch tensor\n","    # Normalize the pixel values to the range [-1, 1]\n","transforms = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,)),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":659,"status":"ok","timestamp":1690022482120,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"3-0w8JsbBhEU","outputId":"35d3c165-136b-4cda-f1bb-62b02795c78a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 280865728.85it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 28881/28881 [00:00<00:00, 16387404.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 167386097.65it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4542/4542 [00:00<00:00, 15047811.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n","\n"]}],"source":["dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)\n","loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JeX-cvBhBX8N"},"outputs":[],"source":["# Optimizers Adam\n","opt_disc = optim.Adam(disc_obj.parameters(), lr=lr)\n","opt_gen = optim.Adam(gen_obj.parameters(), lr=lr)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0UUskswBIaiA"},"outputs":[],"source":["# Binary Cross Entropy loss between the target and the input probabilities.\n","criterion = nn.BCELoss()"]},{"cell_type":"markdown","metadata":{"id":"018tZB4aIU5r"},"source":["The Binary Cross Entropy (BCE) loss measures the difference between the predicted probabilities and the true labels, penalizing the model mode when it makes incorrect confident preds. <br> \n","This encourages the model to produce more accurate probablities for the true class labels. <br>\n","The loss function is minimized during training to update the model's parametres to improve its performance. <br>\n","\n","\n","$$\n","\\text{BCE Loss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right]\n","$$\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CfwWdrWjB5xM"},"source":["The `SummaryWriter` class provides a high-level API to log data (scalars, images, histograms) in a given directory and add summaries and events to it.\n","The class updates the file contents asynchronously.    \n","These logged data can then be visualized in TensorBoard to gain insights into the model's behavior and performance over time.    \n","\n","This allows a training program to call methods to add data to the file directly from the training loop, without slowing down the training."]},{"cell_type":"markdown","metadata":{},"source":["<h3 style=\"color:#BF66F2 \"> Methods: </h3>\n","<div style=\"margin-top: -25px;\">\n","\n","- add_scalar(tag, scalar_value, global_step=None, walltime=None): Log scalar data, such as loss or accuracy, with the specified tag.\n","- add_image(tag, img_tensor, global_step=None, walltime=None): Log images with the specified tag.\n","- add_histogram(tag, values, global_step=None, bins='tensorflow', walltime=None): Log histograms with the specified tag.\n","- add_graph(model, input_to_model=None, verbose=False): Log the computational graph of a PyTorch model.\n","- add_embedding(mat, metadata=None, label_img=None, global_step=None, tag='default', metadata_header=None): Log embeddings (e.g., for visualization using the Embedding Projector).\n","- add_text(tag, text_string, global_step=None, walltime=None): Log text data with the specified tag.\n","- add_figure(tag, figure, global_step=None, close=True, walltime=None): Log matplotlib figures with the specified tag.\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3g8KoDFPBxjk"},"outputs":[],"source":["\"\"\" Writes entries directly to event files in the log_dir to be consumed by TensorBoard. \"\"\"\n","writer_fake = SummaryWriter(f\"logs/fake\")\n","writer_real = SummaryWriter(f\"logs/real\")\n","step = 0"]},{"cell_type":"markdown","metadata":{"id":"ai2QrYb2FJ6A"},"source":["<h2 style=\"color:#BF66F2 \"> Training </h3>\n","Discriminator: \n","\n","$\n","\\max \\log(D(x)) + \\log(1 - D(G(z)))\n","$\n","\n","Generator \n","$\n","\\max \\log(D(x)) + \\log(1 - D(G(z)))\n","\\min \\log(1 - D(G(z)))\n","$\n","\n","That means GAN training trick)...to provide a stronger gradient during the early learning stages:\n","$ \\max \\log(D(G(z))$"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1131111,"status":"ok","timestamp":1690023613217,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"Rqk-x6xoB5Iy","outputId":"5d274dbc-5e1c-4c87-e21e-2e9d2bd09043"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [0/50] Batch 0/1875                       Loss D: 0.6054, loss G: 0.6797\n","Epoch [1/50] Batch 0/1875                       Loss D: 0.2925, loss G: 1.3966\n","Epoch [2/50] Batch 0/1875                       Loss D: 0.4295, loss G: 1.0767\n","Epoch [3/50] Batch 0/1875                       Loss D: 0.6089, loss G: 0.9956\n","Epoch [4/50] Batch 0/1875                       Loss D: 0.6841, loss G: 0.8109\n","Epoch [5/50] Batch 0/1875                       Loss D: 0.3916, loss G: 1.4802\n","Epoch [6/50] Batch 0/1875                       Loss D: 0.7030, loss G: 1.2686\n","Epoch [7/50] Batch 0/1875                       Loss D: 0.7270, loss G: 1.6782\n","Epoch [8/50] Batch 0/1875                       Loss D: 0.7371, loss G: 0.9127\n","Epoch [9/50] Batch 0/1875                       Loss D: 0.5482, loss G: 1.1651\n","Epoch [10/50] Batch 0/1875                       Loss D: 0.4469, loss G: 1.1557\n","Epoch [11/50] Batch 0/1875                       Loss D: 0.4896, loss G: 1.3717\n","Epoch [12/50] Batch 0/1875                       Loss D: 0.2891, loss G: 1.9544\n","Epoch [13/50] Batch 0/1875                       Loss D: 0.4344, loss G: 1.5179\n","Epoch [14/50] Batch 0/1875                       Loss D: 0.6830, loss G: 1.7186\n","Epoch [15/50] Batch 0/1875                       Loss D: 0.4572, loss G: 1.4958\n","Epoch [16/50] Batch 0/1875                       Loss D: 0.5512, loss G: 1.4328\n","Epoch [17/50] Batch 0/1875                       Loss D: 0.7862, loss G: 1.1539\n","Epoch [18/50] Batch 0/1875                       Loss D: 0.5888, loss G: 1.4702\n","Epoch [19/50] Batch 0/1875                       Loss D: 0.6243, loss G: 1.0857\n","Epoch [20/50] Batch 0/1875                       Loss D: 0.5155, loss G: 1.7981\n","Epoch [21/50] Batch 0/1875                       Loss D: 0.5499, loss G: 1.4375\n","Epoch [22/50] Batch 0/1875                       Loss D: 0.6455, loss G: 1.3085\n","Epoch [23/50] Batch 0/1875                       Loss D: 0.5671, loss G: 1.7169\n","Epoch [24/50] Batch 0/1875                       Loss D: 0.6347, loss G: 1.5131\n","Epoch [25/50] Batch 0/1875                       Loss D: 0.4072, loss G: 1.6984\n","Epoch [26/50] Batch 0/1875                       Loss D: 0.5580, loss G: 1.4289\n","Epoch [27/50] Batch 0/1875                       Loss D: 0.6665, loss G: 1.4638\n","Epoch [28/50] Batch 0/1875                       Loss D: 0.6471, loss G: 1.0419\n","Epoch [29/50] Batch 0/1875                       Loss D: 0.5960, loss G: 1.3830\n","Epoch [30/50] Batch 0/1875                       Loss D: 0.3630, loss G: 1.9166\n","Epoch [31/50] Batch 0/1875                       Loss D: 0.5836, loss G: 1.8432\n","Epoch [32/50] Batch 0/1875                       Loss D: 0.7242, loss G: 1.5459\n","Epoch [33/50] Batch 0/1875                       Loss D: 0.4568, loss G: 1.7727\n","Epoch [34/50] Batch 0/1875                       Loss D: 0.6681, loss G: 1.2351\n","Epoch [35/50] Batch 0/1875                       Loss D: 0.6927, loss G: 1.2038\n","Epoch [36/50] Batch 0/1875                       Loss D: 0.5486, loss G: 1.2079\n","Epoch [37/50] Batch 0/1875                       Loss D: 0.7031, loss G: 1.1389\n","Epoch [38/50] Batch 0/1875                       Loss D: 0.6699, loss G: 1.2207\n","Epoch [39/50] Batch 0/1875                       Loss D: 0.7195, loss G: 1.1091\n","Epoch [40/50] Batch 0/1875                       Loss D: 0.4584, loss G: 1.2023\n","Epoch [41/50] Batch 0/1875                       Loss D: 0.4842, loss G: 1.2925\n","Epoch [42/50] Batch 0/1875                       Loss D: 0.6694, loss G: 1.0033\n","Epoch [43/50] Batch 0/1875                       Loss D: 0.7676, loss G: 0.9866\n","Epoch [44/50] Batch 0/1875                       Loss D: 0.5777, loss G: 1.2750\n","Epoch [45/50] Batch 0/1875                       Loss D: 0.7594, loss G: 0.9369\n","Epoch [46/50] Batch 0/1875                       Loss D: 0.4419, loss G: 1.7234\n","Epoch [47/50] Batch 0/1875                       Loss D: 0.5052, loss G: 1.3936\n","Epoch [48/50] Batch 0/1875                       Loss D: 0.6685, loss G: 1.1231\n","Epoch [49/50] Batch 0/1875                       Loss D: 0.7069, loss G: 0.8158\n"]}],"source":["\"\"\" Training.\n","N.B.1\n","The Discriminator is trained by maximizing the log-likelihood of classifying real data as real and fake data as fake.\n","The Generator is trained by minimizing the log-likelihood of the Discriminator classifying fake data as fake\n","(maximizing the log-likelihood of the Discriminator classifying fake data as real).\n","\n","N.B.2\n","no_grad() => Context-manager (thread local)that disabled gradient calculation, to reduce memory consumption.\n","Useful for inference, when the backward() method is not called.\n","\n","N.B.3\n","TensorBoard log uses the global_step value to specify the iteration number at which this data is added to TensorBoard.\n","\n","\"\"\"\n","\n","for epoch in range(num_epochs):\n","    for batch_idx, (real, _) in enumerate(loader):\n","        # Reshape the batch of data real into a 2D tensor with dimensions 784 for 28x28 images\n","        real = real.view(-1, 784).to(device)\n","        batch_size = real.shape[0]\n","\n","        ######### Train Discriminator\n","        noise = torch.randn(batch_size, z_dim).to(device)\n","        fake = gen_obj(noise)\n","\n","        ## Discriminator's predictions for real and fake data (flattening with view(-1))\n","        disc_real = disc_obj(real).view(-1)\n","        disc_fake = disc_obj(fake).view(-1)   #=> D(G(z))\n","        ### Discriminator's loss for real, fake data and overall\n","        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n","        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n","        lossD = (lossD_real + lossD_fake) / 2\n","\n","        # Set gradients of all model parameters to zero\n","        disc_obj.zero_grad()\n","        # Backpropagate Discriminator's parameters\n","        lossD.backward(retain_graph=True)\n","        # Perform a single optimization step (parameter update)\n","        opt_disc.step()\n","\n","        ################# Train Generator\n","        # where the second option of maximizing doesn't suffer from saturating gradients\n","\n","        # Discriminator's predictions for fake data generated by the Generator\n","        output = disc_obj(fake).view(-1)\n","        # Generator loss\n","        lossG = criterion(output, torch.ones_like(output))\n","        ### Gradients to zero, backpropagate and update Generator's parameters\n","        gen_obj.zero_grad()\n","        lossG.backward()\n","        opt_gen.step()\n","\n","        # Print losses and to tensorboard\n","        if batch_idx == 0:\n","            print(f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\n","                        Loss D: {lossD:.4f}, loss G: {lossG:.4f}\")\n","\n","            ####### Generate images using the fixed noise for visualization\n","            with torch.no_grad():\n","                #### Create image grids, the tensor needs to be reshaped to a 4-dimensional tensor with the shape:\n","                # batch_size: The number of images to display in a grid\n","                # 1:          The number of channels in the image => the images are grayscale\n","                # 28:         The height of the image\n","                # 28:         The width of the image\n","                fake = gen_obj(fixed_noise).reshape(-1, 1, 28, 28)\n","                data = real.reshape(-1, 1, 28, 28)\n","                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n","                img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n","\n","                ## Log generated fake and real images to TensorBoard\n","                writer_fake.add_image(\"Mnist Fake Images\", img_grid_fake, global_step=step)\n","                writer_real.add_image(\"Mnist Real Images\", img_grid_real, global_step=step)\n","                step += 1"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMOvpUDMcYlPMPjoY1E2Keo","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
