{"cells":[{"cell_type":"markdown","metadata":{},"source":["<div style=\"line-height:1.2;\">\n","\n","<h1 style=\"color:#FF7C00; margin-bottom: 0.3em;\">Transformers Neural Networks in TensorFlow</h1>\n","\n","<h4 style=\"margin-top: 0.3em; margin-bottom: 1em;\"> Text translation from Italian to Portoguese with a custom Transformer model.</h4>\n","\n","<div style=\"line-height:1.4; margin-bottom: 0.5em;\">\n","    <h3 style=\"color: lightblue; display: inline; margin-right: 0.5em;\">Keywords:</h3> \n","    tensorflow_datasets + tokenization + encoding + mask + $$\\Large formula markdown + matplotlib pcolormesh + <br> numpy set_printoptions + tf.keras.Model + LearningRateSchedule + @tf.function decorators \n","</div>\n","\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JD5RXzlvVyhV"},"outputs":[],"source":["import tensorflow_datasets as tfds\n","import tensorflow as tf\n","\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":149,"referenced_widgets":["c0e25fa7080548d6ba158b1cb4580e0d","2c0ac586037e40709a148c690c48c60e","d71136c3cda34227b7f42131c1b104c5","7bd0bf0cf4784dddba19d0eb1ef5689b","295e2bccfea64ec8b0216f24c5c863a5","4bfab8c731c34da8bb9b342d86f7a841","39e05160b2a94a5aa8004a216fa1ebee","d4365583107d4235a2c1eea7715a4ebe","73df70457eb94df592dc5df67eea29ac","bcfb850f52b64f86ad56447ceb7f670e","36e74585de764fb787358aa5054fd27d","14e86b9f3f1d43f88d6bcafa706387d4","04c6fb76556c4519b84e1b8fc0df4971","7b50abdb50fe4a3a990914f93a8c118e","596f0eaf17a34fc1939b38fed3f4f0b7","beb6f114d24449cb8c55fe34d9a1c032","f0f6b65997954fc8a1312fac5100e6e5","9b5b9774e1da4632a98fadd965e57181","b226f9faec7a4398a9a4b0ccc68420d0","c71e0e0f0f1d4026a55598bcafa50448","1985514b6aae42cea80017c66961fee8","c0c356f862f542f3a14be0930e0074c1","955cbc6ba61745c6831775b6c8e1956b","cfbcd0f400ad4ddb9b17ed555f042956","b3b7b5d748f141e3a255c95ca89ae6b9","4b59ddfa148745ff80ac0b6b36428e96","d0d9fe9d38364d70b46666ff35281c20","db227fbba117485ebcc3e02755c9840e","77e83425d1d543519a69de1eec90ecbb","f0712f2abd2845ec89180a751317a575","62b929c0feae4b3bbb000ef6d4644237","84daf539f8e840469329865e256f5782","be382484c4cc4ddcaed5d89486e15270","c6c0c8c68be7422892480ab254a4e68c","3262d1705a0c42a29f449b1b28353198","0b312960b7d84feb8f1d5fed8535f7ac","b022b51031124b89b6ab9077736ac38e","5f2ce56710c44f84a0676eb98be7a10b","90368340c4a942bb841ec245ceddee6e","7b175880d47447ec805c2238aebe773a","4de78ea6642d405583ac19e76511d672","e9396d893da84e1f8514959317a7899b","5677d1bfd53c4d648a7f4a28dad7fe2b","31e953ea913143d88f15e5d5ba275629","b0a855eae57e4b69b8d1dbf9a66a68f7","932362e9b1e54a30be78340525396450","a0bd737b08c04160b6cd87dd9fa959ab","9292a90227194748b7352a86bfd7b564","104512036e0644e7a1c4c441244b51bd","fb5f2607721343abbc7bd4047f15c8d0","36b3de606e774fd5a4ceb78677794040","6e6a22a1093648bab2eacec71832b842","5eb061a2d57e4f31a0399ee722470a2d","c2e646a7843f43a691efd04922654f5d","c5e99a5672f24ed48dc3ff0a319452ea","e3cebfc78483452dadcdf19ba66b0cf1","46020196386e4e1a85c6c4b37cdffc37","4fa7384601ce4caab00667e37a9093e1","2046452f049a48fea8a0b3c212f728d6","271aa2c550c94aabbcaeb3a646ec86d0","3bcc124f4e2c485dae9b69011edffb8a","b34c27a66b9a44188fc02ff3442be918","bf57a6ad587d400196296ce03a5e747a","cffbb814364d4d8f8d8e534cdefc53c3","13762a799fab4772a6535b953b955537","82d676be5e2345018b7aafdfbf44331d","cfb1f73d0c59411baf17906a900dc1e5","b9578970c6c74597be85cdc56d86d2b3","2c58545b57a340578c1f98102c5a830e","740b09f0cae14b98898e6843cac56471","28874caa28b64e268c503510a5f0bc00","4075ae9f02a84727bae8101fc9023ed8","e2c6754ddcf44f6e96713c5726fb5155","6c02bb39a66e4bc9baa435ef7a874036","dbee0f00c28341c7a2bb9624b4ac90ef","13fe8bdd41294da5b4b20283660946fe","f47a5c8df93c4297b80b0b407b2a5935","b6417f53ef1f440ca7dd0c26759a482a","dc1de0df35484b179391e1ded9097c3f","612d5e4075a0463abb494e3b5e5d69d4","4d8d53d205874e36969119ff16e63e3e","dbd0e88b25eb4a0fad1ec58f5d8ef808","827a8f2d5fc64ccead622ecd4943ef31","1c57aa0c2a5f4d9b89e826cec5e23ca7","dbd043efac80452da9570c4359c55f2d","e71965bdee154d2c927b8227f090705b","f694c7e74ec6488ab9818c59e3dbed81","23b6e11bebd9420f85b2e6706f0ed652","6925bacaccc442fd9d95f1e174c06805","d4d17d1a24654ad0b39074209ca27748","54372bd390e64d549291d2fe937a71ff","7e7ac84b0ace46f5918e80464207fd18","664e3375840f47e2bbe76f7bfacd5535","6ae4ece682544cf39912780e314d6158","1f501737081246cb8bc3dd005d744fac","a5bbb64172854bc7afb6664e9efac615","8cfd5d5a866e4642bf101fdb81671950","42b45b2f99e04e74a6a61e6e6765c6e8","d64cd55b8c914cb294be56c7fd100311","b0654b1db31d4146bc05de70b9bdbadc","e1fc0d8789bb47e398c734ad981196f3","b78542fa903744efb5fc373c36785104","4591f0a2a0494515839ef03188e875c3","f0a7f14c2ba94bf295f322b76a4dd8f5","50c6ddf457f848e9bf81a74b79d23088","e9f8bf9330644711ace573c92b8381a9","b0aba7f75b5446c5903faed1bfb90857","2b1ad1dd87294aa89cdb9360071c4807","559559aff31247938b41498947f19060","d8d464b90a594054b9d4aa8380b78784"]},"executionInfo":{"elapsed":18476,"status":"ok","timestamp":1693145804778,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"F943dW1WVz6Q","outputId":"53b0dc31-9ef7-4a99-e304-2132b419c8fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset 124.94 MiB (download: 124.94 MiB, generated: Unknown size, total: 124.94 MiB) to /root/tensorflow_datasets/ted_hrlr_translate/it_to_pt/1.0.0...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c0e25fa7080548d6ba158b1cb4580e0d","version_major":2,"version_minor":0},"text/plain":["Dl Completed...: 0 url [00:00, ? url/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"14e86b9f3f1d43f88d6bcafa706387d4","version_major":2,"version_minor":0},"text/plain":["Dl Size...: 0 MiB [00:00, ? MiB/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"955cbc6ba61745c6831775b6c8e1956b","version_major":2,"version_minor":0},"text/plain":["Extraction completed...: 0 file [00:00, ? file/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c6c0c8c68be7422892480ab254a4e68c","version_major":2,"version_minor":0},"text/plain":["Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b0a855eae57e4b69b8d1dbf9a66a68f7","version_major":2,"version_minor":0},"text/plain":["Generating train examples...:   0%|          | 0/46259 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e3cebfc78483452dadcdf19ba66b0cf1","version_major":2,"version_minor":0},"text/plain":["Shuffling /root/tensorflow_datasets/ted_hrlr_translate/it_to_pt/1.0.0.incompleteGT2AWD/ted_hrlr_translate-trai…"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cfb1f73d0c59411baf17906a900dc1e5","version_major":2,"version_minor":0},"text/plain":["Generating validation examples...:   0%|          | 0/1162 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b6417f53ef1f440ca7dd0c26759a482a","version_major":2,"version_minor":0},"text/plain":["Shuffling /root/tensorflow_datasets/ted_hrlr_translate/it_to_pt/1.0.0.incompleteGT2AWD/ted_hrlr_translate-vali…"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6925bacaccc442fd9d95f1e174c06805","version_major":2,"version_minor":0},"text/plain":["Generating test examples...:   0%|          | 0/1669 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b0654b1db31d4146bc05de70b9bdbadc","version_major":2,"version_minor":0},"text/plain":["Shuffling /root/tensorflow_datasets/ted_hrlr_translate/it_to_pt/1.0.0.incompleteGT2AWD/ted_hrlr_translate-test…"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset ted_hrlr_translate downloaded and prepared to /root/tensorflow_datasets/ted_hrlr_translate/it_to_pt/1.0.0. Subsequent calls will reuse this data.\n"]}],"source":["examples, metadata = tfds.load('ted_hrlr_translate/it_to_pt', with_info=True, as_supervised=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QD0iNmCjWaoG"},"outputs":[],"source":["train_examples, val_examples = examples['train'], examples['validation']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1693147739083,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"3OLvHxerd8Nn","outputId":"c3d020cc-8ed4-4f93-fd0e-17634eb4d07e"},"outputs":[{"data":{"text/plain":["46259"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["num_examples_train = train_examples.cardinality().numpy()\n","num_examples_train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1693147733927,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"BchdWdY0czjL","outputId":"1a595e49-9f48-4b00-ea27-68d4759d18de"},"outputs":[{"data":{"text/plain":["1162"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["num_examples_val = val_examples.cardinality().numpy()\n","num_examples_val"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1693145814677,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"dth5DStqWZml","outputId":"d9d00953-5363-47d6-f14a-044f520f805c"},"outputs":[{"data":{"text/plain":["tensorflow.python.data.ops.prefetch_op._PrefetchDataset"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["type(train_examples)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1693147342635,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"ukAJZFvdXSGE","outputId":"be25a15a-05e9-447a-deae-0877eae6d070"},"outputs":[{"name":"stdout","output_type":"stream","text":["(<tf.Tensor: shape=(), dtype=string, numpy=b'sulle scatole grigie non gira windows hanno una tecnologia completamente diversa .'>, <tf.Tensor: shape=(), dtype=string, numpy=b'as caixas cinzentas n\\xc3\\xa3o utilizam o software windows ; s\\xc3\\xa3o uma tecnologia completamente diferente .'>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'e come fare per la nostra paura ?'>, <tf.Tensor: shape=(), dtype=string, numpy=b'e ent\\xc3\\xa3o o nosso medo ?'>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'vi dar\\xc3\\xb2 un paio di secondi .'>, <tf.Tensor: shape=(), dtype=string, numpy=b'vou dar-vos alguns segundos .'>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'e non sono i soli .'>, <tf.Tensor: shape=(), dtype=string, numpy=b'e n\\xc3\\xa3o s\\xc3\\xa3o os \\xc3\\xbanicos .'>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'e chiaramente , alla fine , le cose si sono sistemate .'>, <tf.Tensor: shape=(), dtype=string, numpy=b'e , claro , as coisas acabaram por correr bem .'>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'questa \\xc3\\xa8 una montagna .'>, <tf.Tensor: shape=(), dtype=string, numpy=b'isto \\xc3\\xa9 uma montanha .'>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'ma esiste un modo fantastico di farlo nel mondo moderno .'>, <tf.Tensor: shape=(), dtype=string, numpy=b'mas h\\xc3\\xa1 um meio fant\\xc3\\xa1stico para o fazer no mundo moderno .'>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'uno dei servizi pi\\xc3\\xb9 importanti sono le scuole improvvisate .'>, <tf.Tensor: shape=(), dtype=string, numpy=b'um dos eventos mais importantes s\\xc3\\xa3o as escolas improvisadas .'>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'ma credo che a volte non ne facciano uso quando progettano edifici . ecco un caso specifico .'>, <tf.Tensor: shape=(), dtype=string, numpy=b'mas eu acho que , por vezes , n\\xc3\\xa3o os usam quando desenham edif\\xc3\\xadcios . tenho aqui um exemplo .'>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'a cosa avreste detto di s\\xc3\\xac ?'>, <tf.Tensor: shape=(), dtype=string, numpy=b'a que \\xc3\\xa9 que teriam dito sim ?'>)\n"]}],"source":["#for elem in train_examples(10): #not callable!\n","for elem in train_examples.take(10):\n","  print(elem)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1693147365087,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"psB7WdwTWUzr","outputId":"fd660d67-0466-46ec-c470-359f5a3750f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["(<tf.Tensor: shape=(), dtype=string, numpy=b'li vedevano come un modo di pensare .'>, <tf.Tensor: shape=(), dtype=string, numpy=b'viam-no como uma reflex\\xc3\\xa3o .'>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'in corea del nord , la creai io .'>, <tf.Tensor: shape=(), dtype=string, numpy=b'na coreia do norte , eu fi-lo sozinho .'>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b\"`` per questo il tuo lavoro ha un posto molto speciale nel mio cuore ed \\xc3\\xa8 molto importante per me '' '' . una donna ha condiviso il suo ritratto su facebook scrivendo : `` '' per tutta la vita , le persone in tutto il mondo avevano difficolt\\xc3\\xa0 a inserirmi in un gruppo , uno stereotipo , una casella . ''\">, <tf.Tensor: shape=(), dtype=string, numpy=b\"`` `` '' por isso , o seu trabalho tem um lugar muito especial no meu cora\\xc3\\xa7\\xc3\\xa3o `` e \\xc3\\xa9 muito importante para mim . '' uma mulher partilhou o seu retrato no facebook e escreveu : `` '' toda a minha vida , `` '' as pessoas por todo o mundo tiveram dificuldade em colocar-me num grupo , `` '' num estere\\xc3\\xb3tipo , `` '' numa caixa . ''\">)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'e comunque , nel libro fui condannato come un saccheggiatore della terra .'>, <tf.Tensor: shape=(), dtype=string, numpy=b'e , a prop\\xc3\\xb3sito , ele condenou-me como um saqueador da terra .'>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'e la reazione positiva del mercato \\xc3\\xa8 sconvolgente .'>, <tf.Tensor: shape=(), dtype=string, numpy=b'e a boa vontade do mercado \\xc3\\xa9 espantosa .'>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'pi\\xc3\\xb9 tardi , quando accompagnavo mio cugino a scuola , di solito mi prendevano per la tata .'>, <tf.Tensor: shape=(), dtype=string, numpy=b'mais tarde , quando levei o meu primo \\xc3\\xa0 escola , era habitualmente confundida com a ama .'>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'gli insegnanti .'>, <tf.Tensor: shape=(), dtype=string, numpy=b'os professores .'>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'credo nella vita reale .'>, <tf.Tensor: shape=(), dtype=string, numpy=b'eu acredito na vida real .'>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'abbiamo i criminali online .'>, <tf.Tensor: shape=(), dtype=string, numpy=b'os criminosos online .'>)\n","(<tf.Tensor: shape=(), dtype=string, numpy=b'perci\\xc3\\xb2 , parlando di questi valori noi stiamo parlando di fatti .'>, <tf.Tensor: shape=(), dtype=string, numpy=b'portanto , ao falarmos de valores estamos a falar de factos .'>)\n"]}],"source":["for elem in val_examples.take(10):\n","  print(elem)"]},{"cell_type":"markdown","metadata":{"id":"F-CxifuYeL_U"},"source":["<div style=\"line-height:0.3\">\n","<h3 style=\"color:#FF7C00  \">  Subword tokenization with a fixed vocab size </h3>\n","<div style=\"line-height:1\">\n","\n","+ Build the SubwordTextEncoder tokenizer.\n","+ Set the target vocabulary size to 2^13 subwords.       \n","</div>\n","</div>\n","The tokenizer will learn a vocabulary of size 2^13 subwords from the training corpus."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JGxB2SIpV4OY"},"outputs":[],"source":["\"\"\" Create tokenizers \"\"\"\n","tokenizer_it = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n","    (it.numpy() for it, pt in train_examples), target_vocab_size=2**13)\n","\n","tokenizer_pt = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n","    (pt.numpy() for it, pt in train_examples), target_vocab_size=2**13)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1693148027856,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"axXtWsq3WSD8","outputId":"7f2b795f-6035-4429-a773-c5183371f8d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tokenized string is [47, 3951, 171, 284, 7903]\n","The original string: há mau tempo hoje.\n"]}],"source":["sample_string_present = 'viam-no como uma reflex.'\n","sample_string = 'há mau tempo hoje.'\n","\n","tokenized_string = tokenizer_pt.encode(sample_string)\n","print('Tokenized string is {}'.format(tokenized_string))\n","\n","original_string = tokenizer_pt.decode(tokenized_string)\n","print('The original string: {}'.format(original_string))\n","\n","assert original_string == sample_string"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1693148036639,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"z_KkOIGJej_K","outputId":"96820c1c-6b64-4305-8e06-d14f794d89c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["47 ----> há \n","3951 ----> mau \n","171 ----> tempo \n","284 ----> hoje\n","7903 ----> .\n"]}],"source":["for ts in tokenized_string:\n","  print('{} ----> {}'.format(ts, tokenizer_pt.decode([ts])))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":384,"status":"ok","timestamp":1693148108234,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"PFdkp1IofXrj","outputId":"e1bfc8b0-e9b5-4969-8909-8cbb338cf2d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tokenized string is [7941, 3240, 7972, 2295, 1307, 7889, 67, 34, 4456, 7903]\n","The original string: Transformers eles são úteis.\n"]}],"source":["sample_string = 'Transformers eles são úteis.'\n","tokenized_string = tokenizer_pt.encode(sample_string)\n","original_string = tokenizer_pt.decode(tokenized_string)\n","\n","print('Tokenized string is {}'.format(tokenized_string))\n","print('The original string: {}'.format(original_string))\n","\n","assert original_string == sample_string"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1693148110325,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"m_B1vRX7fLmj","outputId":"12792035-5a0d-4185-c969-dd91c6ffa7d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["7941 ----> T\n","3240 ----> ran\n","7972 ----> s\n","2295 ----> form\n","1307 ----> ers\n","7889 ---->  \n","67 ----> eles \n","34 ----> são \n","4456 ----> úteis\n","7903 ----> .\n"]}],"source":["# Tokens can be broken down if the word is not present in the dictionary. => T, ran, s, form. ers\n","for ts in tokenized_string:\n","  print('{} ----> {}'.format(ts, tokenizer_pt.decode([ts])))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I1Zgt8Ixfdru"},"outputs":[],"source":["BUFFER_SIZE = 100 #20000\n","BATCH_SIZE = 4 #64"]},{"cell_type":"markdown","metadata":{"id":"2P2kVgwvfuZ1"},"source":["<h2 style=\"color:#FF7C00  \"> <b> Encoding </b></h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AjYLbDLTgG_Q"},"outputs":[],"source":["def encode_tokenizer(lang1, lang2):\n","    \"\"\" Encodes two language strings to sequences of subword ids.\n","    Add a start and end token to the input and target.\n","\n","    Parameters:\n","        - Tensor containing text in language 1.\n","        - Tensor containing text in language 2.\n","\n","    Details:\n","        For both languages:\n","        - Add special start token index (tokenizer vocab size) to start of lang1 encoding.\n","            - lang1 need to be converted from a tensor to numpy string to be encoded\n","            - Add special end token index (vocab size + 1) to end of lang1 encoding\n","\n","    Returns:\n","        - list of subword ids for language 1 with start/end tokens\n","        - list of subword ids for language 2 with start/end tokens\n","    \"\"\"\n","    ## Special start token index for lang1 and lang2\n","    lang1 = [tokenizer_it.vocab_size] + tokenizer_it.encode(lang1.numpy()) + [tokenizer_it.vocab_size+1]\n","    lang2 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(lang2.numpy()) + [tokenizer_pt.vocab_size+1]\n","\n","    return lang1, lang2"]},{"cell_type":"markdown","metadata":{"id":"Nyr55sOyiFio"},"source":["<h3 style=\"color:#FF7C00\"> Recap: </h3>\n","<div style=\"margin-top: -8px;\">\n","Graph tensors don't have a value. In graph mode you can only use TensorFlow Ops and functions. <br>\n","So the function cannot be mapped directly, to apply a function to each element of the dataset, since Dataset.map runs in graph mode.\n","\n","The function must be wrapped it in a \"tf.py_function\" to pass a regular tensors to the wrapped python function.\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"waMbKa9niMGt"},"outputs":[],"source":["def tf_encode(pt, en):\n","    \"\"\" Encodes Italian and Portoguese tensors to subword sequences.\n","\n","    Parameters:\n","        - Portuguese text [tf.Tensor]\n","        - English tex [tf.Tensor]\n","\n","    Returns:\n","        - pt_encoded: encoded Portuguese text [tf.Tensor]\n","        - en_encoded: encoded English text [tf.Tensor]\n","    \"\"\"\n","    # Call encode() defined previously using tf.py_function\n","    result_pt, result_en = tf.py_function(encode_tokenizer, [pt, en], [tf.int64, tf.int64])\n","\n","    # Set static shape of [None] on encoded sequence tensors. => Required since sequence lengths can vary!\n","    result_pt.set_shape([None])\n","    result_en.set_shape([None])\n","\n","    return result_pt, result_en"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-QuJKwrwiMSM"},"outputs":[],"source":["\"\"\" Drop sample to keep example small and relatively fast and avoid RAM errors \"\"\"\n","MAX_LENGTH = 40\n","\n","def filter_max_length(x, y, max_length=MAX_LENGTH):\n","    return tf.logical_and(tf.size(x) <= max_length, tf.size(y) <= max_length)"]},{"cell_type":"markdown","metadata":{"id":"DxZ85TrDnHaK"},"source":["### => Training data creation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DHjjlEiGiMWV"},"outputs":[],"source":["# Apply encoding to the training examples\n","train_dataset = train_examples.map(tf_encode)\n","# Filter out examples longer than max length\n","train_dataset = train_dataset.filter(filter_max_length)\n","\n","# Cache encoded dataset in memory for faster training\n","train_dataset = train_dataset.cache()\n","\n","# Shuffle dataset for training, with a buffer size for shuffling\n","train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n","\n","# Batch and pad sequences for training\n","train_dataset = train_dataset.padded_batch(BATCH_SIZE)\n","\n","# Prefetch next batch while training for performance\n","train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)"]},{"cell_type":"markdown","metadata":{"id":"DJnQzmw7nRTE"},"source":["### => Validation data creation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2N7WsSeEiMlG"},"outputs":[],"source":["# Apply encoding to validation examples\n","val_dataset = val_examples.map(tf_encode)\n","\n","# Filter and batch pad validation data\n","val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":551,"status":"ok","timestamp":1693150194385,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"dL5rCwQ2iMpx","outputId":"08826608-6aa4-4a75-f836-45f9c8b4e1ae"},"outputs":[{"data":{"text/plain":["(<tf.Tensor: shape=(4, 20), dtype=int64, numpy=\n"," array([[8235,  121, 7504,   52,   21,   10,   86,    4, 1752,    2, 8236,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [8235,   12, 5613,    7,   25, 4006,    1,    8, 1605,   11,  306,\n","            2, 8236,    0,    0,    0,    0,    0,    0,    0],\n","        [8235,    3, 1937,    1,   38,  885, 7793, 6936, 4190,   61,   21,\n","           10, 6707,  255, 5051,  281,   29,  599,    2, 8236],\n","        [8235,    3,    8, 3118, 4549, 8011,   25, 1380,    6, 5734,  701,\n","            2, 8236,    0,    0,    0,    0,    0,    0,    0]])>,\n"," <tf.Tensor: shape=(4, 20), dtype=int64, numpy=\n"," array([[8113, 1049, 7966, 7902,   22,   21,   10, 7466,  102,    2, 8114,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0],\n","        [8113,   24, 3184,  155,   15, 1358,    1,   27,  743, 7902,  245,\n","         3747,    2, 8114,    0,    0,    0,    0,    0,    0],\n","        [8113, 7958,    1,    3, 2155,    1,   60, 6174,  294, 7902,   37,\n","           21,    9,  555,   97, 4240,   19,  589,    2, 8114],\n","        [8113,    6,    3,  520, 3352,   15, 1421,    8, 5000,    2, 8114,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0]])>)"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\" Retrieve a batch of validation data from the val_dataset. \"\"\"\n","pt_batch, en_batch = next(iter(val_dataset))\n","pt_batch, en_batch"]},{"cell_type":"markdown","metadata":{"id":"bvrAyDDhnaSI"},"source":["<div style=\"line-height:0.1\">\n","<h3 style=\"color:#FF7C00  \">  Positional encoding </h3>\n","<div style=\"line-height:1\">\n","Create a positional encoding vector to add info about the relative position of the words in the sentence.     \n","Positional encoding formula:\n","</div>\n","</div>\n","\n","$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n","$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YRZGfV-YoI1w"},"outputs":[],"source":["def get_angles(pos, i, model_dim):\n","    \"\"\" Calculate angle rates based on position and dimension index. \"\"\"\n","    # i // 2 divides i by 2 and floors the result (index 0 gets rate for dimension 0, index 1 gets rate for dimension 1 etc.)\n","    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(model_dim))\n","\n","    # Apply angle rates to position index\n","    return pos * angle_rates"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dfylqothoI9Z"},"outputs":[],"source":["def positional_encoding(position, model_dim):\n","    \"\"\" Performe positional encodings for transformer input.\n","\n","    Parameters:\n","        - Maximum sequence length/positional index [int]\n","        - Dimensionality of model embeddings [int]\n","\n","    Details: \n","        - Get positional encoding angles based on position and model dimension\n","        - Apply sin function to even indices in 'angle_rads'\n","        - Apply cos function to odd indices in 'angle_rads'\n","        - Expand added axis for batch dimension\n","        - Cast to TF float32 tensor\n","\n","    Returns:\n","        Positional encodings with shape (1, position, model_dim) [tf.Tensor]\n","    \"\"\"\n","    angle_rads = get_angles(np.arange(position)[:, np.newaxis], np.arange(model_dim)[np.newaxis, :], model_dim)\n","    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","    \n","    pos_encoding = angle_rads[np.newaxis, ...]\n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":473},"executionInfo":{"elapsed":1515,"status":"ok","timestamp":1693151856163,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"Z8Mvdk9Qs9up","outputId":"e404d999-283d-4768-95ec-845ee77c8400"},"outputs":[{"name":"stdout","output_type":"stream","text":["(1, 50, 512)\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Generate a positional encoding tensor using the function\n","pos_encoding = positional_encoding(50, 512)\n","print(pos_encoding.shape)\n","\n","# Plot using pcolormesh\n","plt.pcolormesh(pos_encoding[0], cmap='inferno')\n","plt.xlim((0, 512))\n","plt.xlabel('Depth')\n","plt.ylabel('Position')\n","# Add a colorbar showing the color mapping\n","plt.colorbar()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ON82_nJPzMx1"},"source":["<div style=\"line-height:0.2\">\n","<h3 style=\"color:#FF7C00  \"> Masking </h3>\n","<div style=\"line-height:1.2\">\n","Mask all the padding in the batch of sequence will ensure that the model does not treat padding as the input. <br>\n","Where the pad value is 0, it masks outputs a 1. Where the pad value is 1, it masks outputs as a 0.\n","</div>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UdWv-LgiuFEv"},"outputs":[],"source":["def add_padding_mask(seq):\n","    \"\"\" Create a masking tensor to mask padded values in input sequence.\n","\n","    Parameters:\n","        Input sequence [Tensor of shape [batch_size, seq_len]]\n","\n","    Details:\n","        - tf.math.equal(seq, 0) compares each element of the seq tensor to 0. \\\\\n","            It returns booleans (still a tensor) indicating which elements are equal to 0 (the padding value).\n","        - tf.cast(..., tf.float32) casts the boolean tensor to float32 to convert True to 1 and False to 0.\n","\n","    Returns:\n","        Masked values [Tensor of shape [batch_size, 1, 1, seq_len]\n","    \"\"\"\n","    # Convert padded tokens to 1, non-padded to 0\n","    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","    # Add extra dimensions for padding (batch_size, 1, 1, seq_len)\n","    sequence = seq[:, tf.newaxis, tf.newaxis, :]\n","    return sequence"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":355,"status":"ok","timestamp":1693155270325,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"cK3pLBxUuFQT","outputId":"9dd9153b-ad7f-4362-b13b-2ac76f9c9794"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n","array([[[[0., 0., 1., 1., 0.]]],\n","\n","\n","       [[[0., 0., 0., 1., 1.]]],\n","\n","\n","       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["# For example...\n","cons = tf.constant([[2, 5, 0, 0, 7], [3, 1, 4, 0, 0], [0, 0, 0, 6, 8]])\n","add_padding_mask(cons)"]},{"cell_type":"markdown","metadata":{"id":"iEfneRW3uFVM"},"source":["<div style=\"line-height:0.2\">\n","<h3 style=\"color:#FF7C00  \"> Look-ahead mask </h3>\n","<div style=\"line-height:1.2\">\n","It is necessary to mask the future tokens in a sequence when predicting. <br>\n","For instance, to predict the sixth word, the 1,2,3,4,5 words will be used.\n","</div>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6n2CvvyquFY-"},"outputs":[],"source":["def add_look_ahead_mask(size):\n","    \"\"\"Create a look-ahead mask for transformer self-attention.\n","\n","    Parameters:\n","        Size of mask matrix / max sequence length\n","\n","    Details: \n","        - Create base mask matrix with ones\n","        - Create band part matrix setting upper triangle to zero\n","        - Invert 0s and 1s to get mask #(seq_len, seq_len)\n","\n","    Returns:\n","        Mask matrix with 1s above diagonal and 0s below [tf.Tensor]\n","    \"\"\"\n","    mask = tf.ones((size, size))\n","    mask = tf.linalg.band_part(mask, -1, 0)\n","    mask = 1 - mask\n","    return mask"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1693155255134,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"wy_zqBKB2PYw","outputId":"27709655-3d63-4259-e776-3dd5ac51bcd7"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n","array([[0., 1., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 0.]], dtype=float32)>"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["### For example...\n","ran = tf.random.uniform((1, 3))\n","temp = add_look_ahead_mask(ran.shape[1])\n","temp"]},{"cell_type":"markdown","metadata":{"id":"Lr5M47aS2XqY"},"source":["<div style=\"line-height:0.2\">\n","<h2 style=\"color:#FF7C00  \"> <b> Attention calculation </b> </h2>\n","<div style=\"line-height:1.2\">\n","Attention => Scaled dot product of Queue, Key, Value vectors.    \n","\n","$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$\n","</div>\n","</div>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t0a-EAX37cY7"},"outputs":[],"source":["def scaled_dot_product_attention(q, k, v, mask):\n","    \"\"\" Calculate Scaled dot-product attention.\n","\n","    Details:\n","        - weights => q, k, v\n","            - q, k, v must have matching 1st dimensions. \n","            - k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n","        \n","        - #1 Matrix multiplication of query and key transpose\n","        - #2 Scale matmul_qk by dimensions for stability\n","        - #3 Add masking to the scaled tensor\n","        - #4 Apply Softmax to normalize the logits (on the last axis (seq_len_k) so that the scores add up to 1)\n","        - #5 Multiply weights by value vectors\n","        \n","    Parameters:\n","        - query Tensor of shape == (..., seq_len_q, depth)\n","        - key Tensor of shape == (..., seq_len_k, depth)\n","        - value Tensor of shape == (..., seq_len_v, depth_v)\n","        - mask: Optional mask on the keys, values [Float tensor with shape broadcastable to (..., seq_len_q, seq_len_k)\n","        \n","    Returns:\n","        - weighted values [Tensor of shape=[batch_size, num_queries, depth_per_key]]\n","        - attention weights [Tensor of shape=[batch_size, num_queries, num_keys]]\n","    \"\"\"\n","    \n","    matmul_qk = tf.matmul(q, k, transpose_b=True)\n","\n","    ## Scale\n","    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","    ## Mask\n","    if mask is not None:\n","        scaled_attention_logits += (mask * -1e9)\n","\n","    # Softmax\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n","    \n","    output = tf.matmul(attention_weights, v)\n","\n","    return output, attention_weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4EpNz48m7ceh"},"outputs":[],"source":["def print_attention(q, k, v):\n","    temp_out, temp_attn = scaled_dot_product_attention(q, k, v, None)\n","    print('Attention weights are:')\n","    print(temp_attn)\n","    print('Output is:')\n","    print(temp_out)"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"line-height:0.2\">\n","<h3 style=\"color:#FF7C00  \"> Step #1 </h3>\n","<div style=\"line-height:1.2\">\n","\n","+ Define keys as a constant tensor of shape (4,3). Each row represents the weights of a key\n","+ Define values as a constant tensor of shape (4,2). Each row represents a value\n","+ Define query (temp_q) as a constant tensor of shape (1,3), representing the weights of the query\n","</div>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3514,"status":"ok","timestamp":1693156784851,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"VsGe-wd87cid","outputId":"51af7d6c-7d73-4df1-dbf8-2016ce3994e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Attention weights are:\n","tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n","Output is:\n","tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"]}],"source":["# Set printing options to suppress scientific notation\n","np.set_printoptions(suppress=True)\n","\n","temp_k = tf.constant([[10,0,0],\n","                    [0,10,0],\n","                    [0,0,10],\n","                    [0,0,10]], dtype=tf.float32)  \n","\n","temp_v = tf.constant([[   1,0],\n","                    [  10,0],\n","                    [ 100,5],\n","                    [1000,6]], dtype=tf.float32)  \n","\n","temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  \n","print_attention(temp_q, temp_k, temp_v)"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"line-height:0.2\">\n","<h3 style=\"color:#FF7C00  \"> Step #2 </h3>\n","<div style=\"line-height:1.2\">\n","Redefine the query to be a constant tensor of shape (1,3), to represent a query where the weight is on the third key. <br> \n","In this way, all associated values will get averaged.\n","</div>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1693156784853,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"iSl8f0XY-s7v","outputId":"9972d575-eed9-4045-c5f8-7b8be08d4791"},"outputs":[{"name":"stdout","output_type":"stream","text":["Attention weights are:\n","tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n","Output is:\n","tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"]}],"source":["temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)\n","print_attention(temp_q, temp_k, temp_v)"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"line-height:0.2\">\n","<h3 style=\"color:#FF7C00  \"> Step #3 </h3>\n","<div style=\"line-height:1.2\">\n","Redefine the query tensor to be a constant tensor of shape (1,3), \n","to represent a query where the weights are on the first and second keys.\n","</div>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1693156784854,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"bXA0p0WD-s_j","outputId":"8dd4519f-0276-41df-e068-ca9e4ec118fe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Attention weights are:\n","tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n","Output is:\n","tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"]}],"source":["temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)\n","print_attention(temp_q, temp_k, temp_v)"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"line-height:0.2\">\n","<h3 style=\"color:#FF7C00  \"> Step #4 </h3>\n","<div style=\"line-height:1.2\">\n","Redefine the query tensor to be of shape (3,3).\n","</div>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1693156784854,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"jAMkzlQN-tDd","outputId":"317e025a-baaa-4e84-b797-8ae64ad5f66c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Attention weights are:\n","tf.Tensor(\n","[[0.  0.  0.5 0.5]\n"," [0.  1.  0.  0. ]\n"," [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n","Output is:\n","tf.Tensor(\n","[[550.    5.5]\n"," [ 10.    0. ]\n"," [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"]}],"source":["temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)\n","print_attention(temp_q, temp_k, temp_v)"]},{"cell_type":"markdown","metadata":{"id":"8elfp32B-tGx"},"source":["<h2 style=\"color:#FF7C00  \"> <u> <b> Multi-head attention</u> </b></h2> "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CxUlM5ld-tKb"},"outputs":[],"source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","    \"\"\"A custom layer implementing Multi-Head Attention. \\\\\n","    The class inherits from 'tf.keras.layers.Layer'. \\\\\n","\n","    This layer implements the multi-head attention mechanism commonly used in transformer models \\\\\n","    for various natural language processing tasks. It projects input queries, keys, and values \\\\\n","    to a specified model dimension, splits them into multiple attention heads, computes attention \\\\\n","    scores and weights, and then combines the heads' outputs to generate the final attention output.\n","\n","    Args:\n","        - Dimensionality of the model [int]\n","        - Number of attention heads to use [int]\n","\n","    Attributes:\n","        - Number of attention heads [int]\n","        - Model's dimension [int]\n","        - Depth of each individual attention head [int]\n","        - wq: Dense layer for query projection [tf.keras.layers.Dense]\n","        - wk: Dense layer for key projection [tf.keras.layers.Dense]\n","        - wv: Dense layer for value projection [tf.keras.layers.Dense]\n","        - dense: Final Dense layer for output projection [tf.keras.layers.Dense]\n","\n","    Methods:\n","        - split_heads(x, batch_size): Splits the last dimension of an input tensor into multiple \\\\\n","            heads and reorganizes dimensions for attention calculations.\n","        - call(v, k, q, mask): Performs multi-head attention on input values, keys, and queries.\n","\n","    Returns:\n","        - The final attention output [tf.Tensor]\n","        - Attention weights computed during the attention calculation [tf.Tensor]\n","    \"\"\"\n","    def __init__(self, d_model, num_heads):\n","        \"\"\" Constructor method, taking d_model (model dimension) and num_heads as arguments. \"\"\"\n","\n","        # Call the parent class constructor\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        # Ensure d_model is divisible by num_heads\n","        assert d_model % self.num_heads == 0\n","        \n","        # Calculate depth per attention head\n","        self.depth = d_model // self.num_heads\n","\n","        #### Create Dense layers for query, key, value projections + output\n","        self.wq = tf.keras.layers.Dense(d_model)\n","        self.wk = tf.keras.layers.Dense(d_model)\n","        self.wv = tf.keras.layers.Dense(d_model)\n","        self.dense = tf.keras.layers.Dense(d_model)\n","\n","\n","    def split_heads(self, x, batch_size):\n","        \"\"\" Split the last dimension of the given tensor into multiple heads.\n","\n","        Parameters:\n","            - Input tensor to be split [tf.Tensor]\n","            - atch size of the input [int]\n","\n","        Details: \n","            - Reshape the tensor to have the shape (batch_size, seq_len, num_heads, depth), \\\\\n","                where seq_len is the length of the sequence.\n","            - Transpose for proper dimensions.\n","\n","        Returns:\n","            Reshaped tensor, with dimensions (batch_size, num_heads, seq_len, depth)\n","        \"\"\"\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        tra = tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","        return tra\n","\n","    def call(self, v, k, q, mask):\n","        \"\"\" Performs multi-head attention on input values, keys, and queries.\n","\n","        Parameters:\n","            - Values tensor [tf.Tensor]\n","            - Keys tensor [tf.Tensor]\n","            - Queries tensor [tf.Tensor]\n","            - Mask for certain elements of the attention [tf.Tensor]\n","\n","        Details: \n","            - Get the batch size\n","            - Project queries using the Dense layer (batch_size, seq_len, d_model)\n","            - Project keys (batch_size, seq_len, d_model)\n","            - Project values (batch_size, seq_len, d_model)\n","            - Split queries, keys, and values into multi-head format # (batch_size, num_heads, seq_len_q, depth)\n","            - Calculate scaled dot-product attention and attention weights\n","            - Transpose attention output for proper dimensions\n","            - Reshape attention output for concatenation\n","            - Pass concatenated attention output through the Dense layer\n","\n","        Returns:\n","            - The final attention output\n","            - Attention weights computed during the attention calculation [tf.Tensor]\n","        \"\"\"\n","        batch_size = tf.shape(q)[0]\n","        ### Project\n","        q = self.wq(q)\n","        k = self.wk(k)\n","        v = self.wv(v)\n","\n","        ### Split\n","        q = self.split_heads(q, batch_size)\n","        k = self.split_heads(k, batch_size)\n","        v = self.split_heads(v, batch_size)\n","\n","        # Calculate \n","        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n","        # Transpose \n","        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","        # Reshape\n","        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n","        # Pass to last\n","        output = self.dense(concat_attention)\n","\n","        return output, attention_weights\n"]},{"cell_type":"markdown","metadata":{"id":"eQKCkcd7FyMn"},"source":["<h3 style=\"color:#FF7C00  \">  Note:</h3>\n","<div style=\"margin-top: -8px;\">\n","The MultiHeadAttention runs all 8 attention heads across all other locations in the sequence, returning a new vector of the same length at each location."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":583,"status":"ok","timestamp":1693158274560,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"xuVyHFSn-tN7","outputId":"a80c0f73-037c-48da-f965-375e79251497"},"outputs":[{"data":{"text/plain":["(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["# Create an instance of the MultiHeadAttention class with specified model dimension and number of heads\n","temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n","\n","# Generate a random input tensor 'y' with shape (batch_size, encoder_sequence, d_model)\n","y = tf.random.uniform((1, 60, 512))\n","\n","# Perform multi-head attention using the created instance. Pass 'y' as queries, keys, and values, and 'None' as the mask\n","out, attn = temp_mha(y, k=y, q=y, mask=None)\n","\n","out.shape, attn.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hNON7jGX-tQv"},"outputs":[],"source":["def create_feed_forward_network(d_model, dff):\n","    \"\"\" Create a feed-forward neural network for the transformer, consisting in two fully connected layers.\n","\n","    Parameters:\n","        - Dmensionality of the model's output [int]\n","        - Number of units in the feed-forward layer [int]\n","\n","    Returns:\n","        Sequential model consisting of a Dense layer with ReLU activation, followed by another Dense layer [tf.keras.Sequential]\n","    \"\"\"\n","    return tf.keras.Sequential([\n","        tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n","        tf.keras.layers.Dense(d_model)                  # (batch_size, seq_len, d_model)\n","    ])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1693158357837,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"smjGK1wWGTmM","outputId":"d0a7bde2-c640-461a-d01d-efdc2b00fe0c"},"outputs":[{"data":{"text/plain":["TensorShape([64, 50, 512])"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["sample_ffn = create_feed_forward_network(512, 2048)\n","sample_ffn(tf.random.uniform((64, 50, 512))).shape"]},{"cell_type":"markdown","metadata":{"id":"0vr4_9epGjXA"},"source":["<div style=\"line-height:0.2\">\n","<h3 style=\"color:#EF380D  \"> <b> Build Encoder and Decoder </b></h3>\n","<div style=\"line-height:1.2\">\n","Each encoder layer consists of sublayers:\n","\n","1.   Multi-head attention (with padding mask)\n","2.    Point wise feed forward networks.\n","\n","<div style=\"line-height:0.7\">\n","Each decoder layer consists of sublayers:\n","</div>\n","<div style=\"line-height:1.2\">\n","\n","1.   Masked multi-head attention (with look ahead mask and padding mask).\n","2.   Multi-head attention (with padding mask). <br>\n","    - V (value) and K (key) receive the encoder output as inputs. <br>\n","    - Q (query) receives the output from the masked multi-head attention sublayer. <br>\n","3.   Point wise feed forward networks.\n","\n","</div>\n","</div>\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"ya1HizowGw4u"},"source":["<h3 style=\"color:#FF7C00  \"> 1) Encoder layer </h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A83wqXcLGxBe"},"outputs":[],"source":["class EncoderLayer(tf.keras.layers.Layer):\n","    \"\"\" Encoder layer in a transformer model. Class inherits from tf.keras.layers.Layer. \\\\\n","    It consists of multi-head self-attention followed by a point-wise feed-forward network. \\\\\n","    It applies layer normalization and dropout to stabilize and regularize the learning process.\n","\n","    Args:\n","        - Dimensionality of the model [int]\n","        - Number of attention heads [int]\n","        - Dimension of the feed-forward network (dff) [int]\n","        - Dropout rate (optional, default: 0.1) [float]\n","\n","    Attributes:\n","        - MultiHeadAttention instance [MultiHeadAttention object]\n","        - Point-wise feed-forward network [tf.keras.Sequential]\n","        - First layer normalization [tf.keras.layers.LayerNormalization]\n","        - Second layer normalization [tf.keras.layers.LayerNormalization]\n","        - First dropout layer [tf.keras.layers.Dropout]\n","        - Second dropout layer [tf.keras.layers.Dropout]\n","\n","    Methods:\n","        call(x, training, mask): Apply the encoder layer's operations on the input.\n","\n","    Returns:\n","        The final output tensor after encoder layer operations [tf.Tensor]\n","    \"\"\"\n","\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        \"\"\" Initializations. \"\"\"\n","        # Call the parent class constructor\n","        super(EncoderLayer, self).__init__()\n","        \n","        # Create a MultiHeadAttention instance with given d_model and num_heads\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        # Create a point-wise feed-forward network with specified d_model and dff\n","        self.ffn = create_feed_forward_network(d_model, dff)\n","\n","        ## Create LayerNormalization layers with epsilon for stabilization\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","        ## Create Dropout layers with the given dropout rate\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, x, training_yes_or_no, mask):\n","        \"\"\" Encode the input with multi-head attention.\n","\n","        Parameters:\n","            - Input tensor [tf.Tensor]\n","            - Value to specify the model is in training mode [Bool]\n","            - Mask tensor for attention masking [tf.Tensor]\n","\n","        Details: \n","            - Apply multi-head attention on the input tensor x, using itself as queries, keys, and values \\\\\n","                (batch_size, input_seq_len, d_model)\n","            - Apply dropout\n","            - Add and normalize using LayerNormalization\n","\n","            - Apply point-wise feed-forward network on the output from previous step (batch_size, input_seq_len, d_model)\n","            - Apply dropout\n","            - Add and normalize using LayerNormalization\n","        \n","        Returns:\n","            Final output after encoder layer operations [tf.Tensor]\n","        \"\"\"\n","        attn_output, _ = self.mha(x, x, x, mask)\n","        attn_output = self.dropout1(attn_output, training=training_yes_or_no)\n","        out1 = self.layernorm1(x + attn_output)\n","\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training_yes_or_no)\n","        out2 = self.layernorm2(out1 + ffn_output)\n","\n","        return out2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":353,"status":"ok","timestamp":1693159112231,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"YsawN6qlGxFu","outputId":"12d1f5b0-2a47-4567-e86c-911e25ac7aec"},"outputs":[{"data":{"text/plain":["TensorShape([64, 43, 512])"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["sample_encoder_layer = EncoderLayer(512, 8, 2048)\n","\n","sample_encoder_layer_output = sample_encoder_layer(tf.random.uniform((64, 43, 512)), False, None)\n","\n","sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"]},{"cell_type":"markdown","metadata":{},"source":["<h3 style=\"color:#FF7C00  \"> 2) Decoder layer </h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pVF2rYoQGxIx"},"outputs":[],"source":["class DecoderLayer(tf.keras.layers.Layer):\n","    \"\"\" Single layer of the decoder in a transformer model.\n","        Class inherits from tf.keras.layers.Layer\n","        - multi-head self-attention \n","        - multi-head attention with encoder output \n","        - point-wise feed-forward network operations \n","        - normalization \n","        - dropout\n","\n","    Args:\n","        - Dimensionality of the model [int]\n","        - Number of attention heads [int]\n","        - Dimension of the feed-forward network (dff) [int]\n","        - Dropout rate (default: 0.1) [float, optional]\n","\n","    Attributes:\n","        - First multi-head attention instance [MultiHeadAttention]\n","        - Second multi-head attention instance [MultiHeadAttention]\n","        - Point-wise feed-forward network [tf.keras.Sequential]\n","        - First layer normalization [tf.keras.layers.LayerNormalization]\n","        - Second layer normalization [tf.keras.layers.LayerNormalization]\n","        - Third layer normalization [tf.keras.layers.LayerNormalization]\n","        - First dropout layer [tf.keras.layers.Dropout]\n","        - Second dropout layer [tf.keras.layers.Dropout]\n","        - Third dropout layer [tf.keras.layers.Dropout]\n","\n","    Methods:\n","        call(x, enc_output, training, look_ahead_mask, padding_mask):\\\\\n","        Apply the decoder layer's operations on the input.\n","\n","    Returns:\n","        - Final output tensor after decoder layer operations [tf.Tensor]\n","        - Attention weights from the first multi-head attention operation [tf.Tensor]\n","        - Attention weights from the second multi-head attention operation [tf.Tensor]\n","    \"\"\"\n","\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        \"\"\" Constructor. \"\"\"\n","        # Call the parent class constructor\n","        super(DecoderLayer, self).__init__()\n","\n","        ## Create MultiHeadAttention instances\n","        self.mha1 = MultiHeadAttention(d_model, num_heads)\n","        self.mha2 = MultiHeadAttention(d_model, num_heads)\n","\n","        # Create a point-wise feed-forward network\n","        self.ffn = create_feed_forward_network(d_model, dff)\n","\n","        ### Create LayerNormalization layers with epsilon for stabilization\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","        #### Create Dropout layers with the given dropout rate\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","        self.dropout3 = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, x, enc_output, training_yes_or_no, look_ahead_mask, padding_mask):\n","        \"\"\" Decoder layer's operations on the input.\n","\n","        Parameters:\n","            - Input x [tf.Tensor]\n","            - Encoder output tensor [tf.Tensor]\n","            - Value to specify if the model is in training mode or not [Bool]\n","            - Mask for look-ahead attention [tf.Tensor]\n","            - Mask for padding [tf.Tensor]\n","\n","        Details: \n","            - 1  \n","                - Apply multi-head attention within the decoder layer\n","                - Apply dropout\n","                - Add and normalize using LayerNormalization\n","            - 2\n","                - Apply multi-head attention to combine with encoder outputs\n","                - Apply dropout\n","                - Add and normalize using LayerNormalization\n","            - 3\n","                - Apply point-wise feed-forward network to the output of the previous step\n","                - Apply dropout\n","                - Add and normalize using LayerNormalization\n","        \n","        Returns:\n","            - Final output tensor after decoder layer operations [tf.Tensor]\n","            - Attention weights from the first multi-head attention operation [tf.Tensor]\n","            - Attention weights from the second multi-head attention operation [tf.Tensor]\n","        \"\"\"\n","        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n","        attn1 = self.dropout1(attn1, training=training_yes_or_no)  \n","        out1 = self.layernorm1(attn1 + x)  \n","        \n","        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n","        attn2 = self.dropout2(attn2, training=training_yes_or_no)  \n","        out2 = self.layernorm2(attn2 + out1)  \n","\n","        ffn_output = self.ffn(out2)\n","        ffn_output = self.dropout3(ffn_output, training=training_yes_or_no)  \n","        out3 = self.layernorm3(ffn_output + out2) \n","\n","        return out3, attn_weights_block1, attn_weights_block2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":510,"status":"ok","timestamp":1693161115679,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"A6VQ9Aa-GxL6","outputId":"d8f931de-9edf-4b4f-e87e-ea8148eb64fa"},"outputs":[{"data":{"text/plain":["TensorShape([64, 50, 512])"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["sample_decoder_layer = DecoderLayer(512, 8, 2048)\n","\n","sample_decoder_layer_output, _, _ = sample_decoder_layer(tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, False, None, None)\n","\n","sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"line-height:0.2\">\n","<h3 style=\"color:#EF380D  \"> <b> Encoder creation </b></h3>\n","<div style=\"line-height:1.2\">\n","\n","1.   Input Embedding\n","2.   Positional Encoding\n","3.   N encoder layers\n","</div>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mPCtNjjvGxS2"},"outputs":[],"source":["class Encoder(tf.keras.layers.Layer):\n","    \"\"\" The Encoder component of a transformer model. \\\\\n","    Stack of identical EncoderLayers, with an embedding layer and positional encoding. \\\\\n","    It applies self-attention and feed-forward operations on the input.\n","\n","    Args:\n","        - Number of EncoderLayers [int]\n","        - Dimensionality of the model [int]\n","        - Number of attention heads [int]\n","        - Dimension of the feed-forward network [int]\n","        - Vocabulary size of the input data [int]\n","        - Maximum position for positional encoding [int]\n","        - The dropout rate (default: 0.1) [float, optional]\n","\n","    Attributes:\n","        -  Dimensionality of the model [int]\n","        -  Number of EncoderLayers in the Encoder [int]\n","        -  Embedding layer for input sequences [tf.keras.layers.Embedding]\n","        -  Positional encoding matrix [tf.Tensor]\n","        -  List of EncoderLayer instances [list]\n","        -  Dropout layer [tf.keras.layers.Dropout]\n","\n","    Methods:\n","        call(x, training, mask): Apply the Encoder's operations on the input.\n","\n","    Returns:\n","        Final output tensor after Encoder operations [tf.Tensor]\n","    \"\"\"\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n","                maximum_position_encoding, rate=0.1):\n","        super(Encoder, self).__init__()  # Call the parent class constructor\n","\n","        # Set class attributes\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        # Create an embedding layer for input sequences\n","        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n","        # Create a positional encoding matrix\n","        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n","\n","        # Create a list of EncoderLayer instances\n","        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","\n","        # Create a dropout layer with the given dropout rate\n","        self.dropout = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, x, training_yes_or_not, mask):\n","        \"\"\" Encoder's operations on the input.\n","\n","        Args:\n","            - The input tensor [tf.Tensor]\n","            - Value to check when the model is in training mode [bool]\n","            - A mask tensor to mask certain elements [tf.Tensor]\n","\n","        Returns:\n","            The final output tensor after Encoder operations [tf.Tensor]\n","        \"\"\"\n","        # Get the sequence length from the input tensor 'x'\n","        seq_len = tf.shape(x)[1]\n","\n","        # Apply embedding and add positional encoding\n","        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","\n","        # Apply dropout to the input\n","        x = self.dropout(x, training=training_yes_or_not)\n","\n","        # Iterate through the list of EncoderLayer instances\n","        for i in range(self.num_layers):\n","            x = self.enc_layers[i](x, training_yes_or_not, mask)\n","\n","        # Return the final output of the encoder (batch_size, input_seq_len, d_model)\n","        return x\n"]},{"cell_type":"markdown","metadata":{"id":"uQ7JJ789M9_-"},"source":["<div style=\"line-height:0.2\">\n","<h3 style=\"color:#EF380D  \"> <b> Decoder creation </b></h3>\n","<div style=\"line-height:1.2\">\n","\n","1.  Output Embedding     \n","2.  Positional Encoding     \n","3.  N decoder layers   \n","</div>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J_QggEGkM-JC"},"outputs":[],"source":["class Decoder(tf.keras.layers.Layer):\n","    \"\"\" The Decoder component of a transformer model. \\\\\n","    Stack of identical DecoderLayers, with an embedding layer and positional encoding. \\\\\n","    It applies self-attention, multi-head attention with encoder output, and feed-forward operations on the input.\n","\n","    Parameters:\n","        - Number of DecoderLayers in the Decoder [int]\n","        - Dimensionality of the model [int]\n","        - Number of attention heads [int]\n","        - Dimension of the feed-forward network (dff) [int]\n","        - Vocabulary size of the target data [int]\n","        - Maximum position for positional encoding [int]\n","        - Dropout rate (default: 0.1) [float, optional]\n","\n","    Attributes:\n","        - Dimensionality of the model [int]\n","        - Number of DecoderLayers in the Decoder [int]\n","        - Embedding layer for target sequences [tf.keras.layers.Embedding]\n","        - Positional encoding matrix [tf.Tensor]\n","        - List of DecoderLayer instances [list]\n","        - Dropout layer [tf.keras.layers.Dropout]\n","\n","    Methods:\n","        call(x, enc_output, training, look_ahead_mask, padding_mask): Apply the Decoder's operations on the input.\n","\n","    Returns:\n","        - Final output tensor after Decoder operations [tf.Tensor]\n","        - Attention weights from DecoderLayers [dict]\n","    \"\"\"\n","    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n","        \"\"\" Constructor. \"\"\"\n","        # Call the parent class constructor\n","        super(Decoder, self).__init__()\n","\n","        # Set class attributes\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        # Create an embedding layer for target sequences\n","        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n","        # Create a positional encoding matrix\n","        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n","\n","        # Create a list of DecoderLayer instances\n","        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","\n","        # Create a dropout layer with the given dropout rate\n","        self.dropout = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, x, enc_output, training_yes_or_not, look_ahead_mask, padding_mask):\n","        \"\"\" Decoder's operations on the input.\n","\n","        Args:\n","            - Input x [tf.Tensor]\n","            - Encoder output [tf.Tensor]\n","            - Value to state whether the model is in training mode [Bool]\n","            - Mask for look-ahead attention [tf.Tensor]\n","            - Mask for padding [tf.Tensor]\n","\n","        Returns:\n","            Final output tensor after Decoder operations [Tensor of shape (batch_size, target_seq_len, d_model)]\n","            Attention weights from DecoderLayers [dict]\n","        \"\"\"\n","        # Get the sequence length from the input tensor 'x'\n","        seq_len = tf.shape(x)[1]\n","        # Create a dictionary to store attention weights\n","        attention_weights = {}\n","\n","        # Apply embedding and add positional encoding to the input\n","        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","\n","        # Apply dropout to the input\n","        x = self.dropout(x, training=training_yes_or_not)\n","\n","        # Iterate through the list of DecoderLayer instances\n","        for i in range(self.num_layers):\n","            # Apply decoder layer operations and get attention weights\n","            x, block1, block2 = self.dec_layers[i](x, enc_output, training_yes_or_not, look_ahead_mask, padding_mask)\n","\n","            # Store attention weights in the dictionary\n","            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n","            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n","\n","        # Return the final output of the decoder and attention weights\n","        return x, attention_weights\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":532,"status":"ok","timestamp":1693161157653,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"8cvdKECuQmeW","outputId":"65e333a8-da0c-4365-c795-e643ea40770c"},"outputs":[{"name":"stdout","output_type":"stream","text":["(64, 62, 512)\n"]}],"source":["sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, dff=2048, input_vocab_size=8500,\n","                        maximum_position_encoding=10000)\n","temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n","\n","sample_encoder_output = sample_encoder(temp_input, training_yes_or_not=False, mask=None)\n","\n","# shape (batch_size, input_seq_len, d_model)\n","sample_encoder_output.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1693161158502,"user":{"displayName":"Ben Goshi","userId":"05767231154074524663"},"user_tz":-120},"id":"hu1NxXykM-NT","outputId":"423e13ea-620e-48ce-c5b2-9b5360e21f64"},"outputs":[{"data":{"text/plain":["(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, dff=2048, target_vocab_size=8000,\n","                        maximum_position_encoding=5000)\n","temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n","\n","output, attn = sample_decoder(temp_input, enc_output=sample_encoder_output, training_yes_or_not=False,look_ahead_mask=None, padding_mask=None)\n","\n","# Shape\n","output.shape, attn['decoder_layer2_block2'].shape"]},{"cell_type":"markdown","metadata":{"id":"lYbaGdaEM-RI"},"source":["<h3 style=\"color:#EF380D  \"> <b> Transformer creation </b></h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nwtovvlFM-Um"},"outputs":[],"source":["class Transformer(tf.keras.Model):\n","    \"\"\" The Transformer model that combines the Encoder and Decoder. \\\\\n","        Encoder + Decoder + final dense layer.\n","\n","    Parameters:\n","        - Number of layers in both Encoder and Decoder [int]\n","        - Dimensionality of the model [int]\n","        - Number of attention heads [int]\n","        - Dimension of the feed-forward network [int]\n","        - Vocabulary size of the input data [int]\n","        - Vocabulary size of the target data [int]\n","        - Maximum position for positional encoding in the input [int]\n","        - Maximum position for positional encoding in the target [int]\n","        - Dropout rate (default: 0.1) [float, optional]\n","\n","    Attributes:\n","        - Encoder instance [Encoder obj]\n","        - Decoder instance [Decoder obj]\n","        - Dense layer for final output [tf.keras.layers.Dense]\n","\n","    Methods:\n","        call(inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n","            Apply the Transformer's operations on the input.\n","\n","    Returns:\n","        - Final output after Transformer operations [tf.Tensor]\n","        - Attention weights from DecoderLayers [dict]\n","    \"\"\"\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n","        \"\"\" Constructor. \"\"\"\n","        # Initialize the parent\n","        super(Transformer, self).__init__()\n","\n","        # Create an Encoder instance\n","        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n","        # Create a Decoder instance\n","        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n","        # Create a dense layer for the final output\n","        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n","\n","    def call(self, inp, tar, training_or_not, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n","        \"\"\" Encode and decode.\n","\n","        Parameters:\n","            - Input tensor [tf.Tensor]\n","            - Target tensor [tf.Tensor]\n","            - Whether the model is in training mode [bool]\n","            - Mask for padding in encoder input (enc_padding_mask) [tf.Tensor]\n","            - Mask for look-ahead attention in decoder [tf.Tensor]\n","            - Mask for padding in decoder input [tf.Tensor]\n","\n","        Details: \n","            - Apply encoder operations to input data\n","            - Apply decoder operations to generate final output and attention weights\n","            - Apply a dense layer to get the final output\n","\n","        Returns:\n","            - Final output tensor after Transformer operations [tf.Tensor]\n","            - Attention weights from DecoderLayers [dict]\n","        \"\"\"\n","        enc_output = self.encoder(inp, training_or_not, enc_padding_mask)\n","        dec_output, attention_weights = self.decoder(tar, enc_output, training_or_not, look_ahead_mask, dec_padding_mask)\n","        final_output = self.final_layer(dec_output)\n","\n","        return final_output, attention_weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ba7A9BcNRn6V"},"outputs":[],"source":["sample_transformer = Transformer(num_layers=2, d_model=512, num_heads=8, dff=2048,\n","    input_vocab_size=8500, target_vocab_size=8000,\n","    pe_input=10000, pe_target=6000)\n","\n","temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n","temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n","\n","#N.B => fn_out shape is  (batch_size, tar_seq_len, target_vocab_size)\n","fn_out, _ = sample_transformer(temp_input, temp_target, training=False, enc_padding_mask=None, \n","            look_ahead_mask=None, dec_padding_mask=None)\n","\n","fn_out.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"knFLyoi5Rn-k"},"outputs":[],"source":["\"\"\" Hyperparameters \"\"\"\n","num_layers = 4  #6\n","d_model = 128   #512\n","dff = 512       #2048\n","num_heads = 8\n","\n","input_vocab_size = tokenizer_pt.vocab_size + 2\n","target_vocab_size = tokenizer_it.vocab_size + 2\n","dropout_rate = 0.1"]},{"cell_type":"markdown","metadata":{"id":"diTOl88xRoCg"},"source":["<h3 style=\"color:#FF7C00  \"> => Optimizer </h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NlnM0UvdRoGP"},"outputs":[],"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    \"\"\" Learning rate schedule class for a Transformer model.\n","\n","    Parameters:\n","        - Dimensionality of the model [tf.Tensor]\n","        - Number of warmup steps [int]\n","\n","    Attributes:\n","        - Dimensionality of the model [tf.Tensor]\n","        - Number of warmup steps [int]\n","\n","    Methods:\n","        __call__(step): Calculate and return the learning rate.\n","\n","    Returns:\n","        Learning rate [tf.Tensor]\n","    \"\"\"\n","    def __init__(self, d_model, warmup_steps=4000):\n","        # Call the constructor of the parent \n","        super(CustomSchedule, self).__init__()\n","\n","        ## Store the dimensionality of the model and cast it to float32\n","        self.d_model = d_model\n","        self.d_model = tf.cast(self.d_model, tf.float32)\n","        # Store the number of warmup steps\n","        self.warmup_steps = warmup_steps\n","\n","    def __call__(self, step):\n","        \"\"\" Calculate and return the learning rate for the given step.\n","        \n","        This is typically used in learning rate warm-up strategies where the learning rate gradually increases\\\\\n","        at the beginning of training. The d_model typically represents the dimensionality of the model's hidden states.\n","\n","        Parameters:\n","            Current optimization step [tf.Tensor]\n","        \n","        Details: \n","            - Calculate the argument for the rsqrt function, to control the rate of decay as training progresses.\\\\\n","            It calculates the reciprocal square root of the input step. [1 / sqrt(step)]. \n","            - Calculate the argument for the minimum function, multiplying the step by the reciprocal\\\\ \n","            of self.warmup_steps raised to the power of -1.5.\\\\\n","            The goal is increasing the learning rate at the beginning of training.\n","            - Get the learning rate as product of_\n","                - Reciprocal square root of self.d_model (represents the dimensionality of the model's hidden states). \n","                - Element-wise minimum between arg1 and arg2. to ensure that the learning rate does not increase too quickly.\n","        \n","        Returns:\n","            Learning rate [tf.Tensor]\n","        \"\"\"\n","        arg1 = tf.math.rsqrt(step)\n","        arg2 = step * (self.warmup_steps ** -1.5)\n","        lr_rate = tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n","        return lr_rate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S_aDd3fBRoJT"},"outputs":[],"source":["learning_rate = CustomSchedule(d_model)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6xmHZcITofMn"},"outputs":[],"source":["temp_learning_rate_schedule = CustomSchedule(d_model)\n","\n","plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n","plt.ylabel(\"Learning Rate\")\n","plt.xlabel(\"Train Step\")"]},{"cell_type":"markdown","metadata":{"id":"EMdJo8jboicf"},"source":["<h3 style=\"color:#FF7C00  \"> => Metrics </h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qw_62cs1oitb"},"outputs":[],"source":["loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wiCr61p6oiws"},"outputs":[],"source":["def transformer_loss_function(real, pred):\n","    \"\"\" Calculate the loss for the predicted sequence compared to the target sequence.\\\\\n","    It is necessary to apply a padding mask when calculating the loss.\n","    \n","    Parameters:\n","        - target [tf.Tensor]\n","        - predicted [tf.Tensor]\n","\n","    Details: \n","        - Create a boolean mask where non-padding elements are True\n","        - Calculate the initial loss using the loss_object\n","        - Cast the mask to the data type of loss_\n","        - Multiply the loss with the mask to only consider non-padding elements\n","        - Calculate the mean loss over non-padding elements\n","\n","    Returns:\n","        Loss value [tf.Tensor]\n","    \"\"\"\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    loss_ = loss_object(real, pred)\n","    mask = tf.cast(mask, dtype=loss_.dtype)\n","    loss_ *= mask\n","    \n","    mean_loss_over = tf.reduce_sum(loss_) / tf.reduce_sum(mask)\n","    return mean_loss_over"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6FnghOaZoi0O"},"outputs":[],"source":["train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4PdEQAbWoi3H"},"outputs":[],"source":["train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n","train_accuracy"]},{"cell_type":"markdown","metadata":{"id":"VFfwBVxdoi6F"},"source":["<h3 style=\"color:#FF7C00  \"> => Training </h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZC6epS9boi9A"},"outputs":[],"source":["my_transformer = Transformer(num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size,\n","                        pe_input=input_vocab_size, pe_target=target_vocab_size,rate=dropout_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z3JrNNOapnPf"},"outputs":[],"source":["def create_masks(inp, tar):\n","    \"\"\" Create masks for input sequences and target sequences in a Transformer model.\n","\n","    Parameters:\n","        - input [tf.Tensor]\n","        - target [tf.Tensor]\n","\n","    Details:\n","        - dec_padding_mask:\\\\\n","        Used in the 2nd attention block in the decoder, to mask the encoder outputs.\n","        - combined_mask:\\\\\n","        Used in the 1st attention block in the decoder, to pad and mask future tokens in the input received by the decoder.\n","\n","    Returns:\n","        - Mask for padding in encoder input [tf.Tensor]\n","        - Combined mask for decoder input [tf.Tensor]\n","        - Mask for padding in decoder input [tf.Tensor]\n","    \"\"\"\n","    # Create a mask for padding in encoder input\n","    enc_padding_mask = create_padding_mask(inp)\n","    # Create a mask for padding in decoder input\n","    dec_padding_mask = create_padding_mask(inp)\n","\n","    # Create a mask for look-ahead attention in decoder input\n","    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n","    # Create a mask for padding in decoder target\n","    dec_target_padding_mask = create_padding_mask(tar)\n","    # Combine the look-ahead mask and decoder target padding mask\n","    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n","\n","    return enc_padding_mask, combined_mask, dec_padding_mask"]},{"cell_type":"markdown","metadata":{"id":"jWL-MaKjramS"},"source":["<h3 style=\"color:#FF7C00  \"> => Checkpoint </h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"adagXHtrpnYH"},"outputs":[],"source":["\"\"\" Create the checkpoint path and the checkpoint manager, to save checkpoints every `n` epochs. \"\"\"\n","\n","checkpoint_path = \"./checkpoints/train\"\n","ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n","\n","## Restore the latest checkpoint, if exists\n","if ckpt_manager.latest_checkpoint:\n","    ckpt.restore(ckpt_manager.latest_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2p0vovgBrpxe"},"outputs":[],"source":["\"\"\" Define the signature decoder for the train_step function. \"\"\"\n","EPOCHS = 20\n","train_step_signature = [\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c8MVrCoFrp16"},"outputs":[],"source":["@tf.function(input_signature=train_step_signature)\n","def train_step(inp, tar):\n","    \"\"\" Perform one training step for the Transformer model, with input signature.\n","\n","    Parameters:\n","        - Input [tf.Tensor]\n","        - Target [tf.Tensor]\n","\n","    Details:\n","        - Remove the last token from target for input\n","        - Remove the first token from target for target\n","        - Create masks for attention\n","\n","        - Open a gradient tape to track operations for differentiation\n","            - Get predictions from the Transformer model\n","            - Calculate the loss using the loss function\n","    \n","        - Calculate gradients of the loss with respect to the model's trainable variables\n","        - Apply the calculated gradients to update model's trainable variables\n","\n","        - Update train_loss metric with the calculated loss value\n","        - Update train_accuracy metric by comparing target and prediction\n","\n","\n","    \"\"\"\n","    tar_inp = tar[:, :-1]\n","    tar_real = tar[:, 1:]\n","    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n","\n","    with tf.GradientTape() as tape:\n","        predictions, _ = transformer(inp, tar_inp, True, enc_padding_mask, combined_mask, dec_padding_mask)\n","        loss = loss_function(tar_real, predictions)\n","\n","    # Calculate gradients \n","    gradients = tape.gradient(loss, transformer.trainable_variables)\n","    # Apply gradients \n","    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n","\n","    ## Update train_loss and train_accuracy\n","    train_loss(loss)\n","    train_accuracy(tar_real, predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZyV1JRUFrp5V"},"outputs":[],"source":["for epoch in range(EPOCHS):\n","    start = time.time()\n","\n","    train_loss.reset_states()\n","    train_accuracy.reset_states()\n","\n","    for (batch, (inp, tar)) in enumerate(train_dataset):\n","        train_step(inp, tar)\n","\n","    if batch % 50 == 0:\n","        print('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n","\n","    if (epoch + 1) % 5 == 0:\n","        ckpt_save_path = ckpt_manager.save()\n","        print('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n","\n","    print('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, train_loss.result(), train_accuracy.result()))\n","\n","    print('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"]},{"cell_type":"markdown","metadata":{"id":"hplUOaLVrp8g"},"source":["<h3 style=\"color:#FF7C00  \"> => Evaluation </h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jrblCenktOJZ"},"outputs":[],"source":["def evaluate_tranformer(inp_sentence):\n","    \"\"\" Perform evaluation using the Transformer model on an input sentence.\n","\n","    Parameters:\n","        Input sentence [str]\n","\n","    Returns:\n","        - Resulting output [tf.Tensor]\n","        - Attention weights [dict]\n","    \"\"\"\n","    ## Define start + end tokens\n","    start_token = [tokenizer_pt.vocab_size]\n","    end_token = [tokenizer_pt.vocab_size + 1]\n","\n","    ## Tokenize + preprocess the input sentence\n","    inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n","    encoder_input = tf.expand_dims(inp_sentence, 0)\n","\n","    ## Initialize the decoder input with the English start token\n","    decoder_input = [tokenizer_en.vocab_size]\n","    output = tf.expand_dims(decoder_input, 0)\n","\n","    for i in range(MAX_LENGTH):\n","        # Create masks for attention\n","        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n","            encoder_input, output)\n","\n","        # Get predictions from the Transformer model\n","        predictions, attention_weights = transformer(encoder_input, output, False, \n","                                                    enc_padding_mask, combined_mask, dec_padding_mask)\n","\n","        # Select the last predicted word # (batch_size, 1, vocab_size)\n","        predictions = predictions[:, -1:, :]\n","\n","        # Choose the word with highest probability as the predicted_id\n","        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","\n","        # Check if the end token is predicted, return the result if so\n","        if predicted_id == tokenizer_en.vocab_size + 1:\n","            return tf.squeeze(output, axis=0), attention_weights\n","\n","        # Concatenate the predicted_id to the output\n","        output = tf.concat([output, predicted_id], axis=-1)\n","\n","    return tf.squeeze(output, axis=0), attention_weights\n"]},{"cell_type":"markdown","metadata":{"id":"ZXyn83-qtON4"},"source":["<h3 style=\"color:#FF7C00  \"> => Visualization </h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"djIMlbzBtOSP"},"outputs":[],"source":["def plot_attention_weights(attention, sentence, result, layer):\n","    \"\"\" Plot the attention weights for visualization.\n","\n","    Parameters:\n","        - Dictionary containing attention weights [dict]\n","        - Input sentence [str]\n","        - Output tensor [tf.Tensor]\n","        - Layer index for which attention is plotted [int]\n","    \"\"\"\n","    fig = plt.figure(figsize=(16, 8))\n","\n","    # Tokenize the input sentence\n","    sentence = tokenizer_pt.encode(sentence)\n","    # Extract attention weights for the specified layer\n","    attention = tf.squeeze(attention[layer], axis=0)\n","\n","    # Iterate through attention heads\n","    for head in range(attention.shape[0]):\n","        ax = fig.add_subplot(2, 4, head + 1)\n","        ax.matshow(attention[head][:-1, :], cmap='winter')\n","\n","        fontdict = {'fontsize': 10}\n","\n","        ax.set_xticks(range(len(sentence) + 2))\n","        ax.set_yticks(range(len(result)))\n","\n","        ax.set_ylim(len(result) - 1.5, -0.5)\n","\n","        # Set x-axis labels with tokens\n","        ax.set_xticklabels(['<start>'] + [tokenizer_pt.decode([i]) for i in sentence] + ['<end>'], fontdict=fontdict, rotation=90)\n","\n","        # Set y-axis labels with decoded tokens\n","        ax.set_yticklabels([tokenizer_en.decode([i]) for i in result\n","                        if i < tokenizer_en.vocab_size], fontdict=fontdict)\n","\n","        ax.set_xlabel('Head {}'.format(head + 1))\n","\n","    # Adjust layout\n","    plt.tight_layout()\n","    plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"lVHAN602tOVr"},"source":["<h2 style=\"color:#FF7C00  \"> <b> Main example <b> </h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3eggZcbptOYc"},"outputs":[],"source":["def translate(sentence, plot=''):\n","    \"\"\" Translate an input sentence using the Transformer model.\n","\n","    Parameters:\n","        - Input sentence [str]\n","        - Layer index for plotting attention (plot) [str, optional (default: '')]\n","\n","    \"\"\"\n","    # Get translation and attention weights using the evaluate function\n","    result, attention_weights = evaluate(sentence)\n","\n","    # Decode the predicted result into a human-readable sentence\n","    predicted_sentence = tokenizer_it.decode([i for i in result if i < tokenizer_it.vocab_size])\n","\n","    # Print the input sentence and the predicted translation\n","    print('Input: {}'.format(sentence))\n","    print('Predicted translation: {}'.format(predicted_sentence))\n","\n","    # If plot is specified, plot the attention weights\n","    if plot:\n","        plot_attention_weights(attention_weights, sentence, result, plot)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vW9JPC6EtOb1"},"outputs":[],"source":["translate(\"Non so cosa dirti.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JB9sxcNbtsS9"},"outputs":[],"source":["translate(\"Questo è un problema tuo caro.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BDEAwCNhtsWl"},"outputs":[],"source":["translate(\"Il dado è tratto.\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyONtcVFM7QMCshDuaDlhcMu","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"04c6fb76556c4519b84e1b8fc0df4971":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0f6b65997954fc8a1312fac5100e6e5","placeholder":"​","style":"IPY_MODEL_9b5b9774e1da4632a98fadd965e57181","value":"Dl Size...: 100%"}},"0b312960b7d84feb8f1d5fed8535f7ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_4de78ea6642d405583ac19e76511d672","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e9396d893da84e1f8514959317a7899b","value":3}},"104512036e0644e7a1c4c441244b51bd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"13762a799fab4772a6535b953b955537":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13fe8bdd41294da5b4b20283660946fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14e86b9f3f1d43f88d6bcafa706387d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_04c6fb76556c4519b84e1b8fc0df4971","IPY_MODEL_7b50abdb50fe4a3a990914f93a8c118e","IPY_MODEL_596f0eaf17a34fc1939b38fed3f4f0b7"],"layout":"IPY_MODEL_beb6f114d24449cb8c55fe34d9a1c032"}},"1985514b6aae42cea80017c66961fee8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c57aa0c2a5f4d9b89e826cec5e23ca7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f501737081246cb8bc3dd005d744fac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2046452f049a48fea8a0b3c212f728d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13762a799fab4772a6535b953b955537","placeholder":"​","style":"IPY_MODEL_82d676be5e2345018b7aafdfbf44331d","value":" 23168/46259 [00:00&lt;00:00, 231658.68 examples/s]"}},"23b6e11bebd9420f85b2e6706f0ed652":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"271aa2c550c94aabbcaeb3a646ec86d0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"28874caa28b64e268c503510a5f0bc00":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"295e2bccfea64ec8b0216f24c5c863a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b1ad1dd87294aa89cdb9360071c4807":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2c0ac586037e40709a148c690c48c60e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bfab8c731c34da8bb9b342d86f7a841","placeholder":"​","style":"IPY_MODEL_39e05160b2a94a5aa8004a216fa1ebee","value":"Dl Completed...: 100%"}},"2c58545b57a340578c1f98102c5a830e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c02bb39a66e4bc9baa435ef7a874036","max":1162,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dbee0f00c28341c7a2bb9624b4ac90ef","value":1162}},"31e953ea913143d88f15e5d5ba275629":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3262d1705a0c42a29f449b1b28353198":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90368340c4a942bb841ec245ceddee6e","placeholder":"​","style":"IPY_MODEL_7b175880d47447ec805c2238aebe773a","value":"Generating splits...: 100%"}},"36b3de606e774fd5a4ceb78677794040":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36e74585de764fb787358aa5054fd27d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39e05160b2a94a5aa8004a216fa1ebee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3bcc124f4e2c485dae9b69011edffb8a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4075ae9f02a84727bae8101fc9023ed8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42b45b2f99e04e74a6a61e6e6765c6e8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4591f0a2a0494515839ef03188e875c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_559559aff31247938b41498947f19060","placeholder":"​","style":"IPY_MODEL_d8d464b90a594054b9d4aa8380b78784","value":" 0/1669 [00:00&lt;?, ? examples/s]"}},"46020196386e4e1a85c6c4b37cdffc37":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bcc124f4e2c485dae9b69011edffb8a","placeholder":"​","style":"IPY_MODEL_b34c27a66b9a44188fc02ff3442be918","value":"Shuffling /root/tensorflow_datasets/ted_hrlr_translate/it_to_pt/1.0.0.incompleteGT2AWD/ted_hrlr_translate-train.tfrecord*...:  50%"}},"4b59ddfa148745ff80ac0b6b36428e96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84daf539f8e840469329865e256f5782","placeholder":"​","style":"IPY_MODEL_be382484c4cc4ddcaed5d89486e15270","value":" 112/112 [00:09&lt;00:00, 16.90 file/s]"}},"4bfab8c731c34da8bb9b342d86f7a841":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d8d53d205874e36969119ff16e63e3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f694c7e74ec6488ab9818c59e3dbed81","placeholder":"​","style":"IPY_MODEL_23b6e11bebd9420f85b2e6706f0ed652","value":" 0/1162 [00:00&lt;?, ? examples/s]"}},"4de78ea6642d405583ac19e76511d672":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fa7384601ce4caab00667e37a9093e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf57a6ad587d400196296ce03a5e747a","max":46259,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cffbb814364d4d8f8d8e534cdefc53c3","value":46259}},"50c6ddf457f848e9bf81a74b79d23088":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54372bd390e64d549291d2fe937a71ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5bbb64172854bc7afb6664e9efac615","max":1669,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8cfd5d5a866e4642bf101fdb81671950","value":1669}},"559559aff31247938b41498947f19060":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5677d1bfd53c4d648a7f4a28dad7fe2b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"596f0eaf17a34fc1939b38fed3f4f0b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1985514b6aae42cea80017c66961fee8","placeholder":"​","style":"IPY_MODEL_c0c356f862f542f3a14be0930e0074c1","value":" 124/124 [00:09&lt;00:00, 32.21 MiB/s]"}},"5eb061a2d57e4f31a0399ee722470a2d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5f2ce56710c44f84a0676eb98be7a10b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"612d5e4075a0463abb494e3b5e5d69d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbd043efac80452da9570c4359c55f2d","max":1162,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e71965bdee154d2c927b8227f090705b","value":1162}},"62b929c0feae4b3bbb000ef6d4644237":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"664e3375840f47e2bbe76f7bfacd5535":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"6925bacaccc442fd9d95f1e174c06805":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d4d17d1a24654ad0b39074209ca27748","IPY_MODEL_54372bd390e64d549291d2fe937a71ff","IPY_MODEL_7e7ac84b0ace46f5918e80464207fd18"],"layout":"IPY_MODEL_664e3375840f47e2bbe76f7bfacd5535"}},"6ae4ece682544cf39912780e314d6158":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c02bb39a66e4bc9baa435ef7a874036":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e6a22a1093648bab2eacec71832b842":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73df70457eb94df592dc5df67eea29ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"740b09f0cae14b98898e6843cac56471":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13fe8bdd41294da5b4b20283660946fe","placeholder":"​","style":"IPY_MODEL_f47a5c8df93c4297b80b0b407b2a5935","value":" 908/1162 [00:00&lt;00:00, 9079.12 examples/s]"}},"77e83425d1d543519a69de1eec90ecbb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b175880d47447ec805c2238aebe773a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b50abdb50fe4a3a990914f93a8c118e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b226f9faec7a4398a9a4b0ccc68420d0","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c71e0e0f0f1d4026a55598bcafa50448","value":1}},"7bd0bf0cf4784dddba19d0eb1ef5689b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcfb850f52b64f86ad56447ceb7f670e","placeholder":"​","style":"IPY_MODEL_36e74585de764fb787358aa5054fd27d","value":" 1/1 [00:09&lt;00:00,  4.92s/ url]"}},"7e7ac84b0ace46f5918e80464207fd18":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42b45b2f99e04e74a6a61e6e6765c6e8","placeholder":"​","style":"IPY_MODEL_d64cd55b8c914cb294be56c7fd100311","value":" 563/1669 [00:00&lt;00:00, 5626.44 examples/s]"}},"827a8f2d5fc64ccead622ecd4943ef31":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82d676be5e2345018b7aafdfbf44331d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84daf539f8e840469329865e256f5782":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cfd5d5a866e4642bf101fdb81671950":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"90368340c4a942bb841ec245ceddee6e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9292a90227194748b7352a86bfd7b564":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2e646a7843f43a691efd04922654f5d","placeholder":"​","style":"IPY_MODEL_c5e99a5672f24ed48dc3ff0a319452ea","value":" 45946/46259 [00:03&lt;00:00, 14857.56 examples/s]"}},"932362e9b1e54a30be78340525396450":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb5f2607721343abbc7bd4047f15c8d0","placeholder":"​","style":"IPY_MODEL_36b3de606e774fd5a4ceb78677794040","value":"Generating train examples...:  99%"}},"955cbc6ba61745c6831775b6c8e1956b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cfbcd0f400ad4ddb9b17ed555f042956","IPY_MODEL_b3b7b5d748f141e3a255c95ca89ae6b9","IPY_MODEL_4b59ddfa148745ff80ac0b6b36428e96"],"layout":"IPY_MODEL_d0d9fe9d38364d70b46666ff35281c20"}},"9b5b9774e1da4632a98fadd965e57181":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0bd737b08c04160b6cd87dd9fa959ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e6a22a1093648bab2eacec71832b842","max":46259,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5eb061a2d57e4f31a0399ee722470a2d","value":46259}},"a5bbb64172854bc7afb6664e9efac615":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b022b51031124b89b6ab9077736ac38e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5677d1bfd53c4d648a7f4a28dad7fe2b","placeholder":"​","style":"IPY_MODEL_31e953ea913143d88f15e5d5ba275629","value":" 3/3 [00:04&lt;00:00,  1.02 splits/s]"}},"b0654b1db31d4146bc05de70b9bdbadc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e1fc0d8789bb47e398c734ad981196f3","IPY_MODEL_b78542fa903744efb5fc373c36785104","IPY_MODEL_4591f0a2a0494515839ef03188e875c3"],"layout":"IPY_MODEL_f0a7f14c2ba94bf295f322b76a4dd8f5"}},"b0a855eae57e4b69b8d1dbf9a66a68f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_932362e9b1e54a30be78340525396450","IPY_MODEL_a0bd737b08c04160b6cd87dd9fa959ab","IPY_MODEL_9292a90227194748b7352a86bfd7b564"],"layout":"IPY_MODEL_104512036e0644e7a1c4c441244b51bd"}},"b0aba7f75b5446c5903faed1bfb90857":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b226f9faec7a4398a9a4b0ccc68420d0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"b34c27a66b9a44188fc02ff3442be918":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b3b7b5d748f141e3a255c95ca89ae6b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0712f2abd2845ec89180a751317a575","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_62b929c0feae4b3bbb000ef6d4644237","value":1}},"b6417f53ef1f440ca7dd0c26759a482a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc1de0df35484b179391e1ded9097c3f","IPY_MODEL_612d5e4075a0463abb494e3b5e5d69d4","IPY_MODEL_4d8d53d205874e36969119ff16e63e3e"],"layout":"IPY_MODEL_dbd0e88b25eb4a0fad1ec58f5d8ef808"}},"b78542fa903744efb5fc373c36785104":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0aba7f75b5446c5903faed1bfb90857","max":1669,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b1ad1dd87294aa89cdb9360071c4807","value":1669}},"b9578970c6c74597be85cdc56d86d2b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4075ae9f02a84727bae8101fc9023ed8","placeholder":"​","style":"IPY_MODEL_e2c6754ddcf44f6e96713c5726fb5155","value":"Generating validation examples...:  78%"}},"bcfb850f52b64f86ad56447ceb7f670e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be382484c4cc4ddcaed5d89486e15270":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"beb6f114d24449cb8c55fe34d9a1c032":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf57a6ad587d400196296ce03a5e747a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0c356f862f542f3a14be0930e0074c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c0e25fa7080548d6ba158b1cb4580e0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c0ac586037e40709a148c690c48c60e","IPY_MODEL_d71136c3cda34227b7f42131c1b104c5","IPY_MODEL_7bd0bf0cf4784dddba19d0eb1ef5689b"],"layout":"IPY_MODEL_295e2bccfea64ec8b0216f24c5c863a5"}},"c2e646a7843f43a691efd04922654f5d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5e99a5672f24ed48dc3ff0a319452ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6c0c8c68be7422892480ab254a4e68c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3262d1705a0c42a29f449b1b28353198","IPY_MODEL_0b312960b7d84feb8f1d5fed8535f7ac","IPY_MODEL_b022b51031124b89b6ab9077736ac38e"],"layout":"IPY_MODEL_5f2ce56710c44f84a0676eb98be7a10b"}},"c71e0e0f0f1d4026a55598bcafa50448":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cfb1f73d0c59411baf17906a900dc1e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b9578970c6c74597be85cdc56d86d2b3","IPY_MODEL_2c58545b57a340578c1f98102c5a830e","IPY_MODEL_740b09f0cae14b98898e6843cac56471"],"layout":"IPY_MODEL_28874caa28b64e268c503510a5f0bc00"}},"cfbcd0f400ad4ddb9b17ed555f042956":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db227fbba117485ebcc3e02755c9840e","placeholder":"​","style":"IPY_MODEL_77e83425d1d543519a69de1eec90ecbb","value":"Extraction completed...: 100%"}},"cffbb814364d4d8f8d8e534cdefc53c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0d9fe9d38364d70b46666ff35281c20":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4365583107d4235a2c1eea7715a4ebe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"d4d17d1a24654ad0b39074209ca27748":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ae4ece682544cf39912780e314d6158","placeholder":"​","style":"IPY_MODEL_1f501737081246cb8bc3dd005d744fac","value":"Generating test examples...:  34%"}},"d64cd55b8c914cb294be56c7fd100311":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d71136c3cda34227b7f42131c1b104c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4365583107d4235a2c1eea7715a4ebe","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_73df70457eb94df592dc5df67eea29ac","value":1}},"d8d464b90a594054b9d4aa8380b78784":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db227fbba117485ebcc3e02755c9840e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbd043efac80452da9570c4359c55f2d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbd0e88b25eb4a0fad1ec58f5d8ef808":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"dbee0f00c28341c7a2bb9624b4ac90ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc1de0df35484b179391e1ded9097c3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_827a8f2d5fc64ccead622ecd4943ef31","placeholder":"​","style":"IPY_MODEL_1c57aa0c2a5f4d9b89e826cec5e23ca7","value":"Shuffling /root/tensorflow_datasets/ted_hrlr_translate/it_to_pt/1.0.0.incompleteGT2AWD/ted_hrlr_translate-validation.tfrecord*...:   0%"}},"e1fc0d8789bb47e398c734ad981196f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50c6ddf457f848e9bf81a74b79d23088","placeholder":"​","style":"IPY_MODEL_e9f8bf9330644711ace573c92b8381a9","value":"Shuffling /root/tensorflow_datasets/ted_hrlr_translate/it_to_pt/1.0.0.incompleteGT2AWD/ted_hrlr_translate-test.tfrecord*...:   0%"}},"e2c6754ddcf44f6e96713c5726fb5155":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3cebfc78483452dadcdf19ba66b0cf1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_46020196386e4e1a85c6c4b37cdffc37","IPY_MODEL_4fa7384601ce4caab00667e37a9093e1","IPY_MODEL_2046452f049a48fea8a0b3c212f728d6"],"layout":"IPY_MODEL_271aa2c550c94aabbcaeb3a646ec86d0"}},"e71965bdee154d2c927b8227f090705b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e9396d893da84e1f8514959317a7899b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e9f8bf9330644711ace573c92b8381a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0712f2abd2845ec89180a751317a575":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"f0a7f14c2ba94bf295f322b76a4dd8f5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"f0f6b65997954fc8a1312fac5100e6e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f47a5c8df93c4297b80b0b407b2a5935":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f694c7e74ec6488ab9818c59e3dbed81":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb5f2607721343abbc7bd4047f15c8d0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
