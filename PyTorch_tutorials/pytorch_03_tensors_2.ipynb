{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"line-height:0.5\">\n",
    "<h1 style=\"color:#BF66F2 \">  Tensors in PyTorch 2 </h1>\n",
    "<h4> Slicing, Permutating, and Converting.  </h4> \n",
    "<div style=\"margin-top: -10px;\">\n",
    "<span style=\"display: inline-block;\">\n",
    "    <h3 style=\"color: lightblue; display: inline;\">Keywords:</h3>\n",
    "    torch.randn() + torch.stack() + torch.sum() + torch.allclose()\n",
    "</span>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore CUDA warnings when GPU is not in use\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Perform tensor operations.\n",
    "N.B.\n",
    "Using 'multiplied_tensor = reshaped_tensor * random_tensor' will lead to a \"RuntimeError! due to sizes mismatch.\"\n",
    "\"\"\"\n",
    "\n",
    "zeros_tensor = torch.zeros((2, 3))\n",
    "ones_tensor = torch.ones((2, 3))\n",
    "random_tensor = torch.rand((3, 2))\n",
    "custom_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "sliced_tensor = custom_tensor[:, 1:]\n",
    "added_tensor = custom_tensor + ones_tensor\n",
    "reshaped_tensor = custom_tensor.reshape((2, 3))\n",
    "\n",
    "# Transpose random_tensor to make the multiplication valid\n",
    "random_tensor_transposed = random_tensor.T  \n",
    "\n",
    "# Perform element-wise multiplication\n",
    "multiplied_tensor = reshaped_tensor * random_tensor_transposed\n",
    "\n",
    "print(reshaped_tensor)\n",
    "print(sliced_tensor)\n",
    "print(added_tensor)\n",
    "print(multiplied_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16, 23],\n",
       "        [40, 65]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Dot product between tensors\n",
    "N.B.\n",
    "Using 'dot_product = torch.mm(custom_tensor, random_tensor)' will lead to #RuntimeError: expected scalar type Long but found Float\n",
    "It is neccesary to create \"Long\" tensors.\n",
    "random_tensor = torch.randint(0, 10, (3, 2), dtype=torch.long)  \n",
    "custom_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.long)\n",
    "\"\"\" \n",
    "\n",
    "## Convert existing tensors to dtype=torch.long, to permit product calculation\n",
    "random_tensor = random_tensor.to(dtype=torch.long)\n",
    "custom_tensor = custom_tensor.to(dtype=torch.long)\n",
    "\n",
    "dot_product = torch.mm(custom_tensor, random_tensor)\n",
    "dot_product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#BF66F2 \">  => Transpose: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2],\n",
       "         [3, 4]]),\n",
       " tensor([[1, 3],\n",
       "         [2, 4]]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2], [3, 4]])\n",
    "y = x.t()\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#BF66F2 \">  => Permute: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2],\n",
       "          [3, 4]],\n",
       " \n",
       "         [[5, 6],\n",
       "          [7, 8]]]),\n",
       " tensor([[[1, 3],\n",
       "          [5, 7]],\n",
       " \n",
       "         [[2, 4],\n",
       "          [6, 8]]]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "y = x.permute(2, 0, 1)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#BF66F2 \">  => Views: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Reshape \"\"\"\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "y = x.view(2, 2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4, 5]),\n",
       " tensor([[0, 1, 2],\n",
       "         [3, 4, 5]]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Add a dimension, from 1d to 2d \"\"\"\n",
    "x = torch.arange(6)\n",
    "y = x.view(2, 3)\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 6]),\n",
       " tensor([[1, 2, 3],\n",
       "         [4, 5, 6]]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Reshape with Inferred second dimension \"\"\"\n",
    "x = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "y = x.view(2, -1)  \n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 6]),\n",
       " tensor([[1, 2, 3],\n",
       "         [4, 5, 6]]),\n",
       " tensor([[1, 2],\n",
       "         [3, 4],\n",
       "         [5, 6]]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Nested view \"\"\"\n",
    "x = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "y = x.view(2, 3)\n",
    "z = y.view(3, 2)\n",
    "x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4]),\n",
       " tensor([[1, 2],\n",
       "         [3, 4]]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Clone with View\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "y = x.clone().view(2, 2)\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4]),\n",
       " tensor([[1, 2],\n",
       "         [3, 4]]),\n",
       " tensor([[[1, 2],\n",
       "          [3, 4]]]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Squeeze and Unsqueeze \"\"\"\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "y = x.view(2, 2)\n",
    "# Add a dimension\n",
    "z = y.unsqueeze(0)  \n",
    "x,y,z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.1812,  0.8232, -1.6328, -0.3370],\n",
       "          [ 2.0581, -0.8308,  2.0918, -0.4919],\n",
       "          [-0.5943, -0.9565,  0.4792, -0.7039]],\n",
       " \n",
       "         [[-1.1146, -0.1058, -0.6221, -0.9684],\n",
       "          [ 0.1239, -0.6627,  0.0068, -1.7819],\n",
       "          [ 0.6685,  0.5804, -1.2789, -1.3036]]]),\n",
       " tensor([[-1.1812,  0.8232, -1.6328, -0.3370,  2.0581, -0.8308,  2.0918, -0.4919,\n",
       "          -0.5943, -0.9565,  0.4792, -0.7039],\n",
       "         [-1.1146, -0.1058, -0.6221, -0.9684,  0.1239, -0.6627,  0.0068, -1.7819,\n",
       "           0.6685,  0.5804, -1.2789, -1.3036]]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Flatten a 3D Tensor \"\"\"\n",
    "x = torch.randn(2, 3, 4)\n",
    "y = x.view(x.size(0), -1)\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.3997,  1.9782,  0.7129,  0.0671],\n",
       "          [ 0.1556,  0.8556, -0.9329,  0.6139],\n",
       "          [-1.4615,  0.2474, -0.9193,  0.2619]],\n",
       " \n",
       "         [[-0.1116, -1.3887,  1.0781, -1.3559],\n",
       "          [-1.0864,  0.7510,  0.0152,  0.4619],\n",
       "          [ 0.6258,  0.3474, -0.0213,  1.1622]]]),\n",
       " tensor([[ 0.3997,  0.1556, -1.4615,  1.9782,  0.8556,  0.2474,  0.7129, -0.9329,\n",
       "          -0.9193,  0.0671,  0.6139,  0.2619],\n",
       "         [-0.1116, -1.0864,  0.6258, -1.3887,  0.7510,  0.3474,  1.0781,  0.0152,\n",
       "          -0.0213, -1.3559,  0.4619,  1.1622]]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Permute and View. \"\"\"\n",
    "x = torch.randn(2, 3, 4)\n",
    "y = x.permute(0, 2, 1).contiguous().view(2, -1)\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4088,  1.0336,  0.5344,  0.4636],\n",
       "         [-0.3784, -3.0223,  0.2899, -2.9596],\n",
       "         [-0.5313, -0.4152, -0.0172, -0.0940],\n",
       "         [ 0.0155, -0.7898,  0.1070, -0.8587]],\n",
       "\n",
       "        [[ 0.4704,  0.2189,  0.0267, -0.3712],\n",
       "         [-1.1777,  0.6148,  1.1800,  0.3318],\n",
       "         [-1.2264,  1.5978,  2.0141, -0.3041],\n",
       "         [-0.7252, -0.1474, -0.1350,  0.2805]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Batch Matrix Multiplication.\n",
    "N.B.\n",
    "Matrix multiplication and reshaping operations must be compatible. \n",
    "The result of the bmm operation has 32 elements => it can be reshaped into a shape that has the same number of elements.\n",
    "\"\"\"\n",
    "x = torch.randn(2, 3, 4)\n",
    "y = torch.randn(2, 4, 3)\n",
    "result_bmm = torch.bmm(x.view(-1, 4, 3), y.view(-1, 3, 4)).view(2, 4, 4)\n",
    "result_bmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#BF66F2 \">  => Equality: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False],\n",
       "        [False,  True]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eq\n",
    "torch.eq(torch.tensor([[1., 2.], [3., 4.]]), torch.tensor([[1., 1.], [4., 4.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# equal\n",
    "print(torch.equal(torch.tensor([[1., 2.], [3, 4.]]), torch.tensor([[1., 1.], [4., 4.]])))\n",
    "print(torch.equal(torch.tensor([[1., 2.], [3., 4.]]), torch.tensor([[1., 2.], [3., 4.]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Check if all elements of two tensors are close to each other within some tolerance.\n",
    "Tolerance => atol + rtol * abs(tensor2)\n",
    "where:\n",
    "- atol absolute tolerance           [default val 1e-08 => 0.00000001]\n",
    "- rtol is the relative tolerance    [default val 1e-08]\n",
    "\"\"\"\n",
    "torch.allclose(torch.tensor([[1., 2.], [3., 4.]]), torch.tensor([[1., 2.000000001], [3., 4.]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#BF66F2 \">  => From tensorFlow to PyTorch: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensor1 = tf.constant(7)\n",
    "tensor2 = tf.constant(7)\n",
    "tensor3 = tf.ones(shape=(7,))\n",
    "tensor4 = tf.ones(shape=(7,))\n",
    "tensor5 = tf.zeros(shape=(9,))\n",
    "\n",
    "print(tensor1)\n",
    "print(tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=bool, numpy=True>,\n",
       " <tf.Tensor: shape=(7,), dtype=bool, numpy=array([ True,  True,  True,  True,  True,  True,  True])>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compare tensors\n",
    "result12 = tf.equal(tensor1, tensor2)\n",
    "result34 = tf.equal(tensor3, tensor4)\n",
    "\n",
    "result12, result34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 1. 1. 1. 1. 1. 1.], shape=(7,), dtype=float32) tensor([1., 1., 1., 1., 1., 1., 1.])\n",
      "tf.Tensor([1. 1. 1. 1. 1. 1. 1.], shape=(7,), dtype=float32) tensor([1., 1., 1., 1., 1., 1., 1.])\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(9,), dtype=float32) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"  Convert the tensors to PyTorch tensors. \"\"\"\n",
    "ten3 = torch.tensor(tensor3.numpy())\n",
    "ten4 = torch.tensor(tensor4.numpy())\n",
    "ten5 = torch.tensor(tensor5.numpy())\n",
    "\n",
    "print(tensor3, ten3)\n",
    "print(tensor4, ten4)\n",
    "print(tensor5, ten5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Calculate the percentage of elements that are equal. \"\"\"\n",
    "print(torch.sum(torch.eq(tensor3, tensor4)).item()/tensor3.nelement())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#BF66F2 \">  => Concatenate: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([4, 5, 6])\n",
    "z = torch.cat((x, y), dim=0)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 12, 13],\n",
      "        [12, 13, 14],\n",
      "        [13, 14, 15]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([4, 5, 6])\n",
    "\n",
    "zz = torch.tensor([[7], [8], [9]])\n",
    "# Reshape y to have the same shape as the rows of z\n",
    "y_expanded = y.view(-1, 1)\n",
    "\n",
    "# Perform element-wise addition\n",
    "q = zz + y\n",
    "\n",
    "y.shape, zz.shape, y_expanded.shape, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 12, 13],\n",
      "        [12, 13, 14],\n",
      "        [13, 14, 15]])\n"
     ]
    }
   ],
   "source": [
    "# Slicing (using whatever number greater than 1)\n",
    "print(q[:643])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#BF66F2 \">  => Slicing: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2, 3, 4]), tensor([2, 5]), tensor([4, 8]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.tensor([1,2,3,4,5]) \n",
    "t2 = torch.tensor([[1,2,3],[4,5,6]])\n",
    "t3 = torch.tensor([[[1,2],[3,4]],[[5,6],[7,8]]])\n",
    "\n",
    "t1[1:4], t2[:,1], t3[::,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.0328, -0.1112,  1.3843],\n",
       "         [ 1.0001, -0.2679, -1.1346],\n",
       "         [-0.0598,  0.0492, -1.3476],\n",
       "         [ 0.2015,  0.2634, -0.3964]]),\n",
       " 2,\n",
       " tensor([[ 0.2015,  0.2634, -0.3964]]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negative indexing\n",
    "t4 = torch.randn(4,3)\n",
    "t4, t4.dim(), t4[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5597, -0.2001, -0.3670,  1.1898, -1.3164],\n",
       "         [-0.7738, -0.5546, -0.6210, -2.1632,  1.5810],\n",
       "         [-0.7321, -1.4175,  0.1097,  0.9072,  0.2233],\n",
       "         [ 0.8454, -0.2556, -0.9642,  0.3502,  2.4169],\n",
       "         [ 1.4442, -1.4146, -1.5604,  1.3196,  0.8837]],\n",
       "\n",
       "        [[-1.6367, -2.1349, -0.3863,  1.2212, -0.5606],\n",
       "         [-1.7655, -1.1650,  1.1667,  0.6932,  0.0084],\n",
       "         [ 1.1665, -0.4275,  0.3919,  0.6940, -1.5913],\n",
       "         [ 0.3855,  1.6351, -0.3890,  1.1391, -1.4347],\n",
       "         [-0.2662,  1.6332, -1.7744,  0.2900, -0.5376]],\n",
       "\n",
       "        [[ 0.6745,  0.0698,  2.3746, -1.6766,  1.2339],\n",
       "         [ 0.7886, -1.1450,  0.0675, -0.1048, -0.0711],\n",
       "         [-1.9525, -0.7117, -0.4527, -0.4212, -0.0189],\n",
       "         [-2.6939,  0.1455,  0.6829, -0.5073, -0.5686],\n",
       "         [ 1.1843,  1.3195,  0.1054, -1.0410, -1.6503]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skip elements\n",
    "t5 = torch.randn(5,5,5) \n",
    "t5[::2,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2676, -0.5557],\n",
       "         [ 0.9558,  1.9563],\n",
       "         [ 1.4871,  0.2636]],\n",
       "\n",
       "        [[ 1.7563, -0.3373],\n",
       "         [-1.2125,  1.6479],\n",
       "         [-0.1627,  0.7981]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multidimensional slice\n",
    "t6 = torch.randn(3,4,5)\n",
    "t6[1:3, 1:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2, 3]),\n",
       " tensor([[ 4,  5,  6],\n",
       "         [10, 11, 12],\n",
       "         [16, 17, 18]]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Stack \"\"\"\n",
    "### Sequence of tensors (must have the same size)\n",
    "t1 = torch.tensor([[1,2,3], [4,5,6]]) \n",
    "t2 = torch.tensor([[7,8,9], [10,11,12]])\n",
    "t3 = torch.tensor([[13,14,15], [16,17,18]])\n",
    "\n",
    "# Stack tensors along a new dimension           \n",
    "t7 = torch.stack((t1, t2, t3), dim=0)\n",
    "t7.shape, t7[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2245, -0.0567, -0.2195, -1.1520,  1.3534, -0.3623],\n",
       "         [ 0.9551,  0.3386,  0.0992,  1.1884,  0.4604,  1.0712],\n",
       "         [-0.3540, -0.1760, -0.7404, -0.8590,  0.3397,  0.1583],\n",
       "         [-1.5235,  0.9464, -0.5895,  0.3317, -1.8394,  0.7540],\n",
       "         [-0.9072,  0.1099, -0.1008, -0.2263,  0.3370, -0.3760],\n",
       "         [-0.6148, -0.2064, -2.4971,  1.5091,  0.2511, -1.3313],\n",
       "         [-1.2007, -0.2711,  0.1316, -0.4046,  1.2316,  1.7293],\n",
       "         [ 0.2079,  0.5154, -0.2842, -0.6503, -0.6726, -1.4182],\n",
       "         [-0.8555,  0.4968, -0.3908,  1.1459, -1.0014,  0.6994],\n",
       "         [-0.2164,  0.1291,  0.9052, -0.0919,  1.4075, -1.1930]],\n",
       "\n",
       "        [[-0.1908, -0.4879, -0.3150, -1.1580,  1.9536,  0.1861],\n",
       "         [ 0.4766, -0.6017,  0.2823,  0.9599, -0.4215, -0.9887],\n",
       "         [-0.9419, -0.7010, -0.3153, -0.7508, -1.8411,  1.0687],\n",
       "         [ 0.1258,  0.4008, -1.8636,  0.9739, -0.6943,  1.7665],\n",
       "         [-1.6353, -0.1708, -0.6436, -0.0708, -1.4541,  0.3976],\n",
       "         [ 1.0065,  1.6922, -0.0925,  0.6860, -1.6537,  0.9132],\n",
       "         [-0.1854,  1.7304,  1.1342, -0.2433,  0.6166,  0.8654],\n",
       "         [ 1.0809, -0.2411,  1.1298,  0.7491,  1.6521,  1.4549],\n",
       "         [-0.0120,  0.3460, -1.1232, -0.1674,  0.7438, -0.9175],\n",
       "         [ 0.1712, -1.8309,  2.0168, -0.5530,  0.9180, -0.9972]],\n",
       "\n",
       "        [[ 1.6528,  1.5124, -0.8058, -0.2520,  2.3822, -0.1845],\n",
       "         [-0.0893, -0.3691,  1.0335, -1.3134, -0.2380,  0.9097],\n",
       "         [ 0.3503,  0.7461, -1.6219, -0.1562,  0.1701,  1.3245],\n",
       "         [ 0.2277, -0.3597,  0.2284, -0.1747,  0.3737,  1.5877],\n",
       "         [-0.4451, -0.5332,  0.3005, -2.1449, -1.1929,  1.0548],\n",
       "         [-0.4005, -0.2139,  0.6515, -0.1048, -0.7078,  0.7060],\n",
       "         [-2.0697,  0.4145, -0.9781, -0.0700, -0.3214,  0.3423],\n",
       "         [-1.5532,  0.3986,  0.3545, -1.6186, -0.2802, -1.9996],\n",
       "         [ 1.4703, -0.3972, -0.3618,  0.0062, -1.4234, -1.7453],\n",
       "         [-1.8932,  0.7693,  0.6346,  0.0595, -0.3815, -0.8560]],\n",
       "\n",
       "        [[ 0.8248, -1.1509, -0.1181,  0.4678, -0.3137,  0.3991],\n",
       "         [ 2.1413,  0.7484,  1.4163,  0.2774, -1.3879,  1.0941],\n",
       "         [ 0.5974, -0.0676, -1.1110,  0.5588,  0.8617, -0.5746],\n",
       "         [-0.8736,  0.9722,  1.4340,  0.1059, -0.6663,  0.2975],\n",
       "         [ 0.7932,  0.8745,  0.7043, -1.4257, -0.8686,  0.6175],\n",
       "         [ 0.2329,  0.0031,  0.7868,  1.3119, -0.3924, -0.9895],\n",
       "         [ 3.0510, -0.7193, -0.4324, -0.1898,  0.0386, -0.9012],\n",
       "         [-0.6018, -0.8032,  0.6625,  0.1496, -1.5743,  0.4729],\n",
       "         [ 0.7978, -0.8918,  0.0509,  0.1994,  1.3103,  0.6719],\n",
       "         [ 0.5187,  0.4779, -0.9426,  0.8291,  0.1238,  1.5368]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slice and step\n",
    "t8 = torch.randn(10,20,30)\n",
    "t8[::3,::2,::5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4416, 0.5405, 0.4767, 0.4347],\n",
       "        [0.6419, 0.0426, 0.9762, 0.5671]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Dynamic slice \"\"\"\n",
    "t9 = torch.rand(3,4)\n",
    "slices = torch.tensor([0, 2]).long()\n",
    "t9[slices] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 3],\n",
       "        [4, 0, 6]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign value to sliced\n",
    "t10 = torch.tensor([[1,2,3],[4,5,6]])\n",
    "t10[...,1] = 0\n",
    "t10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
