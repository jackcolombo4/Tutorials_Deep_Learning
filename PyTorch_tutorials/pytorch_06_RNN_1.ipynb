{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#BF66F2 \">  Recurrent Neural Networks in PyTorch 1 </h1>\n",
    "<div style=\"margin-top: -30px;\">\n",
    "<h4> RNN / GRU / LSTM comparison. Learn long-term dependencies in sequential data. Focus on DataLoaders </h4> \n",
    "</div>\n",
    "<div style=\"margin-top: -18px;\">\n",
    "<span style=\"display: inline-block;\">\n",
    "    <h3 style=\"color: lightblue; display: inline;\">Keywords:</h3>\n",
    "    ``'important words'`` yellow in markdown + tqdm progression bar + PyTorch functional interface +\n",
    "    margin-top: in markdown\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn  \n",
    "from torch import optim \n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets  \n",
    "import torchvision.transforms as transforms  \n",
    "\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Hyperparameters \"\"\"\n",
    "input_size = 28\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "num_classes = 10\n",
    "sequence_length = 28\n",
    "learning_rate = 0.005\n",
    "batch_size = 64\n",
    "num_epochs = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#BF66F2\"> RNN Args </h3>\n",
    "<div style=\"margin-top: -17px;\">\n",
    "\n",
    "- input_size: The number of expected features in the input `x`    \n",
    "- hidden_size: The number of features in the hidden state `h`   \n",
    "- num_layers: Number of recurrent layers. \n",
    "        would mean stacking two RNNs together to form a `stacked RNN`,   \n",
    "        with the second RNN taking in outputs of the first RNN and   \n",
    "        computing the final results. Default: 1   \n",
    "- nonlinearity: The non-linearity to use. Can be either ``'tanh'`` or ``'relu'``. Default: ``'tanh'``   \n",
    "- bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.   \n",
    "        Default: ``True``   \n",
    "- batch_first: If ``True``, then the input and output tensors are provided   \n",
    "        as `(batch, seq, feature)` instead of `(seq, batch, feature)`.   \n",
    "        Note that this does not apply to hidden or cell states. Default: ``False``   \n",
    "- dropout: If non-zero, introduces a `Dropout` layer on the outputs of each    \n",
    "        RNN layer except the last layer, with dropout probability equal to    \n",
    "        :attr:`dropout`. Default: 0\n",
    "- bidirectional: If ``True``, becomes a bidirectional RNN. Default: ``False``\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myRNN(nn.Module):\n",
    "    \"\"\" Recurrent Neural Network model (many-to-one). \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(myRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Perform a forward pass through the neural network.\n",
    "            Params:\n",
    "            Details:\n",
    "                - #*      Initialize the hidden states as a tensor of zeros with dimension (num_layers, batch_size, hidden_size)\n",
    "                - #**     Set initial hidden and cell states \n",
    "                - #***    Use throwaway to ignore the tensor representing the final hidden state \n",
    "                - #****   Reshape the output tensor (while preserving its underlying data) out \\\\\n",
    "                        into a 2D tensor with dimensions (batch_size, num_hidden * sequence_length). \\\\\n",
    "                            __out.shape[0] is the batch size of the input sequence. \\\\\n",
    "                            __-1 it is the size of the second dimension of the output tensor. \\\\\n",
    "                            It means that the size of the second dimension is inferred based on the size of \\\\\n",
    "                            the original tensor and the given batch size.\n",
    "\n",
    "                - #*****  Apply the fully connected layer (Linear) to the reshaped output tensor, to \\\\\n",
    "                            to decode the hidden state of the last time step\n",
    "            Returns:\n",
    "                Output tensor [torch.Tensor of shape batch_size, output_size]\n",
    "        \"\"\"\n",
    "        # Init\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) #*\n",
    "        ## Forward\n",
    "        out, _ = self.rnn(x, h0)                                                  #*** throwaway\n",
    "        out = out.reshape(out.shape[0], -1)     \n",
    "        # Decode\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#BF66F2\"> Recap: Gated Recurrent Unit </h3>\n",
    "<div style=\"margin-top: -15px;\">\n",
    "A GRU is similar to LSTM (Long Short-Term Memory) network (designed to overcome the vanishing gradient problem). <br>    \n",
    "It has a simpler architecture than the LSTM, with only two gates: Reset gate and Update gate. <br>\n",
    "\n",
    "In LSTM networks, the cell state serves as a \"memory\" that is propagated from one time step to the next through the use of gating mechanisms.<br>\n",
    "The cell state is updated at each time step using the input at that time step and the previous cell state, and the updated cell state <br> is then passed to the next time step.<br>\n",
    "On the other hand, the hidden state, is a function of the cell state and is used to make predictions or classifications based on the current input.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myRNN_GRU(nn.Module):\n",
    "    \"\"\" GRU-based Recurrent Neural Network (RNN) model (many-to-one).\n",
    "\n",
    "        Args:\n",
    "            - Number of expected features in the input `x` [int]\n",
    "            - Number of features in the hidden state [int]\n",
    "            - Number of recurrent layers [int]\n",
    "            - Number of output classes [int]\n",
    "\n",
    "        Attributes:\n",
    "            - hidden_size (int): The number of features in the hidden state.\n",
    "            - num_layers (int): Number of recurrent layers.\n",
    "            - gru (nn.GRU): The GRU (Gated Recurrent Unit) layer.\n",
    "            - fc (nn.Linear): The fully connected output layer.\n",
    "\n",
    "        Methods:\n",
    "            forward(x): Forward pass through the RNN.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(myRNN_GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Perform a forward pass through the RNN. \\\\\n",
    "        Set initial hidden and cell states + Forward + Decoding with fullyconnected.\n",
    "        \n",
    "        Parameters:\n",
    "            Input tensor of shape [torch.Tensor of shape (batch_size, sequence_length, input_size)]\n",
    "\n",
    "        Returns:\n",
    "            Output logits for each class [torch.Tensor of shape (batch_size, num_classes)]\n",
    "        \"\"\"        \n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        ## Forward propagate LSTM\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        # Decode \n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_LSTM(nn.Module):\n",
    "    \"\"\" Recurrent Neural Network with LSTM architecture (many-to-one).\n",
    "\n",
    "    Parameters:\n",
    "        - Number of expected features in the input `x` [int]\n",
    "        - Number of features in the hidden state [int]\n",
    "        - Number of recurrent layers [int]\n",
    "        - Number of output classes [int]\n",
    "\n",
    "    Attributes:\n",
    "        - hidden_size (int): The number of features in the hidden state\n",
    "        - num_layers (int): Number of recurrent layers\n",
    "        - lstm (nn.LSTM): The LSTM (Long Short-Term Memory) layer\n",
    "        - fc (nn.Linear): The fully connected output layer\n",
    "\n",
    "    Methods:\n",
    "        forward(x): Forward pass through the LSTM-based RNN\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN_LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Forward pass through the LSTM-based RNN.\n",
    "\n",
    "        Args:\n",
    "            Input tensor of shape [torch, Tensor of shape (batch_size, sequence_length, input_size)]\n",
    "\n",
    "        Returns:\n",
    "            Output predictions for each class [torch.Tensor of shape (batch_size, num_classes)]\n",
    "        \"\"\"        \n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(\n",
    "            x, (h0, c0)\n",
    "        )  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#BF66F2\"> Recap: DataLoader </h3>\n",
    "<div style=\"margin-top: -15px;\">\n",
    "Utility to load and preprocess large datasets for training or inference in a neural network. <br>\n",
    "A data loader takes a dataset object as input and returns batches of data during training or evaluation.<br>\n",
    "A \"torch.utils.data.DataLoader\" can have several optional arguments such as the batch size, shuffle option, and number of worker <br> threads to use for data loading. <br>\n",
    "<div style=\"line-height:1.6\">\n",
    "<h4> Benefits: </h4>\n",
    "</div>\n",
    "<div style=\"margin-top: -23px;\">\n",
    "\n",
    "- Memory efficiency: A data loader can load and preprocess data in batches, which allows it to process large datasets that may not fit into memory.     \n",
    "- Data parallelism: A data loader can be used in conjunction with PyTorch's DataParallel module to split a batch of data across multiple GPUs <br> for parallel processing.    \n",
    "- Randomization: A data loader can shuffle the order of the data during training to prevent the model from overfitting to the order of the data.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load Data\n",
    "train_dataset = datasets.MNIST(root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f421886dff0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Initialize network (try out just using simple RNN, or GRU, and then compare with LSTM) \"\"\"\n",
    "model = RNN_LSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]/home/notto4/anaconda3/envs/MLearning/lib/python3.10/site-packages/torch/autograd/__init__.py:200: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "100%|██████████| 938/938 [04:21<00:00,  3.59it/s]\n",
      "100%|██████████| 938/938 [04:53<00:00,  3.19it/s]\n",
      "100%|██████████| 938/938 [04:33<00:00,  3.43it/s]\n"
     ]
    }
   ],
   "source": [
    "############## Train\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "        ## Get data to cuda if possible\n",
    "        data = data.to(device=device).squeeze(1)\n",
    "        targets = targets.to(device=device)\n",
    "        ## Forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        ## Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # Update Adam step\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    \"\"\" Compute the accuracy of the given model on the given data loader.\n",
    "\n",
    "    Parameters:\n",
    "        - Data loader to use for evaluation [torch.utils.data.DataLoader]\n",
    "        - Model to evaluate [torch.nn.Module]\n",
    "\n",
    "    Returns:\n",
    "        The accuracy of the model on the given data loader [float]\n",
    "    \"\"\"\n",
    "    i, num_correct, num_samples= 0, 0, 0\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    print(f\"type model is {type(model)}\")\n",
    "\n",
    "    # Disable gradient computation\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            i += 1\n",
    "            # Move the data to the device and remove the channel dimension\n",
    "            x = x.to(device=device).squeeze(1)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            # Compute the scores and predictions\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            if i < 10:\n",
    "                print(f\"scores are => {scores}\")\n",
    "\n",
    "            ## Update the number of correct predictions and total samples\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    # Set the model back to training mode\n",
    "    model.train()\n",
    "    # Compute the accuracy\n",
    "    acc = num_correct / num_samples\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### => Check accuracy on training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    \"\"\" Calculate the accuracy of the given model on the given data loader (num correct predictions / total num examples).\n",
    "\n",
    "    Parameters:\n",
    "        - Data loader to use for evaluation [torch.utils.data.DataLoader]\n",
    "        - Model to evaluate [torch.nn.Module]    \n",
    "    \n",
    "    Details: \n",
    "        - #   Set model to eval to disable certain layers such as dropout and batch normalization that are only used during training\n",
    "        - #   Disable gradient computation\n",
    "        - #*  Move the data to the device and remove the channel dimension\n",
    "        - #   Score and predict\n",
    "        - #** The built-in max(1) return the maximum value (ignored) and its index (used to predict)\n",
    "        - #   Update the number of correct predictions and total samples\n",
    "        - #   Set the model back to training mode\n",
    "\n",
    "    Returns:\n",
    "        The accuracy of the model on the given data loader [float]\n",
    "    \"\"\"\n",
    "    i, num_correct, num_samples= 0, 0, 0\n",
    "\n",
    "    model.eval()\n",
    "    print(f\"type model is {type(model)}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            i+=1\n",
    "            x = x.to(device=device).squeeze(1)  #*\n",
    "            y = y.to(device=device)\n",
    "            ## Predict\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)      #**\n",
    "            if i < 3:\n",
    "                print(f\"scores are => {scores}\")\n",
    "                print(f\"predictions are => {predictions}\")\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    # Toggle model back to train\n",
    "    model.train()\n",
    "    \n",
    "    return num_correct / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type model is <class '__main__.RNN_LSTM'>\n",
      "scores are => tensor([[ -1.4506,   0.6159,  11.2689,  -0.0529,  -2.3261,  -5.4228,  -4.1745,\n",
      "           3.4416,  -2.6421,  -8.0659],\n",
      "        [ 11.6694,  -3.2642,  -0.0641,  -4.5471,   0.5387,  -2.5249,   1.6720,\n",
      "          -2.8427,   1.5373,  -1.8280],\n",
      "        [-10.4789,  -2.4007,  -3.8520,  -5.3308,  19.0206,  -5.7118,  -8.8527,\n",
      "           2.9862,   0.3749,  -0.5495],\n",
      "        [-10.6375,  -2.9849,  -1.6753,  -0.5275,   0.4147,  -3.9382, -14.8768,\n",
      "           4.3097,  -2.5668,  12.9842],\n",
      "        [ 14.2484,  -4.6526,   0.3349,  -2.8458,  -2.8282,  -4.4086,  -1.7836,\n",
      "          -2.8119,   1.4300,   0.8523],\n",
      "        [ -5.5365, -10.8673,   3.5054,   6.5811,  -6.0490,  -3.7222,  -7.5258,\n",
      "          -6.1584,  15.2175,  -1.1498],\n",
      "        [  1.2060,  -4.1376,  -5.3185,  -1.6799,  -5.9375,  10.3153,   0.5505,\n",
      "          -2.6321,  -0.3931,  -1.0251],\n",
      "        [ -8.9853,  -0.8404,  -2.9307,  -3.4539,  13.4351,  -6.3206,  -6.2865,\n",
      "           1.3123,   0.8742,   2.0707],\n",
      "        [ -3.6537,  13.2946,   0.3840,  -4.6281,   0.9658,   1.7123,   2.7725,\n",
      "          -4.5934,  -0.8060,  -5.9503],\n",
      "        [  0.8992,   0.7765,  18.9310,  -0.4133,  -6.6680,  -7.8048,  -2.8520,\n",
      "          -2.1985,  -5.5113,  -5.6287],\n",
      "        [ -2.3469,  11.2339,  -1.7447,  -7.8258,   3.2681,  -0.2166,   0.2562,\n",
      "           0.8725,  -1.7873,  -4.1733],\n",
      "        [  0.7895,  -0.7578,   0.3212,  -3.6442,   1.3199,   2.5373,  13.6226,\n",
      "          -8.1837,   0.1681,  -7.9457],\n",
      "        [ -8.2178,  -3.4623,  -2.8325,  -4.8624,  14.3962,  -2.0604,  -6.2061,\n",
      "           2.3148,   0.5575,  -1.0724],\n",
      "        [ -8.6784,  -1.8499,  -4.8610,  -7.3312,  19.2479,  -2.3963,  -7.0255,\n",
      "           1.1514,  -0.4380,  -0.7208],\n",
      "        [ -8.9357,  -3.4339,  -2.1323,  -5.7534,  18.4604,  -6.5417,  -8.9172,\n",
      "           3.9602,  -0.5127,  -0.9017],\n",
      "        [ 15.1051,  -5.4104,   0.1253,  -0.9426,  -1.8231,  -4.6818,  -4.5678,\n",
      "          -2.7471,  -0.2968,   0.8728],\n",
      "        [  1.3332,   6.6371,  15.9277,  -4.2088,  -8.2498,  -4.4563,   3.2667,\n",
      "          -5.4731,  -2.4491,  -9.8909],\n",
      "        [ -3.1361,  10.9932,   0.5542,  -6.0564,   1.5682,  -0.3249,  -0.5677,\n",
      "          -0.8726,  -0.8244,  -4.0221],\n",
      "        [  0.2717,  -8.1414,   5.3843,  -0.1029,  -8.2234,  -1.7540,  -2.6900,\n",
      "         -10.2156,  13.4878,  -0.2505],\n",
      "        [  3.0107,  -0.0774,   0.1737,  -7.3214,   3.3574,   0.8008,  15.7483,\n",
      "         -10.2681,  -1.7101,  -5.7440],\n",
      "        [ -6.6538,  -2.2246,   0.0738,   8.6596,  -4.1891,   2.4959, -13.5504,\n",
      "          -1.6828,   0.1080,  -0.9060],\n",
      "        [ -5.4548,   1.9013,  -2.9188,  -4.5223,   1.4158,  -1.2196,  -8.1318,\n",
      "          13.6836,  -6.0997,   0.2211],\n",
      "        [ -2.4912,  -3.9530,  -7.3222,   0.4017, -10.3927,  17.6734,  -2.5090,\n",
      "         -10.1828,   3.4241,   0.3040],\n",
      "        [ -8.2716,  -1.1476,  -0.7027,  15.0916,  -7.9403,   2.0556, -12.4248,\n",
      "          -2.3181,  -3.1474,  -1.5387],\n",
      "        [ -7.4367,  -8.8896,   1.0564,  12.1329,  -5.2942,   2.5666,  -9.6129,\n",
      "          -4.7582,  -1.8275,   1.9566],\n",
      "        [ -1.4744, -11.1980,   0.6585,   0.6236,  -4.4312,   2.2597,  -6.1604,\n",
      "          -6.9085,  14.9209,  -2.9377],\n",
      "        [ 13.6585,  -5.9387,  -0.9646,  -2.9364,  -3.2685,  -1.8853,  -2.8931,\n",
      "          -2.8442,   1.6582,   1.4120],\n",
      "        [ -6.9050,  -5.6123,   0.9836,  15.2290,  -9.6033,   3.7441,  -8.7840,\n",
      "          -4.0518,  -3.9403,   1.2007],\n",
      "        [ -1.8337, -11.0084,   3.4640,  -0.9842,  -1.0036,  -4.8060,  -9.9176,\n",
      "          -1.9077,  14.4616,  -1.0176],\n",
      "        [ -2.3707,  12.6078,  -0.6940,  -5.4796,   0.5897,   1.0624,   2.8914,\n",
      "          -3.0853,   0.0439,  -5.8205],\n",
      "        [  2.6954,   0.2416,  -2.4200,  -5.8117,   2.6342,   1.3667,  16.8988,\n",
      "          -7.1065,  -1.8152,  -6.4692],\n",
      "        [ -8.5919,  -0.9376,  -3.3828,  -5.6885,  13.1500,  -4.0838,  -6.7187,\n",
      "          -2.0756,   0.2804,   3.4375],\n",
      "        [  4.2963,   3.0822,   7.0547,  -9.2250,   1.9293,  -4.3562,  14.6571,\n",
      "          -9.6843,  -1.6522,  -7.9292],\n",
      "        [ -7.6641,  -1.1642,   0.6312,  -5.5764,  16.7202,  -5.7738,  -5.5015,\n",
      "           0.8724,  -0.1502,  -1.6594],\n",
      "        [ -9.1040,  -5.6881,  -5.0044,  -2.9781,   5.4810,  -1.9863, -15.2473,\n",
      "          -0.5990,  -0.4695,  13.3030],\n",
      "        [-11.3601,  -0.0414,  -1.9482,  -8.3980,   7.9475,   0.4389,  -3.3716,\n",
      "           8.6330,  -1.6142,  -1.3830],\n",
      "        [ -7.7962,  -7.8941,  -0.6099,  15.2990,  -5.6986,   4.7724,  -6.4908,\n",
      "          -2.5529,  -3.3129,   0.0396],\n",
      "        [ -3.6601,  12.4069,  -1.0814,  -4.1806,   2.6636,  -1.9344,  -1.6873,\n",
      "          -0.0428,   0.2854,  -3.6873],\n",
      "        [ -0.3409,  -0.5481,  10.7287,   3.1357,  -9.3692,  -4.4410,  -6.8394,\n",
      "           2.0237,   1.4627,  -9.1985],\n",
      "        [ -7.3436,  -2.2874,   1.7708,  -1.3200,   8.6269,  -2.7801,   0.4800,\n",
      "          -6.7609,   8.8045,  -6.8876],\n",
      "        [ 14.3383,  -3.5415,   0.3337,  -5.2927,  -0.1295,  -2.0287,   2.5623,\n",
      "          -4.2174,   0.4662,  -2.0946],\n",
      "        [ -9.0469,  -0.4059,  -2.4433,  -4.6481,  12.6972,  -2.4029,  -6.3513,\n",
      "           3.9501,  -3.4675,   1.9279],\n",
      "        [-13.4770,  -2.8174,  -4.5523,  -6.6221,  15.1546,  -4.3844,  -7.5873,\n",
      "           3.3935,  -0.8066,   5.0963],\n",
      "        [ -5.1849,   2.3839,  -1.5721,  -1.6049,  -0.9465,  -1.0521, -11.5693,\n",
      "          12.2420,  -9.8464,   3.9717],\n",
      "        [ 13.1955,  -3.4800,  -0.2589,  -3.1149,  -2.0744,  -3.3910,  -0.8430,\n",
      "          -2.6678,   0.7581,  -0.8211],\n",
      "        [ -4.3846,  -2.5799,  -5.5443,  -7.7815,  15.5617,  -2.0144,  -0.4463,\n",
      "           1.1057,   1.1756,  -3.8098],\n",
      "        [ -4.8285,   0.3741,   1.7959,  -2.0360,  -2.8122,  -0.5027,  -8.8235,\n",
      "          10.4895,  -6.2702,   0.7075],\n",
      "        [ -8.7150,  -1.7212,   5.5137,   0.0453,  -2.6438,  -3.6000, -12.5736,\n",
      "          12.0152,  -7.3489,  -1.1499],\n",
      "        [ -4.1873,  -3.2786,  -4.7732,  11.0992,  -7.2546,   7.3125,  -2.3628,\n",
      "          -4.1029,  -2.7517,  -3.2404],\n",
      "        [  4.5875,  -7.5456,   3.2122,  -0.1291,  -5.3390,  -2.0148,   1.0970,\n",
      "          -6.3197,   7.4178,   0.0870],\n",
      "        [-12.7995,  -3.8883,  -7.0740,  -1.6806,   1.0019,   4.8006,  -8.2486,\n",
      "           1.5374,  -2.7422,   8.6595],\n",
      "        [ -3.0570,   0.3520,   5.5212,   1.5610,  -6.9251,  -6.0975,  -9.4410,\n",
      "          10.4138,  -1.0513,  -0.6239],\n",
      "        [  1.9311,  -1.4437,  -0.6439,  -4.8315,   4.6181,  -0.3926,  15.2257,\n",
      "          -7.9576,  -2.7886,  -6.9759],\n",
      "        [ -3.7206,  -2.0926,  14.9137,   1.0188,  -3.9726,  -6.7617,  -2.6292,\n",
      "          -0.5959,  -1.9963,  -3.6315],\n",
      "        [ -4.0370,  11.0975,  -1.9122,  -5.1673,   1.9762,  -0.8582,  -1.7688,\n",
      "           0.3111,  -0.7660,  -2.1647],\n",
      "        [ -9.5544,  -7.3927,   4.2772,  12.8894,  -8.9401,   2.3880, -14.5223,\n",
      "           5.6619,  -4.4393,  -2.5155],\n",
      "        [ -3.7167,  -3.3594,  -0.0337,  -3.9837,   3.1379,  -3.5825,  -9.6481,\n",
      "           9.4345,  -5.4662,   3.3271],\n",
      "        [ -9.1716,  -7.6355,   3.7763,  14.9372,  -9.7455,   0.9943,  -9.6644,\n",
      "          -2.7246,   2.1973,  -0.9871],\n",
      "        [ 11.0874,  -3.4839,   0.4456,   0.0535,  -1.2488,  -2.1807,  -3.1880,\n",
      "          -3.5617,   0.2114,  -2.1366],\n",
      "        [ -7.9122,  -5.8239,  -3.4613,  -0.7927,   4.0940,  -3.4576, -13.1934,\n",
      "           0.0318,  -0.9994,  11.2865],\n",
      "        [ 15.9470,  -6.3619,  -2.7976,  -2.2760,  -2.2622,   0.6176,  -1.1688,\n",
      "          -2.4345,  -1.7743,  -1.6302],\n",
      "        [ -8.4173,  -4.8322,  -2.0263,  -3.9192,   5.8102,  -7.5097, -15.2545,\n",
      "           3.2379,  -0.1975,  12.1522],\n",
      "        [  3.5161,  -1.6399,  -2.1904,  -4.0654,   1.1496,   0.9937,  12.8763,\n",
      "          -6.0179,  -1.2997,  -5.9863],\n",
      "        [  0.7509,  -2.5970,  -5.9690,  -5.0389,   7.7228,   0.3617,  20.0168,\n",
      "          -4.2233,  -3.6383,  -6.1282]])\n",
      "predictions are => tensor([2, 0, 4, 9, 0, 8, 5, 4, 1, 2, 1, 6, 4, 4, 4, 0, 2, 1, 8, 6, 3, 7, 5, 3,\n",
      "        3, 8, 0, 3, 8, 1, 6, 4, 6, 4, 9, 7, 3, 1, 2, 8, 0, 4, 4, 7, 0, 4, 7, 7,\n",
      "        3, 8, 9, 7, 6, 2, 1, 3, 7, 3, 0, 9, 0, 9, 6, 6])\n",
      "scores are => tensor([[-8.8107e+00, -6.0454e+00, -9.1747e+00,  2.9655e+00, -3.4334e+00,\n",
      "          1.3820e+01, -5.8939e-01, -1.1157e+01,  9.6405e-01,  2.8762e+00],\n",
      "        [-9.9972e-01, -7.1659e+00,  4.6820e+00, -7.4761e-01, -2.7406e+00,\n",
      "         -3.0951e+00,  2.1037e+00, -1.0010e+01,  1.2825e+01, -2.1075e+00],\n",
      "        [-1.2144e+01, -9.1187e+00, -1.5593e+00,  1.5516e+01, -8.7938e+00,\n",
      "          4.0771e+00, -1.2389e+01, -1.2816e+00,  9.9593e-01,  1.3932e+00],\n",
      "        [-4.4133e+00, -2.8011e+00, -2.9670e+00, -2.5019e+00,  1.2299e+01,\n",
      "         -5.2476e+00, -2.6831e+00,  4.1583e+00, -6.3979e-01, -9.1405e-01],\n",
      "        [-2.1264e+00, -7.3493e+00,  2.3331e+00, -1.0012e+00, -4.3279e+00,\n",
      "          2.0307e-01, -8.2188e+00, -6.5947e+00,  1.3194e+01,  8.5124e-01],\n",
      "        [-1.6412e+00, -6.7387e+00,  4.9017e+00,  1.4398e+00, -2.6373e+00,\n",
      "         -3.3643e+00,  5.2501e-01, -1.1757e+01,  1.2589e+01, -4.2817e-01],\n",
      "        [-9.4560e+00, -8.6599e+00, -7.5048e+00,  6.1385e+00, -4.0125e+00,\n",
      "          1.5011e+01, -1.1314e+00, -1.0093e+01, -7.0212e-02,  1.0276e+00],\n",
      "        [-1.1138e+01, -7.3905e+00, -1.0229e+00,  1.6115e+01, -9.5930e+00,\n",
      "          5.1842e+00, -1.2829e+01, -1.3356e+00, -2.0365e+00,  1.8676e+00],\n",
      "        [-8.2216e+00, -6.4445e+00, -6.0838e-01, -3.5762e+00,  4.0089e+00,\n",
      "         -6.2720e+00, -1.4678e+01,  3.2430e+00, -1.1520e+00,  1.3444e+01],\n",
      "        [-9.7769e+00, -3.2690e+00, -2.0703e-01, -7.6686e+00,  1.7910e+01,\n",
      "         -8.7752e+00, -8.5568e+00,  4.5992e+00,  9.7984e-01,  1.2811e-01],\n",
      "        [-2.5731e+00, -8.4269e+00,  3.8025e+00,  5.7610e-01, -7.8987e+00,\n",
      "         -3.4048e+00, -5.4649e+00, -6.5275e+00,  1.5216e+01,  1.6817e+00],\n",
      "        [ 4.5165e+00, -5.2381e+00,  4.0477e-01, -8.4959e+00,  7.2345e-01,\n",
      "          1.2673e+00,  1.7136e+01, -7.9487e+00, -2.7212e+00, -6.9235e+00],\n",
      "        [-2.5040e+00, -3.4486e+00,  1.5186e+01,  1.2970e+00, -7.2611e+00,\n",
      "         -8.0334e+00, -4.2933e-01,  3.2161e-01, -2.5770e+00, -5.4862e+00],\n",
      "        [-1.0972e+00,  4.3206e+00,  1.4839e+01,  1.2374e+00, -7.8455e+00,\n",
      "         -6.1190e+00, -4.9295e+00,  1.1041e-01, -1.6624e+00, -5.1163e+00],\n",
      "        [-6.2577e+00, -1.6458e+00, -1.2230e+00, -8.0603e+00,  1.8707e+01,\n",
      "         -5.1512e+00, -3.2896e+00,  7.1177e-01,  2.4694e+00, -4.4745e+00],\n",
      "        [-8.8101e+00, -6.1489e+00, -6.3301e+00,  6.0816e-01, -3.7953e+00,\n",
      "          1.4275e+01, -4.6831e+00, -4.6882e+00, -1.1345e+00,  1.4179e+00],\n",
      "        [-4.0305e+00, -4.4682e+00,  1.9131e+01,  9.0305e-01, -3.7494e+00,\n",
      "         -8.3105e+00, -2.9347e+00, -1.7292e+00, -3.9519e-01, -6.1122e+00],\n",
      "        [-1.0396e+01, -1.0017e+00, -4.8044e+00, -4.7760e+00,  1.4435e+01,\n",
      "         -1.9649e+00, -5.4631e+00,  2.1468e+00,  2.0694e+00, -1.7461e+00],\n",
      "        [ 8.8881e-01, -5.2615e+00,  6.0713e+00, -4.9902e+00, -4.1739e+00,\n",
      "         -3.0372e+00, -5.7199e+00, -7.6446e+00,  1.5334e+01, -1.1457e+00],\n",
      "        [-5.8148e+00,  1.4976e+00,  3.3678e-01, -3.1534e+00, -2.9618e+00,\n",
      "         -4.3197e+00, -1.2154e+01,  1.4369e+01, -6.1053e+00,  1.8644e+00],\n",
      "        [-3.9243e+00,  2.1562e+00,  1.4557e+01, -1.9926e+00, -4.4107e+00,\n",
      "         -8.2024e+00, -5.3533e+00,  3.2915e+00, -1.8161e+00, -6.0125e+00],\n",
      "        [-1.7346e+00,  9.3795e+00, -1.3235e+00, -6.3780e+00,  2.5162e+00,\n",
      "         -3.1608e-02, -6.2690e-01,  1.2638e+00, -1.5690e+00, -2.3032e+00],\n",
      "        [-4.7136e+00, -1.1088e+00,  8.7681e+00, -2.1026e+00,  3.8384e+00,\n",
      "         -1.5814e+00, -1.9836e+00, -4.6593e+00,  1.0882e+00, -4.0050e+00],\n",
      "        [-3.6836e+00,  5.8823e+00,  5.0040e+00, -1.3622e+00,  9.4749e-01,\n",
      "         -9.2488e-01, -1.8122e+00,  5.8303e-01, -5.5515e+00, -4.4503e+00],\n",
      "        [-2.6569e+00,  1.1392e+01,  7.5663e-01, -7.1339e+00,  2.0440e+00,\n",
      "          4.4151e-02, -2.3186e-01, -5.7612e-01, -1.3982e+00, -5.4029e+00],\n",
      "        [ 9.8928e+00, -6.9012e+00,  6.0060e-01, -3.0009e+00, -1.3852e+00,\n",
      "         -1.8234e+00, -1.4626e+00,  2.4765e-02, -3.2081e+00, -5.3690e-01],\n",
      "        [-1.0669e+01, -6.8522e+00, -6.9376e+00,  8.8084e-02, -2.5841e+00,\n",
      "          1.2212e+01,  1.9434e+00, -8.2010e+00,  7.6425e-01,  2.2150e+00],\n",
      "        [-5.4693e+00, -2.9845e+00,  3.6162e+00, -1.7512e-01, -4.6261e+00,\n",
      "         -2.7763e+00, -1.1550e+01,  6.8734e+00, -4.5127e+00,  7.2223e+00],\n",
      "        [-8.0315e+00, -6.2027e+00, -4.8769e+00, -1.9434e+00,  2.4048e+00,\n",
      "         -3.8402e-01, -8.6296e+00, -1.0978e-01, -9.4798e-01,  9.9990e+00],\n",
      "        [-6.6291e+00, -6.8774e+00, -8.6986e+00,  1.6925e+00, -7.4871e+00,\n",
      "          1.8246e+01, -2.7896e-01, -1.0931e+01,  4.2381e+00, -2.2038e+00],\n",
      "        [-8.7275e+00, -1.1214e+00, -8.8637e-01, -3.7649e+00, -1.3717e+00,\n",
      "         -3.1645e+00, -1.3346e+01,  1.4172e+01, -3.1429e+00,  2.6876e+00],\n",
      "        [-7.3415e+00, -6.6039e+00, -2.8106e+00, -2.0717e+00,  5.7445e+00,\n",
      "         -6.9965e+00, -1.3260e+01,  2.5509e+00, -1.9361e+00,  1.2056e+01],\n",
      "        [-1.1162e+01, -1.3473e+01, -9.1024e+00,  4.7398e+00, -7.2423e+00,\n",
      "          1.8739e+01, -6.4300e+00, -6.3466e+00, -1.5898e+00,  4.5401e+00],\n",
      "        [-4.7435e+00, -6.5900e+00, -1.0642e+01, -8.1865e-01, -4.4095e+00,\n",
      "          1.7336e+01, -1.6395e+00, -9.8450e+00,  1.1259e+00,  1.5414e+00],\n",
      "        [ 1.4833e+01, -3.3892e+00, -1.5397e+00, -2.1393e+00, -1.3681e+00,\n",
      "         -3.5203e+00, -4.0189e-01, -2.9039e+00, -1.2669e-01, -2.3131e+00],\n",
      "        [-2.5805e+00,  1.0092e+01,  2.3800e+00, -4.7778e+00, -1.7768e-01,\n",
      "         -1.3939e+00, -8.6384e-01, -1.3353e+00, -4.3142e-01, -4.7133e+00],\n",
      "        [-6.0008e+00, -4.9962e+00, -9.7000e+00,  2.1455e+00, -3.0358e+00,\n",
      "          1.2930e+01,  6.9834e-01, -1.0930e+01, -7.8418e-01,  1.1399e+00],\n",
      "        [-3.9955e-01, -5.3199e+00, -3.1798e+00, -5.2230e+00,  5.8877e+00,\n",
      "         -1.0753e-01,  2.0808e+01, -5.6179e+00, -2.3753e+00, -7.8576e+00],\n",
      "        [-3.4953e+00, -1.7709e+00, -2.1832e+00, -8.9393e+00,  2.0817e+01,\n",
      "         -8.0208e+00, -6.5466e-01,  5.0195e+00, -1.2106e+00, -6.3132e+00],\n",
      "        [-9.4075e+00,  2.7744e+00, -8.0351e-03,  9.3889e-01, -4.2039e-01,\n",
      "         -5.6167e+00, -1.2091e+01,  1.0597e+01, -5.3421e+00,  8.5816e-01],\n",
      "        [-7.1104e+00, -2.6608e+00, -3.5378e+00, -6.9892e+00,  1.6667e+01,\n",
      "         -3.9051e+00, -3.2738e+00,  1.6152e+00, -1.1292e+00, -2.3901e+00],\n",
      "        [-3.3559e+00, -3.5863e+00,  1.6024e+01,  8.9329e-01, -6.7126e+00,\n",
      "         -8.2304e+00, -3.3031e+00, -1.9741e-01,  1.1901e+00, -4.4205e+00],\n",
      "        [-8.2622e+00, -2.8375e+00, -2.6548e+00,  1.4711e+01, -8.4654e+00,\n",
      "          4.8596e+00, -1.0422e+01, -1.7048e+00, -2.3964e+00, -6.5598e-01],\n",
      "        [-7.1521e+00,  5.4160e-02,  7.6804e-02, -1.0154e+00, -2.9152e+00,\n",
      "         -3.4999e+00, -1.3114e+01,  1.2785e+01, -4.5458e+00,  1.7266e+00],\n",
      "        [-4.2963e+00,  5.0798e+00,  1.5299e+01, -2.1372e+00, -6.6409e+00,\n",
      "         -5.0055e+00,  1.4468e-01, -2.9683e+00, -3.0446e+00, -7.4567e+00],\n",
      "        [-6.6464e+00, -3.6631e+00, -2.3569e+00, -5.8143e+00,  1.3377e+01,\n",
      "         -5.8514e+00, -7.7680e+00,  2.2023e+00,  4.7738e+00,  9.9509e-01],\n",
      "        [-9.1427e+00, -7.8757e-01, -2.6257e+00, -5.4529e+00,  1.6438e+01,\n",
      "         -5.0580e+00, -7.2473e+00,  4.0498e+00, -2.9790e+00,  1.9208e+00],\n",
      "        [-3.8327e+00, -5.3822e+00,  1.1100e+00, -4.0238e+00,  2.5305e+00,\n",
      "         -2.7533e+00, -4.0995e+00, -2.0281e+00,  2.5955e+00,  3.1961e+00],\n",
      "        [-8.6570e+00, -1.5162e+00, -2.9365e+00, -7.0426e+00,  1.7215e+01,\n",
      "         -4.9306e+00, -2.6336e+00,  1.9401e+00,  1.2034e+00, -3.4579e+00],\n",
      "        [-3.3837e+00, -3.0259e+00, -2.7755e+00, -6.4093e+00,  1.3550e+01,\n",
      "         -6.0050e+00, -2.6515e+00,  4.2065e+00, -1.5847e+00, -6.0302e-01],\n",
      "        [ 2.3684e+00, -1.1757e+00,  1.1229e+01, -3.4135e-01, -4.5836e+00,\n",
      "         -4.9011e+00, -8.9569e-01, -2.2779e+00,  2.6167e-01, -5.2972e+00],\n",
      "        [-6.9566e+00, -6.1628e+00, -3.3170e-01, -4.1277e+00, -5.1230e+00,\n",
      "          8.3768e+00,  2.0668e+00, -3.5102e+00, -3.2014e+00,  3.0195e+00],\n",
      "        [-1.1891e+01, -8.4861e+00, -1.7776e+00,  4.2793e+00, -8.6038e+00,\n",
      "          1.4461e+01, -2.6723e+00, -7.5409e+00,  8.9907e-01,  2.2673e-01],\n",
      "        [-6.9742e+00, -6.9749e+00,  2.2018e+00,  1.6165e+00, -4.1913e+00,\n",
      "         -2.7403e+00, -2.6835e+00, -8.0652e+00,  1.7881e+01, -3.8736e+00],\n",
      "        [-4.8155e+00, -6.0893e+00,  2.9809e-01,  1.2063e+01, -8.5866e+00,\n",
      "          2.7234e+00, -6.5037e+00, -2.9737e+00, -1.7604e-01, -5.8241e-01],\n",
      "        [-7.8585e+00, -4.9044e+00, -6.7271e+00, -2.5383e+00,  4.0587e+00,\n",
      "         -2.3302e+00, -1.6131e+01,  3.6953e+00, -3.4467e+00,  1.4425e+01],\n",
      "        [-9.6673e+00, -4.2157e+00, -4.9316e+00, -6.9154e+00,  1.8668e+01,\n",
      "         -4.3167e+00, -8.0159e+00,  3.0525e+00, -2.6801e+00,  2.3776e+00],\n",
      "        [ 3.6544e+00, -3.4390e+00,  1.0310e+00, -7.3122e+00,  2.6086e+00,\n",
      "         -1.3391e+00,  2.2101e+01, -8.4399e+00, -4.1123e+00, -9.1509e+00],\n",
      "        [-5.1334e+00, -3.1325e+00,  5.3008e+00,  9.4312e+00, -8.6394e+00,\n",
      "         -3.1433e-01, -1.2273e+01,  1.0481e+00, -4.2113e+00, -1.9627e+00],\n",
      "        [ 2.8255e+00, -2.4858e+00, -1.7926e+00, -4.2421e+00,  3.9998e+00,\n",
      "         -1.5396e-01,  1.7877e+01, -5.4553e+00, -3.6118e+00, -6.5292e+00],\n",
      "        [-3.7093e+00, -2.2199e+00, -8.8592e-01, -7.4469e+00,  1.6001e+01,\n",
      "         -8.6994e+00, -3.5569e+00,  5.3244e+00, -2.3349e+00, -1.5525e+00],\n",
      "        [-3.5990e+00, -4.4760e+00,  2.7678e+00, -7.5759e-01,  4.5458e+00,\n",
      "         -4.1160e+00, -3.4223e+00, -6.4812e+00,  1.3770e+01, -8.9987e+00],\n",
      "        [ 1.4846e+01, -5.8998e+00, -3.5276e+00, -2.7550e+00, -1.9391e+00,\n",
      "         -1.6955e+00, -1.7038e+00, -2.0560e+00,  4.9989e-01,  8.9640e-02],\n",
      "        [ 1.0862e+00, -4.7789e+00, -8.2870e-01, -7.9407e+00,  7.8867e+00,\n",
      "         -2.0855e+00,  1.8541e+01, -4.3797e+00, -5.8999e+00, -8.5130e+00]])\n",
      "predictions are => tensor([5, 8, 3, 4, 8, 8, 5, 3, 9, 4, 8, 6, 2, 2, 4, 5, 2, 4, 8, 7, 2, 1, 2, 1,\n",
      "        1, 0, 5, 9, 9, 5, 7, 9, 5, 5, 0, 1, 5, 6, 4, 7, 4, 2, 3, 7, 2, 4, 4, 9,\n",
      "        4, 4, 2, 5, 5, 8, 3, 9, 4, 6, 3, 6, 4, 8, 0, 6])\n",
      "Accuracy on training set: 98.586670\n",
      "type model is <class '__main__.RNN_LSTM'>\n",
      "scores are => tensor([[-6.6410e+00,  4.7441e+00, -4.5095e+00, -5.8642e+00,  2.3056e+00,\n",
      "          1.6804e-01, -2.8742e+00,  1.0138e+01, -5.0328e+00,  9.7708e-01],\n",
      "        [ 1.1664e+01, -5.2146e+00, -7.0603e-01, -2.2241e+00, -3.0827e+00,\n",
      "         -2.5474e+00, -1.1658e+00, -1.6187e+00,  1.3898e+00, -2.9076e-01],\n",
      "        [ 1.3034e+00, -6.6216e+00,  5.4948e-01, -7.8867e-01,  9.4073e-01,\n",
      "         -1.7176e+00, -9.3340e+00,  9.3508e-01, -1.3642e+00,  5.3616e+00],\n",
      "        [-6.2722e+00, -3.1438e+00, -4.9433e+00, -4.1881e+00,  6.4094e+00,\n",
      "         -5.2819e+00, -1.3631e+01,  4.8850e+00, -2.0089e+00,  9.2342e+00],\n",
      "        [-3.3572e+00,  1.1857e+01, -1.6766e+00, -3.8294e+00,  1.1740e+00,\n",
      "         -2.5398e-01, -8.6748e-01, -7.2697e-01,  6.3615e-02, -4.8092e+00],\n",
      "        [-1.0924e+01, -3.0986e-01, -5.8987e+00, -3.5763e+00,  1.5181e+01,\n",
      "         -5.2678e+00, -1.0379e+01,  1.7594e+00,  8.7525e-01,  2.6417e+00],\n",
      "        [-9.6524e+00,  1.6982e+00, -6.3806e-01, -9.0319e-02, -2.2536e+00,\n",
      "         -3.2813e+00, -1.3859e+01,  1.3125e+01, -1.7345e+00, -1.4292e+00],\n",
      "        [ 1.4465e+01, -7.6409e+00, -2.8765e+00, -8.1487e-01, -4.5253e+00,\n",
      "          3.5205e-01, -4.0703e+00, -2.2176e+00,  1.7034e+00,  1.0843e+00],\n",
      "        [ 1.3565e+01, -5.8683e+00,  5.9590e-01, -3.3593e+00, -3.4987e+00,\n",
      "         -3.2487e+00, -2.7485e+00, -3.0161e+00,  1.0958e+00,  2.3126e+00],\n",
      "        [-7.7746e+00, -1.3196e+00, -6.3340e+00,  4.4115e+00, -8.7645e+00,\n",
      "          1.5256e+01, -3.8649e+00, -9.8521e+00,  2.2480e+00,  3.6805e-03],\n",
      "        [-8.5941e+00, -3.5757e+00,  8.5383e-01,  1.5521e+01, -8.4595e+00,\n",
      "          2.4434e+00, -1.0238e+01, -2.7291e+00, -1.8567e+00, -1.8845e+00],\n",
      "        [-1.1331e+01, -3.2009e+00, -3.2457e+00, -1.6432e+00,  3.0523e+00,\n",
      "         -4.4417e+00, -1.3747e+01,  3.7836e+00,  2.4048e+00,  8.5820e+00],\n",
      "        [-3.5432e+00, -3.2879e+00,  5.3906e+00,  7.7527e-01, -5.0507e+00,\n",
      "         -1.2291e-01, -8.7812e+00, -2.2136e+00, -9.7172e-01,  4.9748e+00],\n",
      "        [-7.7923e+00, -7.6098e+00, -6.4868e+00,  3.3536e+00, -7.4187e+00,\n",
      "          1.1395e+01, -1.6013e+00, -6.3550e+00, -5.6877e-02,  3.1049e+00],\n",
      "        [ 6.6057e+00,  1.0672e+00,  8.7375e-01, -3.9648e+00,  1.9079e+00,\n",
      "         -1.4488e+00,  2.8417e+00, -3.1591e+00,  1.0376e-01, -7.8283e+00],\n",
      "        [-1.0233e+01,  1.8618e+00, -1.5818e-01, -2.9460e+00,  1.6043e-01,\n",
      "         -4.7991e+00, -1.3774e+01,  1.4644e+01, -4.3810e+00,  8.6908e-02],\n",
      "        [-2.3295e+00, -1.1777e+00, -1.2500e+00, -4.5271e+00, -6.8382e-01,\n",
      "         -3.5806e+00, -1.5164e+01,  1.5048e+01, -4.0679e+00,  4.8140e+00],\n",
      "        [ 4.4086e-02, -2.3944e+00, -1.2629e+00, -4.3960e+00,  7.0183e+00,\n",
      "         -1.2696e+00,  1.8563e+01, -2.6447e+00, -5.8125e+00, -7.7438e+00],\n",
      "        [-7.1379e+00,  1.3519e+01, -1.0819e+00, -4.0355e+00,  2.8771e+00,\n",
      "         -2.5835e+00, -3.8006e+00,  3.5692e+00, -1.7310e+00, -3.0148e+00],\n",
      "        [-4.0352e+00, -4.8593e-01, -2.3098e+00, -2.7872e+00,  8.4422e+00,\n",
      "         -5.1378e+00,  3.0040e-01, -1.3896e+00, -1.1834e+00,  1.8261e+00],\n",
      "        [-1.2896e+00, -2.7530e+00,  1.5436e+01,  2.7176e+00, -1.2016e+01,\n",
      "         -7.8178e+00, -8.0725e+00,  2.6919e+00,  2.2584e-01, -3.4269e+00],\n",
      "        [-8.4538e+00,  4.5289e+00, -1.9874e+00, -3.1091e+00, -2.9796e-01,\n",
      "         -1.7031e+00, -1.0037e+01,  1.1858e+01, -5.3386e+00,  1.2746e+00],\n",
      "        [ 1.5012e+01, -4.0463e+00, -2.5636e+00, -2.0913e+00, -1.2331e+00,\n",
      "         -3.1530e+00, -2.4479e+00, -2.3014e+00,  2.9373e-01, -5.7299e-01],\n",
      "        [-9.5171e+00, -5.5341e+00, -9.2835e+00, -4.2639e+00,  7.1207e+00,\n",
      "          1.8068e-02, -6.8211e+00, -2.6902e+00, -2.0958e+00,  1.1325e+01],\n",
      "        [ 6.1190e+00, -5.3026e+00, -5.4624e+00, -3.7871e+00, -2.4396e+00,\n",
      "          1.7698e+00,  1.6643e+01, -1.0896e+01,  3.7803e-01, -1.5809e+00],\n",
      "        [ 1.2689e+00, -5.2754e+00,  1.5303e+01, -1.0836e+00, -3.9840e+00,\n",
      "         -7.1416e+00, -5.9929e+00, -1.8017e-01, -1.2098e+00, -2.3532e+00],\n",
      "        [ 2.6142e+00, -1.8630e+00, -2.9113e+00, -1.5881e+00, -2.1905e+00,\n",
      "          7.0752e+00,  6.6564e+00, -4.8196e+00,  2.5626e-01, -4.7412e+00],\n",
      "        [-4.7132e+00,  2.5318e+00, -4.9846e-03, -1.6046e+00, -1.5069e+00,\n",
      "         -5.0890e+00, -1.2135e+01,  1.4753e+01, -6.3815e+00,  3.5357e+00],\n",
      "        [-2.2924e+00,  1.0248e+01,  3.8747e-01, -6.5780e+00,  1.8686e+00,\n",
      "         -4.0073e-01,  2.8621e-01, -3.5122e+00, -2.6575e-01, -2.2687e+00],\n",
      "        [ 7.5050e+00, -1.0604e+00,  1.4218e+00, -8.0586e+00,  2.2195e+00,\n",
      "         -2.5067e+00,  1.4890e+01, -5.0534e+00, -3.5424e+00, -6.8923e+00],\n",
      "        [-9.9794e+00, -6.4267e+00,  4.6176e+00,  1.5354e+01, -7.4442e+00,\n",
      "          5.7318e-01, -9.9349e+00, -9.1116e-01, -1.6620e+00, -4.4687e+00],\n",
      "        [-5.0406e+00,  1.2218e+01, -1.6686e+00, -3.3277e+00,  1.5688e+00,\n",
      "         -3.0695e+00, -3.4389e+00,  2.0143e+00,  1.4367e+00, -2.3538e+00],\n",
      "        [-1.0684e+01, -5.3425e+00, -3.6145e+00,  1.9431e+01, -1.0323e+01,\n",
      "          5.2114e+00, -1.2951e+01, -4.8199e+00,  1.3455e-01,  3.7990e+00],\n",
      "        [ 5.5503e+00, -1.5114e+00, -1.9499e+00, -5.6842e+00,  3.4032e+00,\n",
      "          4.4171e-01,  2.0901e+01, -7.5011e+00, -4.3975e+00, -8.4855e+00],\n",
      "        [-1.0164e-01, -7.6528e+00,  4.8818e+00, -3.7635e-02, -7.2678e+00,\n",
      "         -1.6504e+00, -4.1887e+00, -8.8283e+00,  1.3821e+01, -6.0669e-01],\n",
      "        [ 9.7193e+00, -2.5212e-01, -2.4581e+00, -3.0357e+00, -2.5874e+00,\n",
      "         -7.5772e-02,  1.1261e+00, -4.6211e+00,  4.1887e+00, -3.1189e+00],\n",
      "        [-5.3864e+00, -1.7628e+00,  1.5169e+01,  2.9768e+00, -4.1238e+00,\n",
      "         -7.6532e+00, -6.6934e+00,  1.3656e+00, -6.5406e-01, -4.8525e+00],\n",
      "        [-7.7747e+00, -5.8308e+00,  6.4559e-02,  1.3851e+01, -7.8252e+00,\n",
      "          1.2749e+00, -1.1439e+01, -1.9099e+00, -6.4400e-01,  6.1291e-01],\n",
      "        [-7.8126e+00, -2.6136e+00,  7.5970e+00,  3.0071e+00, -6.3496e+00,\n",
      "          4.4870e-01, -1.0706e+01,  6.2967e+00, -3.3734e+00, -1.4764e+00],\n",
      "        [-8.8607e+00, -3.1661e+00, -1.2291e-01,  1.3820e+01, -8.3077e+00,\n",
      "          2.3613e+00, -1.3505e+01, -2.0629e+00, -3.0251e+00,  4.7607e-01],\n",
      "        [-3.3046e+00,  1.0328e+01,  1.6604e+00, -6.0966e+00,  2.6452e+00,\n",
      "         -7.4446e-01,  5.8259e-01, -1.0567e+00, -4.1819e-01, -7.8822e+00],\n",
      "        [-9.6165e+00, -2.5162e+00, -5.9360e+00,  1.7376e+00,  8.2366e-01,\n",
      "          1.2221e+01,  3.8335e+00, -8.9419e+00, -2.5527e+00, -2.0978e+00],\n",
      "        [-2.6511e+00, -9.2908e+00, -9.2160e+00,  1.5905e+00, -5.9859e+00,\n",
      "          1.6176e+01, -8.4729e-01, -9.3637e+00,  9.1576e-02,  8.2060e-01],\n",
      "        [-5.1070e+00, -1.1855e+01,  4.6239e+00,  6.5856e-01, -6.1564e+00,\n",
      "         -3.9966e-01, -7.6997e+00, -5.3457e+00,  1.7336e+01,  2.5990e-01],\n",
      "        [-6.9291e-01, -3.1560e+00,  1.7948e+01, -1.1802e-01, -7.0549e+00,\n",
      "         -7.2143e+00, -2.6545e+00, -2.0795e+00, -6.0825e-01, -5.5961e+00],\n",
      "        [-3.7759e+00, -1.0265e+00,  1.9145e+01,  1.6668e+00, -5.0237e+00,\n",
      "         -9.0288e+00, -7.2755e+00,  2.6327e+00, -3.3922e+00, -6.4406e+00],\n",
      "        [-8.4361e+00, -6.6620e+00, -7.4838e+00, -1.2300e+00,  1.0327e+00,\n",
      "          1.4369e+00, -1.0592e+01,  4.5068e+00, -3.0731e+00,  1.0203e+01],\n",
      "        [ 4.3473e+00, -7.5140e+00, -3.4907e-01, -4.8996e+00,  4.6780e+00,\n",
      "         -2.2261e+00,  1.3328e+01, -8.6306e+00,  1.0311e+00, -5.7137e+00],\n",
      "        [-8.8933e+00, -6.9901e+00,  3.6557e+00,  5.2945e-01, -4.9432e+00,\n",
      "          1.0565e+00, -1.4419e+00, -8.7552e+00,  1.5089e+01, -5.7714e+00],\n",
      "        [-5.6261e+00, -1.3062e+00, -4.9457e+00, -6.2262e+00,  1.1004e+01,\n",
      "         -3.5737e+00, -8.6255e+00, -9.4460e-01,  1.7927e+00,  6.4665e+00],\n",
      "        [-4.7636e+00,  1.0126e+01, -3.6759e-01, -5.0706e+00,  1.8785e+00,\n",
      "         -2.6101e+00, -2.9071e+00,  2.8443e+00, -1.5593e+00, -2.7173e+00],\n",
      "        [-1.0888e+01, -8.6927e+00, -5.4608e+00,  1.9532e+01, -1.0084e+01,\n",
      "          1.0900e+01, -1.1698e+01, -4.0419e+00, -6.4727e-01,  1.9486e+00],\n",
      "        [-1.7060e+00,  1.0599e+01,  7.3324e-01, -5.2255e+00,  2.1896e-01,\n",
      "         -6.4713e-01,  1.9032e+00, -3.5646e+00,  6.3655e-01, -4.2625e+00],\n",
      "        [-2.7482e-01, -3.2173e+00,  1.6532e+01,  3.2645e-01, -2.2456e+00,\n",
      "         -6.2164e+00, -6.9112e+00,  1.8616e+00, -3.7228e+00, -1.0192e+01],\n",
      "        [-8.4382e+00, -6.8203e+00,  9.4669e-01,  1.4625e+01, -8.3381e+00,\n",
      "          5.0343e+00, -9.0687e+00, -2.7645e+00,  8.6270e-01, -4.1340e+00],\n",
      "        [-3.1247e+00,  1.1736e+01,  5.8531e-01, -7.3562e+00,  3.0600e+00,\n",
      "         -2.1657e-01, -2.0292e-01,  2.5451e-02, -1.4698e+00, -5.7578e+00],\n",
      "        [ 5.8622e+00, -1.2835e+00, -3.2977e+00, -4.4091e+00, -1.3085e-01,\n",
      "          2.0855e+00,  1.5464e+01, -7.0803e+00, -1.9506e+00, -4.5103e+00],\n",
      "        [-5.5587e+00, -8.1741e+00,  4.1639e+00, -1.9022e+00, -1.7958e+00,\n",
      "         -1.5533e+00, -5.5103e+00, -6.4902e+00,  1.5317e+01,  4.4468e-02],\n",
      "        [-7.8212e+00,  1.2382e+00, -1.8069e-01, -7.0049e-02, -3.4170e+00,\n",
      "         -3.2172e+00, -1.2766e+01,  1.1901e+01, -6.0305e+00,  2.7396e+00],\n",
      "        [ 1.4820e+00, -6.6763e+00, -5.2040e-01, -6.5005e+00,  6.9944e-01,\n",
      "          2.3003e+00,  1.8051e+01, -1.1883e+01,  4.9042e-02, -6.4913e+00],\n",
      "        [-1.0450e+01, -1.9397e+00, -1.8473e-01, -6.6105e+00,  1.5609e+01,\n",
      "         -5.8866e+00, -8.9567e+00,  2.6451e+00,  7.4900e-01,  1.6088e+00],\n",
      "        [ 1.2263e+01, -5.4997e+00,  7.2706e-01, -2.1453e+00, -3.2721e+00,\n",
      "         -4.4000e+00, -3.1109e+00, -6.2065e-01,  2.0924e-01,  2.0239e+00],\n",
      "        [-7.3575e+00, -7.2178e+00,  1.3539e+00,  3.1862e+00, -6.4004e+00,\n",
      "          5.7645e-01, -2.1797e+00, -6.6280e+00,  1.4728e+01, -3.4001e+00],\n",
      "        [-2.3549e+00,  1.7384e+00,  9.6347e+00, -2.7731e+00, -2.4246e+00,\n",
      "         -7.4359e+00, -1.6886e+00, -2.9046e+00,  2.9732e+00, -3.0443e+00]])\n",
      "predictions are => tensor([7, 0, 9, 9, 1, 4, 7, 0, 0, 5, 3, 9, 2, 5, 0, 7, 7, 6, 1, 4, 2, 7, 0, 9,\n",
      "        6, 2, 5, 7, 1, 6, 3, 1, 3, 6, 8, 0, 2, 3, 2, 3, 1, 5, 5, 8, 2, 2, 9, 6,\n",
      "        8, 4, 1, 3, 1, 2, 3, 1, 6, 8, 7, 6, 4, 0, 8, 2])\n",
      "scores are => tensor([[-1.0042e+01, -1.1719e+00, -1.8832e+00, -7.0999e+00,  1.6958e+01,\n",
      "         -6.2267e+00, -5.1574e+00,  1.7567e+00, -5.3593e-01,  1.9108e-01],\n",
      "        [-6.4565e+00, -1.1806e+00,  1.1697e+00, -5.6680e+00,  1.4266e+01,\n",
      "         -3.2603e+00, -4.3500e+00, -4.1553e-01, -1.0531e+00, -3.3315e+00],\n",
      "        [ 1.1402e+01, -4.8771e+00,  2.3888e+00, -2.9535e+00, -3.8384e-01,\n",
      "         -5.5301e+00, -1.7984e+00, -4.9948e-01, -1.1458e+00, -1.0665e+00],\n",
      "        [-2.1221e+00,  5.2662e-01,  1.4370e+01, -7.6062e-01, -8.6490e+00,\n",
      "         -5.9137e+00, -7.2885e+00,  2.0811e+00, -8.5393e-01, -4.3255e+00],\n",
      "        [-2.1297e+00,  1.0936e+01,  3.1275e-01, -6.3383e+00,  1.2145e+00,\n",
      "          4.5336e-01,  5.2092e-01, -1.7986e+00, -1.6679e+00, -3.6604e+00],\n",
      "        [-1.1491e+01, -9.3913e-01,  9.6332e-01, -6.2100e+00,  1.6206e+01,\n",
      "         -5.9215e+00, -4.6600e+00,  6.5442e+00,  3.0701e-01, -3.5935e+00],\n",
      "        [-1.2653e+00, -7.3687e+00,  4.4833e+00,  4.6387e-01, -2.1221e+00,\n",
      "         -3.5263e+00, -3.0207e+00, -7.0086e+00,  1.3703e+01, -3.9115e+00],\n",
      "        [-6.1897e+00, -8.3530e+00,  4.9033e+00,  2.4242e+00, -6.1116e+00,\n",
      "         -4.5239e+00, -6.4667e+00, -7.9647e+00,  1.8960e+01, -6.1433e-01],\n",
      "        [-2.5303e+00,  1.0137e+01, -1.5574e+00, -4.0997e+00,  1.2890e+00,\n",
      "          1.3425e+00,  7.0948e+00, -3.3520e+00, -1.8488e+00, -6.0565e+00],\n",
      "        [-3.6946e+00, -4.3982e+00,  1.0286e+00, -2.4013e+00,  7.1362e+00,\n",
      "         -8.4144e+00, -9.9493e+00,  2.0279e+00, -3.4362e+00,  1.0415e+01],\n",
      "        [-5.0367e+00, -3.8337e+00,  6.9308e-01,  1.4130e+01, -8.9136e+00,\n",
      "          3.9642e+00, -9.1316e+00, -1.7498e+00, -3.3871e+00, -1.7814e+00],\n",
      "        [-5.4542e+00, -7.6430e+00, -5.9856e+00,  6.0278e-01, -5.4884e+00,\n",
      "          1.4430e+01,  2.4345e+00, -8.6735e+00,  1.2170e+00, -2.3821e+00],\n",
      "        [-3.3706e+00,  2.5077e+00,  1.2419e+01, -1.1617e+00, -4.5983e+00,\n",
      "         -4.7942e+00, -2.2291e+00,  2.2314e-01, -1.5909e+00, -5.4036e+00],\n",
      "        [-7.5359e+00, -3.9912e+00,  3.7849e+00,  1.1900e+01, -6.6169e+00,\n",
      "         -1.9891e-02, -1.2924e+01, -2.1152e+00, -2.4158e+00,  3.1070e-01],\n",
      "        [-4.1049e+00,  5.6358e+00, -1.8916e+00, -1.2790e+00,  2.7102e+00,\n",
      "         -3.0580e+00, -6.0432e+00,  7.2562e+00, -3.7951e+00,  1.0208e-01],\n",
      "        [-5.6852e+00,  9.7699e+00, -2.4766e+00, -5.7802e+00, -1.9727e-01,\n",
      "          1.3954e+00,  1.0850e+00, -1.5635e+00,  2.7619e+00, -2.7749e+00],\n",
      "        [-6.6455e+00, -4.4306e+00, -6.0869e+00, -4.2831e+00,  5.4913e+00,\n",
      "         -6.5108e-01, -1.2496e+01,  4.1338e+00, -5.5838e-01,  7.8063e+00],\n",
      "        [ 1.3749e+01, -6.9246e+00,  1.7102e+00, -2.4086e+00, -4.0568e+00,\n",
      "         -4.1098e+00, -3.0596e+00, -5.6943e-02,  7.3976e-01,  1.5493e+00],\n",
      "        [-2.4990e+00,  1.0876e+01,  8.7017e-01, -5.9479e+00,  9.3789e-01,\n",
      "          2.9259e-01, -3.6827e-01, -1.0928e+00, -1.0202e+00, -4.3477e+00],\n",
      "        [-1.0454e-01, -2.3487e+00, -4.2398e+00, -4.9924e-02,  1.2850e-01,\n",
      "          9.8900e+00,  3.8876e+00, -9.0302e+00, -2.8979e+00, -4.3795e+00],\n",
      "        [-8.4517e+00, -5.1024e+00, -3.8697e+00,  1.8739e+01, -9.7118e+00,\n",
      "          5.5068e+00, -1.0378e+01, -1.7057e+00, -3.9117e+00, -1.5687e-02],\n",
      "        [-6.4921e+00, -3.6888e+00,  3.3788e-01, -5.6604e-02,  1.4910e+00,\n",
      "         -1.7457e+00, -9.5968e+00, -2.0906e-01,  2.3624e-03,  7.7575e+00],\n",
      "        [ 1.9826e+00,  1.1362e+00,  5.3686e-01, -5.6875e+00,  7.5822e+00,\n",
      "         -9.6275e-01,  1.0194e+01,  7.5608e-01, -8.4665e+00, -6.0169e+00],\n",
      "        [ 1.2687e+01, -5.7105e+00,  1.3600e+00, -3.2811e+00, -7.2509e-01,\n",
      "         -4.2319e+00, -2.6211e+00, -1.3107e+00, -3.2882e-01, -9.4194e-01],\n",
      "        [-5.9204e+00,  5.4537e+00, -3.4935e+00, -4.0421e+00,  4.0746e+00,\n",
      "         -1.3189e+00, -8.0142e+00,  1.0408e+01, -6.1087e+00,  4.5460e-01],\n",
      "        [-6.0408e+00, -7.3141e+00, -3.7417e-01, -9.8549e-01, -6.1079e-01,\n",
      "          2.0090e+00,  5.7826e+00, -1.1356e+01,  1.3221e+01, -6.3174e+00],\n",
      "        [-4.3160e+00,  1.1916e+01, -2.1476e+00, -4.9522e+00,  1.7765e+00,\n",
      "         -1.1501e+00,  5.7653e-01,  5.1977e-01, -8.4878e-01, -3.5120e+00],\n",
      "        [-9.0836e+00, -1.1872e+01, -8.4762e+00,  4.2530e+00, -6.1538e+00,\n",
      "          1.1222e+01, -3.1456e+00, -7.3687e+00,  5.1231e+00,  6.4339e+00],\n",
      "        [-5.5537e+00, -9.4255e+00, -9.2516e+00, -1.4323e+00, -3.3723e+00,\n",
      "          1.5197e+01, -3.9313e+00, -8.2472e+00, -1.5816e+00,  4.3245e+00],\n",
      "        [-3.8646e+00, -1.8077e+00, -2.9674e+00, -1.4342e+00,  4.1802e-02,\n",
      "          2.6709e+00, -8.7400e+00,  3.3185e+00, -6.6023e+00,  8.2472e+00],\n",
      "        [-1.6243e+00, -6.1272e+00, -2.7744e+00, -5.8261e+00,  1.7553e+01,\n",
      "         -5.8036e+00, -1.1684e+00,  3.5256e+00,  5.1181e-01, -5.3259e+00],\n",
      "        [-5.8635e+00,  2.0470e+00, -8.2382e-01, -2.1868e+00, -4.6267e-01,\n",
      "         -3.8732e+00, -1.0739e+01,  1.4414e+01, -5.4088e+00,  7.6966e-01],\n",
      "        [-6.7309e+00, -3.9337e-01,  1.2546e+00, -1.3649e+00, -4.6879e+00,\n",
      "         -4.4432e+00, -1.4856e+01,  1.4506e+01, -6.4586e+00,  2.3444e+00],\n",
      "        [-4.2780e+00,  1.2097e+01, -2.1382e+00, -3.1808e+00,  1.7859e+00,\n",
      "         -2.3928e+00, -3.0988e+00,  1.7849e+00,  3.5460e-02, -2.3780e+00],\n",
      "        [ 6.0550e+00, -3.6314e+00, -6.0561e-01, -5.9870e+00,  2.0573e+00,\n",
      "          1.0085e+00,  1.8216e+01, -8.9653e+00, -2.8125e+00, -8.9892e+00],\n",
      "        [ 1.1605e+01, -6.8797e+00,  1.9787e+00, -3.2433e+00,  2.7139e-01,\n",
      "         -4.9055e+00, -1.9152e+00,  4.3465e-02, -1.8758e+00, -1.2946e+00],\n",
      "        [-4.1895e+00, -7.2714e-01,  1.1252e+01,  1.6757e+00, -3.7463e+00,\n",
      "         -3.5601e+00, -7.1731e+00,  1.4841e+00, -2.4517e-01, -4.2077e+00],\n",
      "        [-6.7363e+00, -6.6167e+00,  3.1858e+00,  1.1662e+01, -8.6190e+00,\n",
      "          4.8599e-01, -1.0550e+01,  1.4734e+00, -2.9623e+00,  1.2366e+00],\n",
      "        [-5.8656e+00, -4.7646e+00,  1.6080e+01,  7.7298e-01, -4.5292e+00,\n",
      "         -6.9753e+00, -5.4206e+00, -3.9196e-01, -2.9954e-01, -1.4625e+00],\n",
      "        [-8.1163e+00, -3.0640e+00, -5.9657e+00, -4.5192e+00,  6.2678e+00,\n",
      "         -1.2581e+00, -1.3661e+01,  3.0480e+00, -3.2700e+00,  1.2188e+01],\n",
      "        [-2.5523e+00, -1.0075e+01, -7.5503e+00, -8.4550e-01, -3.1896e+00,\n",
      "          1.3642e+01, -1.8334e+00, -8.8091e+00, -1.1381e+00,  2.5149e+00],\n",
      "        [-6.3618e+00,  1.5272e+00,  2.3390e+00,  2.7469e-01, -5.0880e+00,\n",
      "         -5.8510e+00, -1.2229e+01,  1.2833e+01, -4.8126e+00, -1.6093e-01],\n",
      "        [ 5.6925e+00, -1.2329e+00, -4.4208e+00, -6.3164e+00,  3.2239e+00,\n",
      "          3.2708e-02,  1.8038e+01, -5.7771e+00, -1.4774e+00, -7.4973e+00],\n",
      "        [-7.9675e+00,  3.7521e-01, -6.0458e+00, -6.0075e+00,  1.1079e+01,\n",
      "         -7.0189e-02, -7.7392e+00, -1.9411e-01,  2.0056e+00,  2.6559e+00],\n",
      "        [-5.2136e-01, -5.6867e+00,  1.6149e+01,  5.8872e+00, -1.2336e+01,\n",
      "         -8.6915e+00, -4.3393e+00, -3.1804e+00,  2.9798e+00, -4.8007e+00],\n",
      "        [-2.1075e+00,  1.5393e+00, -2.8328e+00, -6.6168e+00,  1.2821e+01,\n",
      "         -2.5249e+00,  5.7583e+00,  3.7273e+00, -8.4132e+00, -2.0876e+00],\n",
      "        [-1.0461e+01, -2.6373e+00, -1.5526e+00, -4.1004e+00,  1.6064e+01,\n",
      "         -7.1938e+00, -7.7050e+00,  5.6635e+00,  1.5169e+00, -2.7482e+00],\n",
      "        [-9.9307e+00, -5.4170e+00, -6.5914e+00,  4.5001e-01, -8.6449e+00,\n",
      "          1.4259e+01, -1.7798e+00, -4.7585e+00,  1.6938e+00,  8.7702e-01],\n",
      "        [-5.5947e+00, -3.9574e+00,  3.7996e-01,  1.3737e+01, -1.3503e+01,\n",
      "          2.6520e+00, -1.1832e+01,  3.1927e-01, -3.0690e+00,  2.4132e+00],\n",
      "        [-2.0069e+00,  1.1321e+01,  5.2518e-01, -5.1504e+00,  6.8413e-01,\n",
      "          3.0207e-01, -6.2831e-01, -1.3541e+00,  1.0689e-01, -5.4258e+00],\n",
      "        [-7.5909e+00, -7.1849e+00,  1.5054e+00,  3.0645e-01, -9.7539e+00,\n",
      "          2.2729e+00, -4.6428e+00, -6.8632e+00,  1.7768e+01, -2.1424e+00],\n",
      "        [-3.0886e+00, -2.0140e+00, -6.3751e-01, -5.5608e+00,  1.5575e+01,\n",
      "         -3.9653e+00, -2.6175e+00,  7.5287e-01, -2.5227e+00, -4.3438e+00],\n",
      "        [-8.0073e+00,  2.1264e+00, -8.6198e-03, -2.2823e+00, -2.9090e+00,\n",
      "         -4.2836e+00, -1.3308e+01,  1.3868e+01, -6.4107e+00,  4.8495e+00],\n",
      "        [ 5.1628e+00, -1.0983e+00, -3.1578e+00, -4.2176e+00,  6.5588e-02,\n",
      "          1.1797e+00,  1.6465e+01, -6.3658e+00, -2.7824e+00, -5.9852e+00],\n",
      "        [-4.6199e+00,  1.1266e+01, -2.7259e+00, -5.8815e+00,  2.4658e+00,\n",
      "         -7.7147e-01, -2.1115e+00,  2.4980e+00, -2.3892e+00, -8.1697e-01],\n",
      "        [-3.1059e+00,  1.1999e+01, -1.1665e+00, -3.8610e+00,  2.9802e+00,\n",
      "         -1.8331e+00, -1.0326e+00, -8.5934e-01,  9.0265e-01, -2.4121e+00],\n",
      "        [-2.8788e+00,  8.7979e+00, -1.0311e+00, -4.2089e+00,  1.3928e+00,\n",
      "         -6.3717e-01, -9.3672e-01, -6.7642e-01, -3.7520e-01, -2.7589e+00],\n",
      "        [-3.8994e+00, -8.1865e+00,  4.7268e+00,  2.3790e+00, -5.8069e+00,\n",
      "         -4.3826e+00, -3.2141e+00, -9.5306e+00,  1.7501e+01, -1.7313e+00],\n",
      "        [-4.9055e+00,  7.8539e-01, -1.4833e+00, -2.5199e+00,  1.0535e+01,\n",
      "         -2.8509e+00, -3.6560e+00,  4.2595e+00, -2.4708e+00,  1.4114e-01],\n",
      "        [-1.4060e+01, -1.1575e+00, -2.6276e+00, -5.6997e+00,  1.3091e+01,\n",
      "         -4.0317e-02,  8.1202e-01,  2.4793e+00, -1.4474e+00, -1.9728e+00],\n",
      "        [-7.4186e+00, -3.1696e+00, -3.9708e+00, -7.1268e+00,  1.7388e+01,\n",
      "         -4.8264e+00, -7.2978e+00,  2.4524e+00,  9.1957e-02, -1.9005e-01],\n",
      "        [-7.9853e+00, -2.7709e+00,  4.4959e+00,  9.3866e+00, -9.2396e+00,\n",
      "          6.7477e-02, -1.1453e+01,  1.9882e+00, -2.7462e+00, -1.8760e+00],\n",
      "        [ 7.7443e-03, -1.1705e+01,  3.8421e+00,  2.3524e+00, -4.5516e+00,\n",
      "         -4.4437e+00, -3.4037e+00, -5.0257e+00,  1.1975e+01,  1.5806e+00],\n",
      "        [ 4.6334e+00, -4.4175e+00, -3.7154e+00, -4.3854e+00,  1.2692e+00,\n",
      "          1.5675e+00,  1.5218e+01, -9.1041e+00,  1.4922e+00, -7.0346e+00]])\n",
      "predictions are => tensor([4, 4, 0, 2, 1, 4, 8, 8, 1, 9, 3, 5, 2, 3, 7, 1, 9, 0, 1, 5, 3, 9, 6, 0,\n",
      "        7, 8, 1, 5, 5, 9, 4, 7, 7, 1, 6, 0, 2, 3, 2, 9, 5, 7, 6, 4, 2, 4, 4, 5,\n",
      "        3, 1, 8, 4, 7, 6, 1, 1, 1, 8, 4, 4, 4, 3, 8, 6])\n",
      "Accuracy on test set: 98.23\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:2f}\")\n",
    "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
